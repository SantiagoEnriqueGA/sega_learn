<!DOCTYPE html>
<html lang="en">
<head>
<style>
body { background-color: #f0f0f8; }
table.heading tr { background-color: #7799ee; }
.decor { color: #ffffff; }
.title-decor { background-color: #ffc8d8; color: #000000; }
.pkg-content-decor { background-color: #aa55cc; }
.index-decor { background-color: #ee77aa; }
.functions-decor { background-color: #eeaa77; }
.data-decor { background-color: #55aa55; }
.author-decor { background-color: #7799ee; }
.credits-decor { background-color: #7799ee; }
.error-decor { background-color: #bb0000; }
.grey { color: #909090; }
.white { color: #ffffff; }
.repr { color: #c040c0; }
table.heading tr td.title, table.heading tr td.extra { vertical-align: bottom; }
table.heading tr td.extra { text-align: right; }
.heading-text { font-family: helvetica, arial; }
.bigsection { font-size: larger; }
.title { font-size: x-large; }
.code { font-family: monospace; }
table { width: 100%; border-spacing: 0; border-collapse: collapse; border: 0; }
td { padding: 2; }
td.section-title, td.multicolumn { vertical-align: bottom; }
td.multicolumn { width: 25%; }
td.singlecolumn { width: 100%; }
</style>
<meta charset="utf-8">
<title>Python: module sega_learn.utils.metrics</title>
</head><body>

<table class="heading">
<tr class="heading-text decor">
<td class="title">&nbsp;<br><strong class="title"><a href="sega_learn.html" class="white">sega_learn</a>.<a href="sega_learn.utils.html" class="white">utils</a>.metrics</strong></td>
</tr></table>
    <p></p>
<p>
<table class="section">
<tr class="decor pkg-content-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Modules</strong></td></tr>

<tr><td class="decor pkg-content-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><table><tr><td class="multicolumn"><a href="numpy.html">numpy</a><br>
</td><td class="multicolumn"></td><td class="multicolumn"></td><td class="multicolumn"></td></tr></table></td></tr></table><p>
<table class="section">
<tr class="decor index-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Classes</strong></td></tr>

<tr><td class="decor index-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><dl>
<dt class="heading-text"><a href="builtins.html#object">builtins.object</a>
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.utils.metrics.html#Metrics">Metrics</a>
</dt></dl>
</dd>
</dl>
 <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Metrics">class <strong>Metrics</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Implements&nbsp;various&nbsp;regression&nbsp;and&nbsp;classification&nbsp;metrics.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Class methods defined here:<br>
<dl><dt><a name="Metrics-accuracy"><strong>accuracy</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;accuracy&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;accuracy:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;accuracy&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-classification_report"><strong>classification_report</strong></a>(y_true, y_pred)</dt><dd><span class="code">Generates&nbsp;a&nbsp;classification&nbsp;report&nbsp;for&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;report:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;classification&nbsp;report.</span></dd></dl>

<dl><dt><a name="Metrics-confusion_matrix"><strong>confusion_matrix</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;confusion&nbsp;matrix&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;cm:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;confusion&nbsp;matrix.</span></dd></dl>

<dl><dt><a name="Metrics-f1_score"><strong>f1_score</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;F1&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;f1_score:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;F1&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-log_loss"><strong>log_loss</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;log&nbsp;loss&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;probabilities.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;log_loss:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;log&nbsp;loss.</span></dd></dl>

<dl><dt><a name="Metrics-mean_absolute_error"><strong>mean_absolute_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;absolute&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;mae:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;mean&nbsp;absolute&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-mean_absolute_percentage_error"><strong>mean_absolute_percentage_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;absolute&nbsp;percentage&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;mape:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;mean&nbsp;absolute&nbsp;percentage&nbsp;error&nbsp;as&nbsp;a&nbsp;decimal.&nbsp;Returns&nbsp;np.nan&nbsp;if&nbsp;y_true&nbsp;is&nbsp;all&nbsp;zeros.</span></dd></dl>

<dl><dt><a name="Metrics-mean_percentage_error"><strong>mean_percentage_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;percentage&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;mpe:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;mean&nbsp;percentage&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-mean_squared_error"><strong>mean_squared_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;squared&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;mse:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;mean&nbsp;squared&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-precision"><strong>precision</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;precision&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;precision:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;precision&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-r_squared"><strong>r_squared</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;R-squared&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;r_squared:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;R-squared&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-recall"><strong>recall</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;recall&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;recall:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;recall&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-root_mean_squared_error"><strong>root_mean_squared_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;root&nbsp;mean&nbsp;squared&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;rmse:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;root&nbsp;mean&nbsp;squared&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-show_classification_report"><strong>show_classification_report</strong></a>(y_true, y_pred)</dt><dd><span class="code">Generates&nbsp;and&nbsp;displays&nbsp;a&nbsp;classification&nbsp;report&nbsp;for&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;report:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;classification&nbsp;report.</span></dd></dl>

<dl><dt><a name="Metrics-show_confusion_matrix"><strong>show_confusion_matrix</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;and&nbsp;displays&nbsp;the&nbsp;confusion&nbsp;matrix&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;cm:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;confusion&nbsp;matrix.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table></td></tr></table>
</body></html>
