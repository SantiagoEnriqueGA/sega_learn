<!DOCTYPE html>
<html lang="en">
<head>
<style>
body { background-color: #f0f0f8; }
table.heading tr { background-color: #7799ee; }
.decor { color: #ffffff; }
.title-decor { background-color: #ffc8d8; color: #000000; }
.pkg-content-decor { background-color: #aa55cc; }
.index-decor { background-color: #ee77aa; }
.functions-decor { background-color: #eeaa77; }
.data-decor { background-color: #55aa55; }
.author-decor { background-color: #7799ee; }
.credits-decor { background-color: #7799ee; }
.error-decor { background-color: #bb0000; }
.grey { color: #909090; }
.white { color: #ffffff; }
.repr { color: #c040c0; }
table.heading tr td.title, table.heading tr td.extra { vertical-align: bottom; }
table.heading tr td.extra { text-align: right; }
.heading-text { font-family: helvetica, arial; }
.bigsection { font-size: larger; }
.title { font-size: x-large; }
.code { font-family: monospace; }
table { width: 100%; border-spacing: 0; border-collapse: collapse; border: 0; }
td { padding: 2; }
td.section-title, td.multicolumn { vertical-align: bottom; }
td.multicolumn { width: 25%; }
td.singlecolumn { width: 100%; }
</style>
<meta charset="utf-8">
<title>Python: package sega_learn.trees</title>
</head><body>

<table class="heading">
<tr class="heading-text decor">
<td class="title">&nbsp;<br><strong class="title"><a href="sega_learn.html" class="white">sega_learn</a>.trees</strong></td>
</tr></table>
    <p></p>
<p>
<table class="section">
<tr class="decor pkg-content-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Package Contents</strong></td></tr>

<tr><td class="decor pkg-content-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><table><tr><td class="multicolumn"><a href="sega_learn.trees.adaBoostClassifier.html">adaBoostClassifier</a><br>
<a href="sega_learn.trees.adaBoostRegressor.html">adaBoostRegressor</a><br>
<a href="sega_learn.trees.gradientBoostedClassifier.html">gradientBoostedClassifier</a><br>
</td><td class="multicolumn"><a href="sega_learn.trees.gradientBoostedRegressor.html">gradientBoostedRegressor</a><br>
<a href="sega_learn.trees.isolationForest.html">isolationForest</a><br>
<a href="sega_learn.trees.randomForestClassifier.html">randomForestClassifier</a><br>
</td><td class="multicolumn"><a href="sega_learn.trees.randomForestRegressor.html">randomForestRegressor</a><br>
<a href="sega_learn.trees.treeClassifier.html">treeClassifier</a><br>
<a href="sega_learn.trees.treeRegressor.html">treeRegressor</a><br>
</td><td class="multicolumn"></td></tr></table></td></tr></table><p>
<table class="section">
<tr class="decor index-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Classes</strong></td></tr>

<tr><td class="decor index-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><dl>
<dt class="heading-text"><a href="builtins.html#object">builtins.object</a>
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.trees.adaBoostClassifier.html#AdaBoostClassifier">sega_learn.trees.adaBoostClassifier.AdaBoostClassifier</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.adaBoostRegressor.html#AdaBoostRegressor">sega_learn.trees.adaBoostRegressor.AdaBoostRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.gradientBoostedClassifier.html#GradientBoostedClassifier">sega_learn.trees.gradientBoostedClassifier.GradientBoostedClassifier</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.gradientBoostedRegressor.html#GradientBoostedRegressor">sega_learn.trees.gradientBoostedRegressor.GradientBoostedRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.isolationForest.html#IsolationForest">sega_learn.trees.isolationForest.IsolationForest</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.isolationForest.html#IsolationTree">sega_learn.trees.isolationForest.IsolationTree</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.isolationForest.html#IsolationUtils">sega_learn.trees.isolationForest.IsolationUtils</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.randomForestClassifier.html#RandomForestClassifier">sega_learn.trees.randomForestClassifier.RandomForestClassifier</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.randomForestRegressor.html#RandomForestRegressor">sega_learn.trees.randomForestRegressor.RandomForestRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeClassifier.html#ClassifierTree">sega_learn.trees.treeClassifier.ClassifierTree</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeClassifier.html#ClassifierTreeUtility">sega_learn.trees.treeClassifier.ClassifierTreeUtility</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeRegressor.html#RegressorTree">sega_learn.trees.treeRegressor.RegressorTree</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeRegressor.html#RegressorTreeUtility">sega_learn.trees.treeRegressor.RegressorTreeUtility</a>
</dt></dl>
</dd>
</dl>
 <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="AdaBoostClassifier">class <strong>AdaBoostClassifier</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#AdaBoostClassifier">AdaBoostClassifier</a>(base_estimator=None,&nbsp;n_estimators=50,&nbsp;learning_rate=1.0,&nbsp;random_state=None,&nbsp;max_depth=3,&nbsp;min_samples_split=2)<br>
&nbsp;<br>
AdaBoost&nbsp;classifier.<br>
&nbsp;<br>
Builds&nbsp;an&nbsp;additive&nbsp;model&nbsp;by&nbsp;sequentially&nbsp;fitting&nbsp;weak&nbsp;classifiers&nbsp;(default:&nbsp;decision&nbsp;stumps)<br>
on&nbsp;modified&nbsp;versions&nbsp;of&nbsp;the&nbsp;data.&nbsp;Each&nbsp;subsequent&nbsp;classifier&nbsp;focuses&nbsp;more&nbsp;on&nbsp;samples<br>
that&nbsp;were&nbsp;misclassified&nbsp;by&nbsp;the&nbsp;previous&nbsp;ensemble.<br>
&nbsp;<br>
Uses&nbsp;the&nbsp;SAMME&nbsp;algorithm&nbsp;which&nbsp;supports&nbsp;multi-class&nbsp;classification.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;base_estimator_&nbsp;(<a href="builtins.html#object">object</a>):&nbsp;The&nbsp;base&nbsp;estimator&nbsp;template&nbsp;used&nbsp;for&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;estimators&nbsp;at&nbsp;which&nbsp;boosting&nbsp;is&nbsp;terminated.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Weight&nbsp;applied&nbsp;to&nbsp;each&nbsp;classifier's&nbsp;contribution.<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimators_&nbsp;(list):&nbsp;The&nbsp;collection&nbsp;of&nbsp;fitted&nbsp;base&nbsp;estimators.<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimator_weights_&nbsp;(np.ndarray):&nbsp;Weights&nbsp;for&nbsp;each&nbsp;estimator.<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimator_errors_&nbsp;(np.ndarray):&nbsp;Classification&nbsp;error&nbsp;for&nbsp;each&nbsp;estimator.<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes_&nbsp;(np.ndarray):&nbsp;The&nbsp;class&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_classes_&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;classes.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="AdaBoostClassifier-__init__"><strong>__init__</strong></a>(self, base_estimator=None, n_estimators=50, learning_rate=1.0, random_state=None, max_depth=3, min_samples_split=2)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#AdaBoostClassifier">AdaBoostClassifier</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;base_estimator&nbsp;(<a href="builtins.html#object">object</a>,&nbsp;optional):&nbsp;The&nbsp;base&nbsp;estimator&nbsp;from&nbsp;which&nbsp;the&nbsp;boosted&nbsp;ensemble&nbsp;is&nbsp;built.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Support&nbsp;for&nbsp;sample&nbsp;weighting&nbsp;is&nbsp;required.&nbsp;If&nbsp;None,&nbsp;then<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;base&nbsp;estimator&nbsp;is&nbsp;DecisionTreeClassifier(max_depth=1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;estimators&nbsp;at&nbsp;which&nbsp;boosting&nbsp;is&nbsp;terminated.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In&nbsp;case&nbsp;of&nbsp;perfect&nbsp;fit,&nbsp;the&nbsp;learning&nbsp;procedure&nbsp;is&nbsp;stopped&nbsp;early.&nbsp;Defaults&nbsp;to&nbsp;50.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;Weight&nbsp;applied&nbsp;to&nbsp;each&nbsp;classifier's&nbsp;contribution.&nbsp;Defaults&nbsp;to&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int,&nbsp;optional):&nbsp;Controls&nbsp;the&nbsp;random&nbsp;seed&nbsp;given&nbsp;to&nbsp;the&nbsp;base&nbsp;estimator&nbsp;at&nbsp;each&nbsp;boosting&nbsp;iteration.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;base&nbsp;estimator.&nbsp;Defaults&nbsp;to&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;when&nbsp;using&nbsp;the&nbsp;default&nbsp;`<a href="#ClassifierTree">ClassifierTree</a>`&nbsp;base&nbsp;estimator.&nbsp;Defaults&nbsp;to&nbsp;2.</span></dd></dl>

<dl><dt><a name="AdaBoostClassifier-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;the&nbsp;decision&nbsp;function&nbsp;of&nbsp;X.</span></dd></dl>

<dl><dt><a name="AdaBoostClassifier-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Build&nbsp;a&nbsp;boosted&nbsp;classifier&nbsp;from&nbsp;the&nbsp;training&nbsp;set&nbsp;(X,&nbsp;y).</span></dd></dl>

<dl><dt><a name="AdaBoostClassifier-get_stats"><strong>get_stats</strong></a>(self, y_true, X=None, y_pred=None, verbose=False)</dt><dd><span class="code">Calculate&nbsp;and&nbsp;optionally&nbsp;print&nbsp;evaluation&nbsp;metrics.&nbsp;Requires&nbsp;either&nbsp;X&nbsp;or&nbsp;y_pred.</span></dd></dl>

<dl><dt><a name="AdaBoostClassifier-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;classes&nbsp;for&nbsp;X.</span></dd></dl>

<dl><dt><a name="AdaBoostClassifier-predict_proba"><strong>predict_proba</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;class&nbsp;probabilities&nbsp;for&nbsp;X.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="AdaBoostRegressor">class <strong>AdaBoostRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#AdaBoostRegressor">AdaBoostRegressor</a>(base_estimator=None,&nbsp;n_estimators=50,&nbsp;learning_rate=1.0,&nbsp;loss='linear',&nbsp;random_state=None,&nbsp;max_depth=3,&nbsp;min_samples_split=2)<br>
&nbsp;<br>
AdaBoost&nbsp;regressor.<br>
&nbsp;<br>
Builds&nbsp;an&nbsp;additive&nbsp;model&nbsp;by&nbsp;sequentially&nbsp;fitting&nbsp;weak&nbsp;regressors&nbsp;(default:&nbsp;decision&nbsp;trees)<br>
on&nbsp;modified&nbsp;versions&nbsp;of&nbsp;the&nbsp;data.&nbsp;The&nbsp;weights&nbsp;of&nbsp;instances&nbsp;are&nbsp;adjusted&nbsp;at&nbsp;each&nbsp;iteration<br>
so&nbsp;that&nbsp;subsequent&nbsp;regressors&nbsp;focus&nbsp;more&nbsp;on&nbsp;instances&nbsp;with&nbsp;larger&nbsp;errors.<br>
&nbsp;<br>
Uses&nbsp;the&nbsp;AdaBoost.R2&nbsp;algorithm.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;base_estimator_&nbsp;(<a href="builtins.html#object">object</a>):&nbsp;The&nbsp;base&nbsp;estimator&nbsp;template&nbsp;used&nbsp;for&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;estimators&nbsp;at&nbsp;which&nbsp;boosting&nbsp;is&nbsp;terminated.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Contribution&nbsp;of&nbsp;each&nbsp;regressor&nbsp;to&nbsp;the&nbsp;final&nbsp;prediction.<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss&nbsp;(str):&nbsp;The&nbsp;loss&nbsp;function&nbsp;to&nbsp;use&nbsp;when&nbsp;updating&nbsp;the&nbsp;weights&nbsp;('linear',&nbsp;'square',&nbsp;'exponential').<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimators_&nbsp;(list):&nbsp;The&nbsp;collection&nbsp;of&nbsp;fitted&nbsp;base&nbsp;estimators.<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimator_weights_&nbsp;(np.ndarray):&nbsp;Weights&nbsp;for&nbsp;each&nbsp;estimator&nbsp;(alpha&nbsp;values,&nbsp;specifically&nbsp;log(1/beta)).<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimator_errors_&nbsp;(np.ndarray):&nbsp;Loss&nbsp;value&nbsp;for&nbsp;each&nbsp;estimator&nbsp;on&nbsp;the&nbsp;weighted&nbsp;training&nbsp;data.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="AdaBoostRegressor-__init__"><strong>__init__</strong></a>(self, base_estimator=None, n_estimators=50, learning_rate=1.0, loss='linear', random_state=None, max_depth=3, min_samples_split=2)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#AdaBoostRegressor">AdaBoostRegressor</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;base_estimator&nbsp;(<a href="builtins.html#object">object</a>,&nbsp;optional):&nbsp;The&nbsp;base&nbsp;estimator&nbsp;from&nbsp;which&nbsp;the&nbsp;boosted&nbsp;ensemble&nbsp;is&nbsp;built.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Support&nbsp;for&nbsp;sample&nbsp;weighting&nbsp;is&nbsp;required.&nbsp;If&nbsp;None,&nbsp;then<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;base&nbsp;estimator&nbsp;is&nbsp;DecisionTreeRegressor(max_depth=3).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;estimators.&nbsp;Defaults&nbsp;to&nbsp;50.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;Shrinks&nbsp;the&nbsp;contribution&nbsp;of&nbsp;each&nbsp;regressor&nbsp;by&nbsp;learning_rate.&nbsp;Defaults&nbsp;to&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss&nbsp;(str,&nbsp;optional):&nbsp;The&nbsp;loss&nbsp;function&nbsp;to&nbsp;use&nbsp;when&nbsp;updating&nbsp;sample&nbsp;weights&nbsp;('linear',&nbsp;'square',&nbsp;'exponential').<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;'linear'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int,&nbsp;optional):&nbsp;Controls&nbsp;the&nbsp;random&nbsp;seed.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int,&nbsp;optional):&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;base&nbsp;estimator.&nbsp;Defaults&nbsp;to&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int,&nbsp;optional):&nbsp;Minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node.&nbsp;Defaults&nbsp;to&nbsp;2.</span></dd></dl>

<dl><dt><a name="AdaBoostRegressor-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Build&nbsp;a&nbsp;boosted&nbsp;regressor&nbsp;from&nbsp;the&nbsp;training&nbsp;set&nbsp;(X,&nbsp;y).</span></dd></dl>

<dl><dt><a name="AdaBoostRegressor-get_stats"><strong>get_stats</strong></a>(self, y_true, X=None, y_pred=None, verbose=False)</dt><dd><span class="code">Calculate&nbsp;and&nbsp;optionally&nbsp;print&nbsp;evaluation&nbsp;metrics.&nbsp;Requires&nbsp;either&nbsp;X&nbsp;or&nbsp;y_pred.</span></dd></dl>

<dl><dt><a name="AdaBoostRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;regression&nbsp;target&nbsp;for&nbsp;X.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="ClassifierTree">class <strong>ClassifierTree</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#ClassifierTree">ClassifierTree</a>(max_depth=5,&nbsp;min_samples_split=2)<br>
&nbsp;<br>
A&nbsp;class&nbsp;representing&nbsp;a&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#ClassifierTree-learn">learn</a>(X,&nbsp;y,&nbsp;par_node={},&nbsp;depth=0):&nbsp;Builds&nbsp;the&nbsp;decision&nbsp;tree&nbsp;based&nbsp;on&nbsp;the&nbsp;given&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#ClassifierTree-classify">classify</a>(record):&nbsp;Classifies&nbsp;a&nbsp;record&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="ClassifierTree-__init__"><strong>__init__</strong></a>(self, max_depth=5, min_samples_split=2)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#ClassifierTree">ClassifierTree</a>&nbsp;with&nbsp;a&nbsp;maximum&nbsp;depth.</span></dd></dl>

<dl><dt><a name="ClassifierTree-fit"><strong>fit</strong></a>(self, X, y, sample_weight=None)</dt><dd><span class="code">Fits&nbsp;the&nbsp;decision&nbsp;tree&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).</span></dd></dl>

<dl><dt><a name="ClassifierTree-learn"><strong>learn</strong></a>(self, X, y, par_node=None, depth=0, sample_weight=None)</dt><dd><span class="code">Builds&nbsp;the&nbsp;decision&nbsp;tree&nbsp;based&nbsp;on&nbsp;the&nbsp;given&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;par_node:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;parent&nbsp;node&nbsp;of&nbsp;the&nbsp;current&nbsp;subtree&nbsp;(default:&nbsp;{}).<br>
&nbsp;&nbsp;&nbsp;&nbsp;depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;current&nbsp;depth&nbsp;of&nbsp;the&nbsp;subtree&nbsp;(default:&nbsp;0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;The&nbsp;learned&nbsp;decision&nbsp;tree.</span></dd></dl>

<dl><dt><a name="ClassifierTree-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;labels&nbsp;for&nbsp;a&nbsp;given&nbsp;set&nbsp;of&nbsp;records&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;A&nbsp;list&nbsp;of&nbsp;predicted&nbsp;labels&nbsp;for&nbsp;each&nbsp;record.</span></dd></dl>

<dl><dt><a name="ClassifierTree-predict_proba"><strong>predict_proba</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;probabilities&nbsp;for&nbsp;a&nbsp;given&nbsp;set&nbsp;of&nbsp;records&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;A&nbsp;list&nbsp;of&nbsp;dictionaries&nbsp;where&nbsp;each&nbsp;dictionary&nbsp;represents&nbsp;the&nbsp;probability&nbsp;distribution<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;over&nbsp;the&nbsp;classes&nbsp;for&nbsp;a&nbsp;record.</span></dd></dl>

<hr>
Static methods defined here:<br>
<dl><dt><a name="ClassifierTree-classify"><strong>classify</strong></a>(tree, record)</dt><dd><span class="code">Classifies&nbsp;a&nbsp;given&nbsp;record&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;decision&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;record:&nbsp;(dict)&nbsp;-&nbsp;A&nbsp;dictionary&nbsp;representing&nbsp;the&nbsp;record&nbsp;to&nbsp;be&nbsp;classified.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;label&nbsp;assigned&nbsp;to&nbsp;the&nbsp;record&nbsp;based&nbsp;on&nbsp;the&nbsp;decision&nbsp;tree.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="ClassifierTreeUtility">class <strong>ClassifierTreeUtility</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#ClassifierTreeUtility">ClassifierTreeUtility</a>(min_samples_split=2)<br>
&nbsp;<br>
Utility&nbsp;class&nbsp;for&nbsp;computing&nbsp;entropy,&nbsp;partitioning&nbsp;classes,&nbsp;and&nbsp;calculating&nbsp;information&nbsp;gain.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="ClassifierTreeUtility-__init__"><strong>__init__</strong></a>(self, min_samples_split=2)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;utility&nbsp;class.</span></dd></dl>

<dl><dt><a name="ClassifierTreeUtility-best_split"><strong>best_split</strong></a>(self, X, y, sample_weight=None)</dt><dd><span class="code">Finds&nbsp;the&nbsp;best&nbsp;attribute&nbsp;and&nbsp;value&nbsp;to&nbsp;split&nbsp;the&nbsp;data&nbsp;based&nbsp;on&nbsp;information&nbsp;gain.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;variable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;the&nbsp;best&nbsp;split&nbsp;attribute,&nbsp;split&nbsp;value,&nbsp;left&nbsp;and&nbsp;right&nbsp;subsets&nbsp;of&nbsp;X&nbsp;and&nbsp;y,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;the&nbsp;information&nbsp;gain&nbsp;achieved&nbsp;by&nbsp;the&nbsp;split.</span></dd></dl>

<dl><dt><a name="ClassifierTreeUtility-entropy"><strong>entropy</strong></a>(self, class_y, sample_weight=None)</dt><dd><span class="code">Computes&nbsp;the&nbsp;entropy&nbsp;for&nbsp;a&nbsp;given&nbsp;class.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;class_y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;class&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;entropy&nbsp;value.</span></dd></dl>

<dl><dt><a name="ClassifierTreeUtility-information_gain"><strong>information_gain</strong></a>(self, previous_y, current_y, sample_weight_prev=None, sample_weight_current=None)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;information&nbsp;gain&nbsp;between&nbsp;the&nbsp;previous&nbsp;and&nbsp;current&nbsp;values&nbsp;of&nbsp;y.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;previous_y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;previous&nbsp;values&nbsp;of&nbsp;y.<br>
&nbsp;&nbsp;&nbsp;&nbsp;current_y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;current&nbsp;values&nbsp;of&nbsp;y.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight_prev:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;for&nbsp;the&nbsp;previous&nbsp;y&nbsp;values&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight_current:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;for&nbsp;the&nbsp;current&nbsp;y&nbsp;values&nbsp;(default:&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;information&nbsp;gain&nbsp;between&nbsp;the&nbsp;previous&nbsp;and&nbsp;current&nbsp;values&nbsp;of&nbsp;y.</span></dd></dl>

<dl><dt><a name="ClassifierTreeUtility-partition_classes"><strong>partition_classes</strong></a>(self, X, y, split_attribute, split_val, sample_weight=None)</dt><dd><span class="code">Partitions&nbsp;the&nbsp;dataset&nbsp;into&nbsp;two&nbsp;subsets&nbsp;based&nbsp;on&nbsp;a&nbsp;given&nbsp;split&nbsp;attribute&nbsp;and&nbsp;value.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;split_attribute:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;attribute&nbsp;to&nbsp;split&nbsp;on.<br>
&nbsp;&nbsp;&nbsp;&nbsp;split_val:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;value&nbsp;to&nbsp;split&nbsp;the&nbsp;attribute&nbsp;on.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_left:&nbsp;&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;subset&nbsp;of&nbsp;input&nbsp;features&nbsp;where&nbsp;the&nbsp;split&nbsp;attribute&nbsp;is&nbsp;less&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;the&nbsp;split&nbsp;value.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_right:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;subset&nbsp;of&nbsp;input&nbsp;features&nbsp;where&nbsp;the&nbsp;split&nbsp;attribute&nbsp;is&nbsp;greater&nbsp;than&nbsp;the&nbsp;split&nbsp;value.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_left:&nbsp;&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;subset&nbsp;of&nbsp;target&nbsp;labels&nbsp;corresponding&nbsp;to&nbsp;X_left.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_right:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;subset&nbsp;of&nbsp;target&nbsp;labels&nbsp;corresponding&nbsp;to&nbsp;X_right.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="GradientBoostedClassifier">class <strong>GradientBoostedClassifier</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#GradientBoostedClassifier">GradientBoostedClassifier</a>(X=None,&nbsp;y=None,&nbsp;n_estimators:&nbsp;int&nbsp;=&nbsp;100,&nbsp;learning_rate:&nbsp;float&nbsp;=&nbsp;0.1,&nbsp;max_depth:&nbsp;int&nbsp;=&nbsp;3,&nbsp;min_samples_split:&nbsp;int&nbsp;=&nbsp;2,&nbsp;random_seed:&nbsp;int&nbsp;=&nbsp;None)<br>
&nbsp;<br>
A&nbsp;Gradient&nbsp;Boosted&nbsp;Decision&nbsp;Tree&nbsp;Classifier.<br>
&nbsp;<br>
This&nbsp;model&nbsp;builds&nbsp;an&nbsp;ensemble&nbsp;of&nbsp;regression&nbsp;trees&nbsp;sequentially.&nbsp;Each&nbsp;tree<br>
is&nbsp;trained&nbsp;to&nbsp;predict&nbsp;the&nbsp;pseudo-residuals&nbsp;(gradients&nbsp;of&nbsp;the&nbsp;loss&nbsp;function)<br>
of&nbsp;the&nbsp;previous&nbsp;model's&nbsp;predictions.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(np.ndarray):&nbsp;Training&nbsp;input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(np.ndarray):&nbsp;Training&nbsp;target&nbsp;class&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;boosting&nbsp;stages&nbsp;(trees)&nbsp;to&nbsp;perform.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Step&nbsp;size&nbsp;shrinkage&nbsp;to&nbsp;prevent&nbsp;overfitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;individual&nbsp;regression&nbsp;tree&nbsp;estimators.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;Minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node&nbsp;in&nbsp;a&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int&nbsp;or&nbsp;None):&nbsp;Controls&nbsp;the&nbsp;randomness&nbsp;for&nbsp;reproducibility&nbsp;(currently&nbsp;affects&nbsp;feature&nbsp;selection&nbsp;within&nbsp;trees&nbsp;if&nbsp;applicable).<br>
&nbsp;&nbsp;&nbsp;&nbsp;trees_&nbsp;(list):&nbsp;List&nbsp;storing&nbsp;the&nbsp;fitted&nbsp;regression&nbsp;tree&nbsp;instances&nbsp;for&nbsp;each&nbsp;boosting&nbsp;stage&nbsp;(and&nbsp;for&nbsp;each&nbsp;class&nbsp;in&nbsp;multiclass).<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes_&nbsp;(np.ndarray):&nbsp;The&nbsp;unique&nbsp;class&nbsp;labels&nbsp;found&nbsp;in&nbsp;the&nbsp;target&nbsp;variable&nbsp;`y`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_classes_&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;unique&nbsp;classes.<br>
&nbsp;&nbsp;&nbsp;&nbsp;init_estimator_&nbsp;(float&nbsp;or&nbsp;np.ndarray):&nbsp;The&nbsp;initial&nbsp;prediction&nbsp;model&nbsp;(predicts&nbsp;log-odds).<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss_&nbsp;(str):&nbsp;The&nbsp;loss&nbsp;function&nbsp;used&nbsp;('log_loss'&nbsp;for&nbsp;binary,&nbsp;'multinomial'&nbsp;for&nbsp;multi-class).<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="GradientBoostedClassifier-__init__"><strong>__init__</strong></a>(self, X=None, y=None, n_estimators: int = 100, learning_rate: float = 0.1, max_depth: int = 3, min_samples_split: int = 2, random_seed: int = None)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;Gradient&nbsp;Boosted&nbsp;Classifier.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Training&nbsp;input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(array-like):&nbsp;Training&nbsp;target&nbsp;class&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;boosting&nbsp;stages&nbsp;(trees).<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Step&nbsp;size&nbsp;shrinkage&nbsp;to&nbsp;prevent&nbsp;overfitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;individual&nbsp;regression&nbsp;tree&nbsp;estimator.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;Minimum&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node&nbsp;in&nbsp;a&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int,&nbsp;optional):&nbsp;Seed&nbsp;for&nbsp;reproducibility.&nbsp;Defaults&nbsp;to&nbsp;None.</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-calculate_metrics"><strong>calculate_metrics</strong></a>(self, y_true, y_pred, y_prob=None)</dt><dd><span class="code">Calculate&nbsp;common&nbsp;classification&nbsp;metrics.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;class&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like):&nbsp;Predicted&nbsp;class&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_prob&nbsp;(array-like,&nbsp;optional):&nbsp;Predicted&nbsp;probabilities&nbsp;for&nbsp;Log&nbsp;Loss&nbsp;calculation.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics&nbsp;(Accuracy,&nbsp;Precision,&nbsp;Recall,&nbsp;F1&nbsp;Score,&nbsp;Log&nbsp;Loss&nbsp;if&nbsp;applicable).</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;the&nbsp;raw&nbsp;decision&nbsp;scores&nbsp;(log-odds)&nbsp;for&nbsp;samples&nbsp;in&nbsp;X.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;The&nbsp;raw&nbsp;decision&nbsp;scores.&nbsp;Shape&nbsp;(n_samples,)&nbsp;for&nbsp;binary<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or&nbsp;(n_samples,&nbsp;n_classes)&nbsp;for&nbsp;multi-class.</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-fit"><strong>fit</strong></a>(self, X=None, y=None, sample_weight=None, verbose=0)</dt><dd><span class="code">Fits&nbsp;the&nbsp;gradient&nbsp;boosted&nbsp;classifier&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Training&nbsp;input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(array-like):&nbsp;Training&nbsp;target&nbsp;class&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight&nbsp;(array-like,&nbsp;optional):&nbsp;Sample&nbsp;weights&nbsp;for&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(int):&nbsp;Controls&nbsp;the&nbsp;verbosity&nbsp;of&nbsp;the&nbsp;fitting&nbsp;process.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;for&nbsp;no&nbsp;output,&nbsp;1&nbsp;for&nbsp;basic&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;The&nbsp;fitted&nbsp;<a href="#GradientBoostedClassifier">GradientBoostedClassifier</a>&nbsp;instance.</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-get_params"><strong>get_params</strong></a>(self)</dt><dd><span class="code">Get&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;<a href="#GradientBoostedClassifier">GradientBoostedClassifier</a>.</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-get_stats"><strong>get_stats</strong></a>(self, y_true, X=None, y_pred=None, verbose=False)</dt><dd><span class="code">Calculate&nbsp;and&nbsp;optionally&nbsp;print&nbsp;evaluation&nbsp;metrics.&nbsp;Requires&nbsp;either&nbsp;X&nbsp;or&nbsp;y_pred.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like,&nbsp;optional):&nbsp;Input&nbsp;features&nbsp;to&nbsp;generate&nbsp;predictions&nbsp;if&nbsp;y_pred&nbsp;is&nbsp;not&nbsp;provided.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like,&nbsp;optional):&nbsp;Pre-computed&nbsp;predicted&nbsp;class&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;the&nbsp;metrics.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics.</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;input&nbsp;features&nbsp;X.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Predicted&nbsp;class&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-predict_proba"><strong>predict_proba</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;class&nbsp;probabilities&nbsp;for&nbsp;samples&nbsp;in&nbsp;X.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Predicted&nbsp;class&nbsp;probabilities.&nbsp;Shape&nbsp;(n_samples,&nbsp;n_classes).<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;binary,&nbsp;columns&nbsp;are&nbsp;[P(class&nbsp;0),&nbsp;P(class&nbsp;1)].</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="GradientBoostedRegressor">class <strong>GradientBoostedRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#GradientBoostedRegressor">GradientBoostedRegressor</a>(X=None,&nbsp;y=None,&nbsp;num_trees:&nbsp;int&nbsp;=&nbsp;100,&nbsp;max_depth:&nbsp;int&nbsp;=&nbsp;3,&nbsp;learning_rate:&nbsp;float&nbsp;=&nbsp;0.1,&nbsp;min_samples_split:&nbsp;int&nbsp;=&nbsp;2,&nbsp;random_seed:&nbsp;int&nbsp;=&nbsp;None)<br>
&nbsp;<br>
A&nbsp;class&nbsp;to&nbsp;represent&nbsp;a&nbsp;Gradient&nbsp;Boosted&nbsp;Decision&nbsp;Tree&nbsp;Regressor.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int):&nbsp;The&nbsp;random&nbsp;seed&nbsp;for&nbsp;the&nbsp;random&nbsp;number&nbsp;generator.<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_trees&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;ensemble.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;decision&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;gradient&nbsp;boosted&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int):&nbsp;The&nbsp;random&nbsp;seed&nbsp;for&nbsp;the&nbsp;random&nbsp;number&nbsp;generator.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-fit">fit</a>(X=None,&nbsp;y=None,&nbsp;verbose=0):&nbsp;Fits&nbsp;the&nbsp;gradient&nbsp;boosted&nbsp;decision&nbsp;tree&nbsp;regressor&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-predict">predict</a>(X):&nbsp;Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-calculate_metrics">calculate_metrics</a>(y_true,&nbsp;y_pred):&nbsp;Calculates&nbsp;the&nbsp;evaluation&nbsp;metrics.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-get_stats">get_stats</a>(y_true,&nbsp;y_pred,&nbsp;verbose=False):&nbsp;Returns&nbsp;the&nbsp;evaluation&nbsp;metrics.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="GradientBoostedRegressor-__init__"><strong>__init__</strong></a>(self, X=None, y=None, num_trees: int = 100, max_depth: int = 3, learning_rate: float = 0.1, min_samples_split: int = 2, random_seed: int = None)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;Gradient&nbsp;Boosted&nbsp;Decision&nbsp;Tree&nbsp;Regressor.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Input&nbsp;feature&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Target&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_trees&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;boosting&nbsp;stages&nbsp;(trees).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;individual&nbsp;tree&nbsp;regressor.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Step&nbsp;size&nbsp;shrinkage&nbsp;to&nbsp;prevent&nbsp;overfitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;Minimum&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int):&nbsp;Seed&nbsp;for&nbsp;reproducibility&nbsp;(currently&nbsp;affects&nbsp;feature&nbsp;selection&nbsp;within&nbsp;trees).</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-calculate_metrics"><strong>calculate_metrics</strong></a>(self, y_true, y_pred)</dt><dd><span class="code">Calculate&nbsp;common&nbsp;regression&nbsp;metrics.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like):&nbsp;Predicted&nbsp;target&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics&nbsp;(MSE,&nbsp;R^2,&nbsp;MAE,&nbsp;RMSE,&nbsp;MAPE).</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-fit"><strong>fit</strong></a>(self, X=None, y=None, sample_weight=None, verbose=0)</dt><dd><span class="code">Fits&nbsp;the&nbsp;gradient&nbsp;boosted&nbsp;decision&nbsp;tree&nbsp;regressor&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
This&nbsp;method&nbsp;trains&nbsp;the&nbsp;ensemble&nbsp;of&nbsp;decision&nbsp;trees&nbsp;by&nbsp;iteratively&nbsp;fitting&nbsp;each&nbsp;tree&nbsp;to&nbsp;the&nbsp;residuals<br>
of&nbsp;the&nbsp;previous&nbsp;iteration.&nbsp;The&nbsp;residuals&nbsp;are&nbsp;updated&nbsp;after&nbsp;each&nbsp;iteration&nbsp;by&nbsp;subtracting&nbsp;the&nbsp;predictions<br>
made&nbsp;by&nbsp;the&nbsp;current&nbsp;tree&nbsp;from&nbsp;the&nbsp;:target&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Training&nbsp;input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(array-like):&nbsp;Training&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight&nbsp;(array-like):&nbsp;Sample&nbsp;weights&nbsp;for&nbsp;each&nbsp;instance&nbsp;(not&nbsp;used&nbsp;in&nbsp;this&nbsp;implementation).<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(int):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;progress&nbsp;messages&nbsp;(e.g.,&nbsp;residuals).&nbsp;0&nbsp;for&nbsp;no&nbsp;output,&nbsp;1&nbsp;for&nbsp;output,&nbsp;&gt;1&nbsp;for&nbsp;detailed&nbsp;output<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;The&nbsp;fitted&nbsp;<a href="#GradientBoostedRegressor">GradientBoostedRegressor</a>&nbsp;instance.</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-get_params"><strong>get_params</strong></a>(self)</dt><dd><span class="code">Get&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;<a href="#GradientBoostedRegressor">GradientBoostedRegressor</a>.</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-get_stats"><strong>get_stats</strong></a>(self, y_true, y_pred, verbose=False)</dt><dd><span class="code">Calculate&nbsp;and&nbsp;optionally&nbsp;print&nbsp;evaluation&nbsp;metrics.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like):&nbsp;Predicted&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;progress&nbsp;messages&nbsp;(e.g.,&nbsp;residuals).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics&nbsp;(MSE,&nbsp;R^2,&nbsp;MAE,&nbsp;RMSE,&nbsp;MAPE).</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;target&nbsp;values&nbsp;for&nbsp;input&nbsp;features&nbsp;X&nbsp;using&nbsp;the&nbsp;fitted&nbsp;GBR&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Predicted&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="IsolationForest">class <strong>IsolationForest</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#IsolationForest">IsolationForest</a>(n_trees=100,&nbsp;max_samples=None,&nbsp;max_depth=10,&nbsp;n_jobs=1,&nbsp;force_true_length=False)<br>
&nbsp;<br>
<a href="#IsolationForest">IsolationForest</a>&nbsp;is&nbsp;an&nbsp;implementation&nbsp;of&nbsp;the&nbsp;Isolation&nbsp;Forest&nbsp;algorithm&nbsp;for&nbsp;anomaly&nbsp;detection.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_trees&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;isolation&nbsp;trees&nbsp;to&nbsp;build.&nbsp;Default&nbsp;is&nbsp;100.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_samples&nbsp;(int&nbsp;or&nbsp;None):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;samples&nbsp;to&nbsp;draw&nbsp;for&nbsp;each&nbsp;tree.&nbsp;If&nbsp;None,&nbsp;defaults&nbsp;to&nbsp;the&nbsp;minimum&nbsp;of&nbsp;256&nbsp;or&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the&nbsp;dataset.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;isolation&nbsp;tree.&nbsp;Default&nbsp;is&nbsp;10.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;parallel&nbsp;jobs&nbsp;to&nbsp;run.&nbsp;Set&nbsp;to&nbsp;-1&nbsp;to&nbsp;use&nbsp;all&nbsp;available&nbsp;cores.&nbsp;Default&nbsp;is&nbsp;1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;force&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;calculation.&nbsp;Default&nbsp;is&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;trees&nbsp;(list):&nbsp;A&nbsp;list&nbsp;to&nbsp;store&nbsp;the&nbsp;trained&nbsp;isolation&nbsp;trees.<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes_&nbsp;(numpy.ndarray):&nbsp;An&nbsp;array&nbsp;representing&nbsp;the&nbsp;classes&nbsp;(0&nbsp;for&nbsp;normal,&nbsp;1&nbsp;for&nbsp;anomaly).<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationForest-__init__">__init__</a>(n_trees=100,&nbsp;max_samples=None,&nbsp;max_depth=10,&nbsp;n_jobs=1,&nbsp;force_true_length=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;<a href="#IsolationForest">IsolationForest</a>&nbsp;with&nbsp;the&nbsp;specified&nbsp;parameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationForest-fit">fit</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;the&nbsp;isolation&nbsp;forest&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_fit_tree(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;a&nbsp;single&nbsp;isolation&nbsp;tree&nbsp;to&nbsp;a&nbsp;subset&nbsp;of&nbsp;the&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationTree">IsolationTree</a>:&nbsp;A&nbsp;trained&nbsp;isolation&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationForest-anomaly_score">anomaly_score</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;the&nbsp;anomaly&nbsp;scores&nbsp;for&nbsp;given&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numpy.ndarray:&nbsp;An&nbsp;array&nbsp;of&nbsp;anomaly&nbsp;scores.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationForest-predict">predict</a>(X,&nbsp;threshold=0.5):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predicts&nbsp;whether&nbsp;samples&nbsp;are&nbsp;anomalies.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;threshold&nbsp;(float):&nbsp;The&nbsp;threshold&nbsp;for&nbsp;classifying&nbsp;anomalies&nbsp;(default:&nbsp;0.5).<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numpy.ndarray:&nbsp;An&nbsp;array&nbsp;of&nbsp;predictions&nbsp;(1&nbsp;if&nbsp;the&nbsp;sample&nbsp;is&nbsp;an&nbsp;anomaly,&nbsp;0&nbsp;otherwise).<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationForest-__sklearn_is_fitted__">__sklearn_is_fitted__</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Checks&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool:&nbsp;True&nbsp;if&nbsp;the&nbsp;model&nbsp;is&nbsp;fitted,&nbsp;False&nbsp;otherwise.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="IsolationForest-__init__"><strong>__init__</strong></a>(self, n_trees=100, max_samples=None, max_depth=10, n_jobs=1, force_true_length=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#IsolationForest">IsolationForest</a>&nbsp;with&nbsp;the&nbsp;specified&nbsp;parameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_trees:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;isolation&nbsp;trees&nbsp;to&nbsp;build&nbsp;(default:&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_samples:&nbsp;(int&nbsp;or&nbsp;None),&nbsp;optional&nbsp;-&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;samples&nbsp;to&nbsp;draw&nbsp;for&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;None,&nbsp;defaults&nbsp;to&nbsp;the&nbsp;minimum&nbsp;of&nbsp;256&nbsp;or&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the&nbsp;dataset&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;isolation&nbsp;tree&nbsp;(default:&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;parallel&nbsp;jobs&nbsp;to&nbsp;run.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set&nbsp;to&nbsp;-1&nbsp;to&nbsp;use&nbsp;all&nbsp;available&nbsp;cores&nbsp;(default:&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;force&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;calculation&nbsp;(default:&nbsp;False).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_trees:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;isolation&nbsp;trees.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_samples:&nbsp;(int&nbsp;or&nbsp;None)&nbsp;-&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;samples&nbsp;for&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;trees.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length:&nbsp;(bool)&nbsp;-&nbsp;Indicates&nbsp;whether&nbsp;to&nbsp;use&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;for&nbsp;scoring.<br>
&nbsp;&nbsp;&nbsp;&nbsp;trees:&nbsp;(list)&nbsp;-&nbsp;A&nbsp;list&nbsp;to&nbsp;store&nbsp;the&nbsp;trained&nbsp;isolation&nbsp;trees.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;parallel&nbsp;jobs&nbsp;to&nbsp;run.<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes_:&nbsp;(np.ndarray)&nbsp;-&nbsp;An&nbsp;array&nbsp;representing&nbsp;the&nbsp;classes&nbsp;(0&nbsp;for&nbsp;normal,&nbsp;1&nbsp;for&nbsp;anomaly).</span></dd></dl>

<dl><dt><a name="IsolationForest-__sklearn_is_fitted__"><strong>__sklearn_is_fitted__</strong></a>(self)</dt><dd><span class="code">Checks&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted.</span></dd></dl>

<dl><dt><a name="IsolationForest-anomaly_score"><strong>anomaly_score</strong></a>(self, X)</dt><dd><span class="code">Computes&nbsp;the&nbsp;anomaly&nbsp;scores&nbsp;for&nbsp;given&nbsp;samples.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;samples.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;array:&nbsp;An&nbsp;array&nbsp;of&nbsp;anomaly&nbsp;scores.</span></dd></dl>

<dl><dt><a name="IsolationForest-fit"><strong>fit</strong></a>(self, X, y=None)</dt><dd><span class="code">Fits&nbsp;the&nbsp;isolation&nbsp;forest&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels&nbsp;(not&nbsp;used&nbsp;in&nbsp;this&nbsp;implementation).</span></dd></dl>

<dl><dt><a name="IsolationForest-predict"><strong>predict</strong></a>(self, X, threshold=0.5)</dt><dd><span class="code">Predicts&nbsp;whether&nbsp;samples&nbsp;are&nbsp;anomalies.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;threshold:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;threshold&nbsp;for&nbsp;classifying&nbsp;anomalies&nbsp;(default:&nbsp;0.5).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;array:&nbsp;An&nbsp;array&nbsp;of&nbsp;predictions&nbsp;(1&nbsp;if&nbsp;the&nbsp;sample&nbsp;is&nbsp;an&nbsp;anomaly,&nbsp;0&nbsp;otherwise).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="IsolationTree">class <strong>IsolationTree</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#IsolationTree">IsolationTree</a>(max_depth=10,&nbsp;force_true_length=False)<br>
&nbsp;<br>
<a href="#IsolationTree">IsolationTree</a>&nbsp;is&nbsp;a&nbsp;class&nbsp;that&nbsp;implements&nbsp;an&nbsp;isolation&nbsp;tree,&nbsp;which&nbsp;is&nbsp;a&nbsp;fundamental&nbsp;building&nbsp;block&nbsp;of&nbsp;the&nbsp;Isolation&nbsp;Forest&nbsp;algorithm.<br>
&nbsp;<br>
The&nbsp;Isolation&nbsp;Forest&nbsp;is&nbsp;an&nbsp;unsupervised&nbsp;learning&nbsp;method&nbsp;used&nbsp;for&nbsp;anomaly&nbsp;detection.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree.&nbsp;Default&nbsp;is&nbsp;10.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree&nbsp;(dict):&nbsp;The&nbsp;learned&nbsp;isolation&nbsp;tree&nbsp;structure.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length&nbsp;(bool):&nbsp;If&nbsp;True,&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;is&nbsp;used&nbsp;for&nbsp;scoring<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;the&nbsp;average&nbsp;path&nbsp;length.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationTree-__init__">__init__</a>(max_depth=10,&nbsp;force_true_length=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;<a href="#IsolationTree">IsolationTree</a>&nbsp;with&nbsp;the&nbsp;specified&nbsp;maximum&nbsp;depth&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scoring&nbsp;method.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationTree-fit">fit</a>(X,&nbsp;depth=0):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;the&nbsp;isolation&nbsp;tree&nbsp;to&nbsp;the&nbsp;input&nbsp;data&nbsp;by&nbsp;recursively&nbsp;partitioning<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;data&nbsp;based&nbsp;on&nbsp;randomly&nbsp;selected&nbsp;features&nbsp;and&nbsp;split&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationTree-path_length">path_length</a>(X,&nbsp;tree=None,&nbsp;depth=0):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;the&nbsp;path&nbsp;length&nbsp;for&nbsp;a&nbsp;given&nbsp;sample&nbsp;by&nbsp;traversing&nbsp;the&nbsp;tree<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;structure.&nbsp;The&nbsp;path&nbsp;length&nbsp;is&nbsp;used&nbsp;to&nbsp;determine&nbsp;how&nbsp;isolated&nbsp;a&nbsp;sample&nbsp;is.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="IsolationTree-__init__"><strong>__init__</strong></a>(self, max_depth=10, force_true_length=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;Isolation&nbsp;Forest&nbsp;with&nbsp;specified&nbsp;parameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree&nbsp;(default&nbsp;is&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;If&nbsp;True,&nbsp;use&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;for&nbsp;scoring&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree:&nbsp;(<a href="builtins.html#object">object</a>&nbsp;or&nbsp;None)&nbsp;-&nbsp;The&nbsp;tree&nbsp;structure&nbsp;used&nbsp;in&nbsp;the&nbsp;Isolation&nbsp;Forest&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length:&nbsp;(bool)&nbsp;-&nbsp;Indicates&nbsp;whether&nbsp;to&nbsp;use&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;for&nbsp;scoring.</span></dd></dl>

<dl><dt><a name="IsolationTree-fit"><strong>fit</strong></a>(self, X, depth=0)</dt><dd><span class="code">Fits&nbsp;the&nbsp;isolation&nbsp;tree&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;current&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree&nbsp;(default:&nbsp;0).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;The&nbsp;learned&nbsp;isolation&nbsp;tree.</span></dd></dl>

<dl><dt><a name="IsolationTree-path_length"><strong>path_length</strong></a>(self, X, tree=None, depth=0)</dt><dd><span class="code">Computes&nbsp;the&nbsp;path&nbsp;length&nbsp;for&nbsp;a&nbsp;given&nbsp;sample.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;sample.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;current&nbsp;node&nbsp;of&nbsp;the&nbsp;tree&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;current&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree&nbsp;(default:&nbsp;0).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;int:&nbsp;The&nbsp;path&nbsp;length.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="IsolationUtils">class <strong>IsolationUtils</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Utility&nbsp;functions&nbsp;for&nbsp;the&nbsp;Isolation&nbsp;Forest&nbsp;algorithm.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Static methods defined here:<br>
<dl><dt><a name="IsolationUtils-compute_avg_path_length"><strong>compute_avg_path_length</strong></a>(size)</dt><dd><span class="code">Computes&nbsp;the&nbsp;average&nbsp;path&nbsp;length&nbsp;of&nbsp;unsuccessful&nbsp;searches&nbsp;in&nbsp;a&nbsp;binary&nbsp;search&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;size:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;size&nbsp;of&nbsp;the&nbsp;tree.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;average_path_length:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;average&nbsp;path&nbsp;length.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RandomForestClassifier">class <strong>RandomForestClassifier</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RandomForestClassifier">RandomForestClassifier</a>(forest_size=100,&nbsp;max_depth=10,&nbsp;min_samples_split=2,&nbsp;n_jobs=-1,&nbsp;random_seed=None,&nbsp;X=None,&nbsp;y=None)<br>
&nbsp;<br>
<a href="#RandomForestClassifier">RandomForestClassifier</a>&nbsp;is&nbsp;a&nbsp;custom&nbsp;implementation&nbsp;of&nbsp;a&nbsp;Random&nbsp;Forest&nbsp;classifier.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;trees&nbsp;in&nbsp;the&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;jobs&nbsp;to&nbsp;run&nbsp;in&nbsp;parallel.&nbsp;Defaults&nbsp;to&nbsp;-1&nbsp;(use&nbsp;all&nbsp;available&nbsp;processors).<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int&nbsp;or&nbsp;None):&nbsp;The&nbsp;seed&nbsp;for&nbsp;random&nbsp;number&nbsp;generation.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;trees&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;trained&nbsp;decision&nbsp;trees.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bootstraps&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;bootstrapped&nbsp;indices&nbsp;for&nbsp;out-of-bag&nbsp;(OOB)&nbsp;scoring.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(numpy.ndarray&nbsp;or&nbsp;None):&nbsp;The&nbsp;feature&nbsp;matrix&nbsp;used&nbsp;for&nbsp;training.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(numpy.ndarray&nbsp;or&nbsp;None):&nbsp;The&nbsp;target&nbsp;labels&nbsp;used&nbsp;for&nbsp;training.<br>
&nbsp;&nbsp;&nbsp;&nbsp;accuracy&nbsp;(float):&nbsp;The&nbsp;accuracy&nbsp;of&nbsp;the&nbsp;model&nbsp;after&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;precision&nbsp;(float):&nbsp;The&nbsp;precision&nbsp;of&nbsp;the&nbsp;model&nbsp;after&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;recall&nbsp;(float):&nbsp;The&nbsp;recall&nbsp;of&nbsp;the&nbsp;model&nbsp;after&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;f1_score&nbsp;(float):&nbsp;The&nbsp;F1&nbsp;score&nbsp;of&nbsp;the&nbsp;model&nbsp;after&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;log_loss&nbsp;(float&nbsp;or&nbsp;None):&nbsp;The&nbsp;log&nbsp;loss&nbsp;of&nbsp;the&nbsp;model&nbsp;after&nbsp;fitting&nbsp;(only&nbsp;for&nbsp;binary&nbsp;classification).<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-__init__">__init__</a>(forest_size=100,&nbsp;max_depth=10,&nbsp;n_jobs=-1,&nbsp;random_seed=None,&nbsp;X=None,&nbsp;y=None):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;<a href="#RandomForestClassifier">RandomForestClassifier</a>&nbsp;<a href="builtins.html#object">object</a>&nbsp;with&nbsp;the&nbsp;specified&nbsp;parameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-fit">fit</a>(X=None,&nbsp;y=None,&nbsp;verbose=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;the&nbsp;random&nbsp;forest&nbsp;model&nbsp;to&nbsp;the&nbsp;provided&nbsp;data&nbsp;using&nbsp;parallel&nbsp;processing.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-calculate_metrics">calculate_metrics</a>(y_true,&nbsp;y_pred):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Calculates&nbsp;evaluation&nbsp;metrics&nbsp;(accuracy,&nbsp;precision,&nbsp;recall,&nbsp;F1&nbsp;score,&nbsp;and&nbsp;log&nbsp;loss)&nbsp;for&nbsp;classification.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-predict">predict</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;provided&nbsp;data&nbsp;using&nbsp;the&nbsp;trained&nbsp;random&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-get_stats">get_stats</a>(verbose=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns&nbsp;the&nbsp;evaluation&nbsp;metrics&nbsp;(accuracy,&nbsp;precision,&nbsp;recall,&nbsp;F1&nbsp;score,&nbsp;and&nbsp;log&nbsp;loss)&nbsp;as&nbsp;a&nbsp;dictionary.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RandomForestClassifier-__init__"><strong>__init__</strong></a>(self, forest_size=100, max_depth=10, min_samples_split=2, n_jobs=-1, random_seed=None, X=None, y=None)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;RandomForest&nbsp;<a href="builtins.html#object">object</a>.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-calculate_metrics"><strong>calculate_metrics</strong></a>(self, y_true, y_pred)</dt><dd><span class="code">Calculate&nbsp;evaluation&nbsp;metrics&nbsp;for&nbsp;classification.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-fit"><strong>fit</strong></a>(self, X=None, y=None, sample_weight=None, verbose=False)</dt><dd><span class="code">Fit&nbsp;the&nbsp;random&nbsp;forest&nbsp;with&nbsp;parallel&nbsp;processing.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-get_params"><strong>get_params</strong></a>(self)</dt><dd><span class="code">Get&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;<a href="#RandomForestClassifier">RandomForestClassifier</a>.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-get_stats"><strong>get_stats</strong></a>(self, verbose=False)</dt><dd><span class="code">Return&nbsp;the&nbsp;evaluation&nbsp;metrics.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;provided&nbsp;data.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-predict_proba"><strong>predict_proba</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;class&nbsp;probabilities&nbsp;for&nbsp;the&nbsp;provided&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;A&nbsp;2D&nbsp;array&nbsp;where&nbsp;each&nbsp;row&nbsp;represents&nbsp;the&nbsp;probability&nbsp;distribution<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;over&nbsp;the&nbsp;classes&nbsp;for&nbsp;a&nbsp;record.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RandomForestRegressor">class <strong>RandomForestRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RandomForestRegressor">RandomForestRegressor</a>(forest_size=100,&nbsp;max_depth=10,&nbsp;min_samples_split=2,&nbsp;n_jobs=-1,&nbsp;random_seed=None,&nbsp;X=None,&nbsp;y=None)<br>
&nbsp;<br>
A&nbsp;class&nbsp;representing&nbsp;a&nbsp;Random&nbsp;Forest&nbsp;model&nbsp;for&nbsp;regression.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;trees&nbsp;in&nbsp;the&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;jobs&nbsp;to&nbsp;run&nbsp;in&nbsp;parallel&nbsp;for&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int):&nbsp;Seed&nbsp;for&nbsp;random&nbsp;number&nbsp;generation&nbsp;for&nbsp;reproducibility.<br>
&nbsp;&nbsp;&nbsp;&nbsp;trees&nbsp;(list):&nbsp;List&nbsp;holding&nbsp;the&nbsp;fitted&nbsp;<a href="#RegressorTree">RegressorTree</a>&nbsp;instances.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(numpy.ndarray&nbsp;or&nbsp;None):&nbsp;The&nbsp;feature&nbsp;matrix&nbsp;used&nbsp;for&nbsp;training.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(numpy.ndarray&nbsp;or&nbsp;None):&nbsp;The&nbsp;target&nbsp;labels&nbsp;used&nbsp;for&nbsp;training.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-fit">fit</a>(X=None,&nbsp;y=None,&nbsp;verbose=False):&nbsp;Fits&nbsp;the&nbsp;random&nbsp;forest&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-calculate_metrics">calculate_metrics</a>(y_true,&nbsp;y_pred):&nbsp;Calculates&nbsp;the&nbsp;evaluation&nbsp;metrics.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-predict">predict</a>(X):&nbsp;Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-get_stats">get_stats</a>(verbose=False):&nbsp;Returns&nbsp;the&nbsp;evaluation&nbsp;metrics.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RandomForestRegressor-__init__"><strong>__init__</strong></a>(self, forest_size=100, max_depth=10, min_samples_split=2, n_jobs=-1, random_seed=None, X=None, y=None)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;Random&nbsp;Forest&nbsp;Regressor.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-calculate_metrics"><strong>calculate_metrics</strong></a>(self, y_true, y_pred)</dt><dd><span class="code">Calculate&nbsp;common&nbsp;regression&nbsp;metrics.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like):&nbsp;Predicted&nbsp;target&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics&nbsp;(MSE,&nbsp;R^2,&nbsp;MAE,&nbsp;RMSE,&nbsp;MAPE).</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-fit"><strong>fit</strong></a>(self, X=None, y=None, sample_weight=None, verbose=False)</dt><dd><span class="code">Fit&nbsp;the&nbsp;random&nbsp;forest&nbsp;to&nbsp;the&nbsp;training&nbsp;data&nbsp;X&nbsp;and&nbsp;y.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Training&nbsp;input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(array-like):&nbsp;Training&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight&nbsp;(array-like):&nbsp;Sample&nbsp;weights&nbsp;for&nbsp;each&nbsp;instance&nbsp;in&nbsp;X.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;progress&nbsp;messages.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;The&nbsp;fitted&nbsp;<a href="#RandomForestRegressor">RandomForestRegressor</a>&nbsp;instance.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-get_params"><strong>get_params</strong></a>(self)</dt><dd><span class="code">Get&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;Random&nbsp;Forest&nbsp;Regressor.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-get_stats"><strong>get_stats</strong></a>(self, y_true, y_pred, verbose=False)</dt><dd><span class="code">Calculate&nbsp;and&nbsp;optionally&nbsp;print&nbsp;evaluation&nbsp;metrics.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like):&nbsp;Predicted&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;progress&nbsp;messages&nbsp;(e.g.,&nbsp;residuals).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics&nbsp;(MSE,&nbsp;R^2,&nbsp;MAE,&nbsp;RMSE,&nbsp;MAPE).</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;target&nbsp;values&nbsp;for&nbsp;input&nbsp;features&nbsp;X&nbsp;using&nbsp;the&nbsp;trained&nbsp;random&nbsp;forest.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Predicted&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RegressorTree">class <strong>RegressorTree</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RegressorTree">RegressorTree</a>(max_depth=5,&nbsp;min_samples_split=2)<br>
&nbsp;<br>
A&nbsp;class&nbsp;representing&nbsp;a&nbsp;decision&nbsp;tree&nbsp;for&nbsp;regression.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_features:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;features&nbsp;in&nbsp;the&nbsp;dataset.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RegressorTree-fit">fit</a>(X,&nbsp;y,&nbsp;verbose=False):&nbsp;Fits&nbsp;the&nbsp;decision&nbsp;tree&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RegressorTree-predict">predict</a>(X):&nbsp;Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_traverse_tree(x,&nbsp;node):&nbsp;Traverses&nbsp;the&nbsp;decision&nbsp;tree&nbsp;for&nbsp;a&nbsp;single&nbsp;sample&nbsp;x.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_leran_recursive(indices,&nbsp;depth):&nbsp;Recursive&nbsp;helper&nbsp;function&nbsp;for&nbsp;learning.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RegressorTree-__init__"><strong>__init__</strong></a>(self, max_depth=5, min_samples_split=2)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node.</span></dd></dl>

<dl><dt><a name="RegressorTree-fit"><strong>fit</strong></a>(self, X, y, sample_weight=None, verbose=False)</dt><dd><span class="code">Fit&nbsp;the&nbsp;decision&nbsp;tree&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;(bool)&nbsp;-&nbsp;If&nbsp;True,&nbsp;print&nbsp;detailed&nbsp;logs&nbsp;during&nbsp;fitting.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;The&nbsp;learned&nbsp;decision&nbsp;tree.</span></dd></dl>

<dl><dt><a name="RegressorTree-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;the&nbsp;target&nbsp;value&nbsp;for&nbsp;a&nbsp;record&nbsp;or&nbsp;batch&nbsp;of&nbsp;records&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;The&nbsp;predicted&nbsp;target&nbsp;values.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RegressorTreeUtility">class <strong>RegressorTreeUtility</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RegressorTreeUtility">RegressorTreeUtility</a>(X,&nbsp;y,&nbsp;min_samples_split,&nbsp;n_features)<br>
&nbsp;<br>
Utility&nbsp;class&nbsp;containing&nbsp;helper&nbsp;functions&nbsp;for&nbsp;building&nbsp;the&nbsp;Regressor&nbsp;Tree.<br>
&nbsp;<br>
Handles&nbsp;variance&nbsp;calculation,&nbsp;leaf&nbsp;value&nbsp;calculation,&nbsp;and&nbsp;finding&nbsp;the&nbsp;best&nbsp;split.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RegressorTreeUtility-__init__"><strong>__init__</strong></a>(self, X, y, min_samples_split, n_features)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;utility&nbsp;class&nbsp;with&nbsp;references&nbsp;to&nbsp;data&nbsp;and&nbsp;parameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(np.ndarray):&nbsp;Reference&nbsp;to&nbsp;the&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(np.ndarray):&nbsp;Reference&nbsp;to&nbsp;the&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;Minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_features&nbsp;(int):&nbsp;Total&nbsp;number&nbsp;of&nbsp;features&nbsp;in&nbsp;X.</span></dd></dl>

<dl><dt><a name="RegressorTreeUtility-best_split"><strong>best_split</strong></a>(self, indices, sample_weight=None)</dt><dd><span class="code">Finds&nbsp;the&nbsp;best&nbsp;split&nbsp;for&nbsp;the&nbsp;data&nbsp;subset&nbsp;defined&nbsp;by&nbsp;indices.</span></dd></dl>

<dl><dt><a name="RegressorTreeUtility-calculate_leaf_value"><strong>calculate_leaf_value</strong></a>(self, indices, sample_weight=None)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;weighted&nbsp;mean&nbsp;value&nbsp;for&nbsp;a&nbsp;leaf&nbsp;node.</span></dd></dl>

<dl><dt><a name="RegressorTreeUtility-calculate_variance"><strong>calculate_variance</strong></a>(self, indices, sample_weight=None)</dt><dd><span class="code">Calculate&nbsp;weighted&nbsp;variance&nbsp;for&nbsp;the&nbsp;subset&nbsp;defined&nbsp;by&nbsp;indices.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table></td></tr></table><p>
<table class="section">
<tr class="decor data-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Data</strong></td></tr>

<tr><td class="decor data-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><strong>__all__</strong> = ['ClassifierTreeUtility', 'ClassifierTree', 'RegressorTreeUtility', 'RegressorTree', 'RandomForestClassifier', 'RandomForestRegressor', 'GradientBoostedClassifier', 'GradientBoostedRegressor', 'IsolationForest', 'IsolationTree', 'IsolationUtils', 'AdaBoostClassifier', 'AdaBoostRegressor']</td></tr></table>
</body></html>
