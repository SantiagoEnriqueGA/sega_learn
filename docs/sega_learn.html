<!DOCTYPE html>
<html lang="en">
<head>
<style>
body { background-color: #f0f0f8; }
table.heading tr { background-color: #7799ee; }
.decor { color: #ffffff; }
.title-decor { background-color: #ffc8d8; color: #000000; }
.pkg-content-decor { background-color: #aa55cc; }
.index-decor { background-color: #ee77aa; }
.functions-decor { background-color: #eeaa77; }
.data-decor { background-color: #55aa55; }
.author-decor { background-color: #7799ee; }
.credits-decor { background-color: #7799ee; }
.error-decor { background-color: #bb0000; }
.grey { color: #909090; }
.white { color: #ffffff; }
.repr { color: #c040c0; }
table.heading tr td.title, table.heading tr td.extra { vertical-align: bottom; }
table.heading tr td.extra { text-align: right; }
.heading-text { font-family: helvetica, arial; }
.bigsection { font-size: larger; }
.title { font-size: x-large; }
.code { font-family: monospace; }
table { width: 100%; border-spacing: 0; border-collapse: collapse; border: 0; }
td { padding: 2; }
td.section-title, td.multicolumn { vertical-align: bottom; }
td.multicolumn { width: 25%; }
td.singlecolumn { width: 100%; }
</style>
<meta charset="utf-8">
<title>Python: package sega_learn</title>
</head><body>

<table class="heading">
<tr class="heading-text decor">
<td class="title">&nbsp;<br><strong class="title">sega_learn</strong></td>
</tr></table>
    <p></p>
<p>
<table class="section">
<tr class="decor pkg-content-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Package Contents</strong></td></tr>

<tr><td class="decor pkg-content-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><table><tr><td class="multicolumn"><a href="sega_learn.auto.html"><strong>auto</strong>&nbsp;(package)</a><br>
<a href="sega_learn.clustering.html"><strong>clustering</strong>&nbsp;(package)</a><br>
<a href="sega_learn.linear_models.html"><strong>linear_models</strong>&nbsp;(package)</a><br>
</td><td class="multicolumn"><a href="sega_learn.nearest_neighbors.html"><strong>nearest_neighbors</strong>&nbsp;(package)</a><br>
<a href="sega_learn.neural_networks.html"><strong>neural_networks</strong>&nbsp;(package)</a><br>
<a href="sega_learn.neural_networks_cupy_dev.html"><strong>neural_networks_cupy_dev</strong>&nbsp;(package)</a><br>
</td><td class="multicolumn"><a href="sega_learn.neural_networks_numba_dev.html"><strong>neural_networks_numba_dev</strong>&nbsp;(package)</a><br>
<a href="sega_learn.setup.html">setup</a><br>
<a href="sega_learn.svm.html"><strong>svm</strong>&nbsp;(package)</a><br>
</td><td class="multicolumn"><a href="sega_learn.trees.html"><strong>trees</strong>&nbsp;(package)</a><br>
<a href="sega_learn.utils.html"><strong>utils</strong>&nbsp;(package)</a><br>
</td></tr></table></td></tr></table><p>
<table class="section">
<tr class="decor index-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Classes</strong></td></tr>

<tr><td class="decor index-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><dl>
<dt class="heading-text"><a href="builtins.html#object">builtins.object</a>
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.auto.classifier.html#AutoClassifier">sega_learn.auto.classifier.AutoClassifier</a>
</dt><dt class="heading-text"><a href="sega_learn.auto.regressor.html#AutoRegressor">sega_learn.auto.regressor.AutoRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.clustering.clustering.html#DBSCAN">sega_learn.clustering.clustering.DBSCAN</a>
</dt><dt class="heading-text"><a href="sega_learn.clustering.clustering.html#KMeans">sega_learn.clustering.clustering.KMeans</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.classifiers.html#LinearDiscriminantAnalysis">sega_learn.linear_models.classifiers.LinearDiscriminantAnalysis</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.classifiers.html#LogisticRegression">sega_learn.linear_models.classifiers.LogisticRegression</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.classifiers.html#Perceptron">sega_learn.linear_models.classifiers.Perceptron</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.classifiers.html#QuadraticDiscriminantAnalysis">sega_learn.linear_models.classifiers.QuadraticDiscriminantAnalysis</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.regressors.html#Bayesian">sega_learn.linear_models.regressors.Bayesian</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.regressors.html#Lasso">sega_learn.linear_models.regressors.Lasso</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.regressors.html#OrdinaryLeastSquares">sega_learn.linear_models.regressors.OrdinaryLeastSquares</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.regressors.html#PassiveAggressiveRegressor">sega_learn.linear_models.regressors.PassiveAggressiveRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.regressors.html#RANSAC">sega_learn.linear_models.regressors.RANSAC</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.regressors.html#Ridge">sega_learn.linear_models.regressors.Ridge</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.activations.html#Activation">sega_learn.neural_networks.activations.Activation</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.layers.html#ConvLayer">sega_learn.neural_networks.layers.ConvLayer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.layers.html#DenseLayer">sega_learn.neural_networks.layers.DenseLayer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.layers.html#FlattenLayer">sega_learn.neural_networks.layers.FlattenLayer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.layers.html#RNNLayer">sega_learn.neural_networks.layers.RNNLayer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.layers_jit.html#JITRNNLayer">sega_learn.neural_networks.layers_jit.JITRNNLayer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss.html#BCEWithLogitsLoss">sega_learn.neural_networks.loss.BCEWithLogitsLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss.html#CrossEntropyLoss">sega_learn.neural_networks.loss.CrossEntropyLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss.html#HuberLoss">sega_learn.neural_networks.loss.HuberLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss.html#MeanAbsoluteErrorLoss">sega_learn.neural_networks.loss.MeanAbsoluteErrorLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss.html#MeanSquaredErrorLoss">sega_learn.neural_networks.loss.MeanSquaredErrorLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss_jit.html#JITBCEWithLogitsLoss">sega_learn.neural_networks.loss_jit.JITBCEWithLogitsLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss_jit.html#JITCrossEntropyLoss">sega_learn.neural_networks.loss_jit.JITCrossEntropyLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss_jit.html#JITHuberLoss">sega_learn.neural_networks.loss_jit.JITHuberLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss_jit.html#JITMeanAbsoluteErrorLoss">sega_learn.neural_networks.loss_jit.JITMeanAbsoluteErrorLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss_jit.html#JITMeanSquaredErrorLoss">sega_learn.neural_networks.loss_jit.JITMeanSquaredErrorLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.neuralNetworkBase.html#NeuralNetworkBase">sega_learn.neural_networks.neuralNetworkBase.NeuralNetworkBase</a>
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.neural_networks.neuralNetworkBaseBackend.html#BaseBackendNeuralNetwork">sega_learn.neural_networks.neuralNetworkBaseBackend.BaseBackendNeuralNetwork</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.neuralNetworkNumbaBackend.html#NumbaBackendNeuralNetwork">sega_learn.neural_networks.neuralNetworkNumbaBackend.NumbaBackendNeuralNetwork</a>
</dt></dl>
</dd>
<dt class="heading-text"><a href="sega_learn.neural_networks.optimizers.html#AdadeltaOptimizer">sega_learn.neural_networks.optimizers.AdadeltaOptimizer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.optimizers.html#AdamOptimizer">sega_learn.neural_networks.optimizers.AdamOptimizer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.optimizers.html#SGDOptimizer">sega_learn.neural_networks.optimizers.SGDOptimizer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.schedulers.html#lr_scheduler_exp">sega_learn.neural_networks.schedulers.lr_scheduler_exp</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.schedulers.html#lr_scheduler_plateau">sega_learn.neural_networks.schedulers.lr_scheduler_plateau</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.schedulers.html#lr_scheduler_step">sega_learn.neural_networks.schedulers.lr_scheduler_step</a>
</dt><dt class="heading-text"><a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.svm.generalizedSVM.html#GeneralizedSVC">sega_learn.svm.generalizedSVM.GeneralizedSVC</a>
</dt><dt class="heading-text"><a href="sega_learn.svm.generalizedSVM.html#GeneralizedSVR">sega_learn.svm.generalizedSVM.GeneralizedSVR</a>
</dt><dt class="heading-text"><a href="sega_learn.svm.linerarSVM.html#LinearSVC">sega_learn.svm.linerarSVM.LinearSVC</a>
</dt><dt class="heading-text"><a href="sega_learn.svm.linerarSVM.html#LinearSVR">sega_learn.svm.linerarSVM.LinearSVR</a>
</dt><dt class="heading-text"><a href="sega_learn.svm.oneClassSVM.html#OneClassSVM">sega_learn.svm.oneClassSVM.OneClassSVM</a>
</dt></dl>
</dd>
<dt class="heading-text"><a href="sega_learn.trees.adaBoostClassifier.html#AdaBoostClassifier">sega_learn.trees.adaBoostClassifier.AdaBoostClassifier</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.adaBoostRegressor.html#AdaBoostRegressor">sega_learn.trees.adaBoostRegressor.AdaBoostRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.gradientBoostedClassifier.html#GradientBoostedClassifier">sega_learn.trees.gradientBoostedClassifier.GradientBoostedClassifier</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.gradientBoostedRegressor.html#GradientBoostedRegressor">sega_learn.trees.gradientBoostedRegressor.GradientBoostedRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.isolationForest.html#IsolationForest">sega_learn.trees.isolationForest.IsolationForest</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.isolationForest.html#IsolationTree">sega_learn.trees.isolationForest.IsolationTree</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.isolationForest.html#IsolationUtils">sega_learn.trees.isolationForest.IsolationUtils</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.randomForestClassifier.html#RandomForestClassifier">sega_learn.trees.randomForestClassifier.RandomForestClassifier</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.randomForestRegressor.html#RandomForestRegressor">sega_learn.trees.randomForestRegressor.RandomForestRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeClassifier.html#ClassifierTree">sega_learn.trees.treeClassifier.ClassifierTree</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeClassifier.html#ClassifierTreeUtility">sega_learn.trees.treeClassifier.ClassifierTreeUtility</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeRegressor.html#RegressorTree">sega_learn.trees.treeRegressor.RegressorTree</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeRegressor.html#RegressorTreeUtility">sega_learn.trees.treeRegressor.RegressorTreeUtility</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.dataAugmentation.html#Augmenter">sega_learn.utils.dataAugmentation.Augmenter</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.dataAugmentation.html#RandomOverSampler">sega_learn.utils.dataAugmentation.RandomOverSampler</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.dataAugmentation.html#RandomUnderSampler">sega_learn.utils.dataAugmentation.RandomUnderSampler</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.dataAugmentation.html#SMOTE">sega_learn.utils.dataAugmentation.SMOTE</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.dataPrep.html#DataPrep">sega_learn.utils.dataPrep.DataPrep</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.dataPreprocessing.html#Scaler">sega_learn.utils.dataPreprocessing.Scaler</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.decomposition.html#PCA">sega_learn.utils.decomposition.PCA</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.decomposition.html#SVD">sega_learn.utils.decomposition.SVD</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.metrics.html#Metrics">sega_learn.utils.metrics.Metrics</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.modelSelection.html#GridSearchCV">sega_learn.utils.modelSelection.GridSearchCV</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.modelSelection.html#ModelSelectionUtility">sega_learn.utils.modelSelection.ModelSelectionUtility</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.modelSelection.html#RandomSearchCV">sega_learn.utils.modelSelection.RandomSearchCV</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.polynomialTransform.html#PolynomialTransform">sega_learn.utils.polynomialTransform.PolynomialTransform</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.voting.html#VotingClassifier">sega_learn.utils.voting.VotingClassifier</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.voting.html#VotingRegressor">sega_learn.utils.voting.VotingRegressor</a>
</dt></dl>
</dd>
<dt class="heading-text"><a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">sega_learn.nearest_neighbors.base.KNeighborsBase</a>(<a href="abc.html#ABC">abc.ABC</a>)
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.nearest_neighbors.knn_classifier.html#KNeighborsClassifier">sega_learn.nearest_neighbors.knn_classifier.KNeighborsClassifier</a>
</dt><dt class="heading-text"><a href="sega_learn.nearest_neighbors.knn_regressor.html#KNeighborsRegressor">sega_learn.nearest_neighbors.knn_regressor.KNeighborsRegressor</a>
</dt></dl>
</dd>
<dt class="heading-text">sega_learn.neural_networks.layers_jit.JITConvLayer(<a href="builtins.html#object">builtins.object</a>)
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.neural_networks.layers_jit.html#JITConvLayer">sega_learn.neural_networks.layers_jit.JITConvLayer</a>
</dt></dl>
</dd>
<dt class="heading-text">sega_learn.neural_networks.layers_jit.JITDenseLayer(<a href="builtins.html#object">builtins.object</a>)
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.neural_networks.layers_jit.html#JITDenseLayer">sega_learn.neural_networks.layers_jit.JITDenseLayer</a>
</dt></dl>
</dd>
<dt class="heading-text">sega_learn.neural_networks.layers_jit.JITFlattenLayer(<a href="builtins.html#object">builtins.object</a>)
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.neural_networks.layers_jit.html#JITFlattenLayer">sega_learn.neural_networks.layers_jit.JITFlattenLayer</a>
</dt></dl>
</dd>
<dt class="heading-text">sega_learn.neural_networks.optimizers_jit.JITAdadeltaOptimizer(<a href="builtins.html#object">builtins.object</a>)
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.neural_networks.optimizers_jit.html#JITAdadeltaOptimizer">sega_learn.neural_networks.optimizers_jit.JITAdadeltaOptimizer</a>
</dt></dl>
</dd>
<dt class="heading-text">sega_learn.neural_networks.optimizers_jit.JITAdamOptimizer(<a href="builtins.html#object">builtins.object</a>)
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.neural_networks.optimizers_jit.html#JITAdamOptimizer">sega_learn.neural_networks.optimizers_jit.JITAdamOptimizer</a>
</dt></dl>
</dd>
<dt class="heading-text">sega_learn.neural_networks.optimizers_jit.JITSGDOptimizer(<a href="builtins.html#object">builtins.object</a>)
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.neural_networks.optimizers_jit.html#JITSGDOptimizer">sega_learn.neural_networks.optimizers_jit.JITSGDOptimizer</a>
</dt></dl>
</dd>
</dl>
 <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Activation">class <strong>Activation</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">This&nbsp;class&nbsp;contains&nbsp;various&nbsp;activation&nbsp;functions&nbsp;and&nbsp;their&nbsp;corresponding&nbsp;derivatives&nbsp;for&nbsp;use&nbsp;in&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;relu:&nbsp;Rectified&nbsp;Linear&nbsp;Unit&nbsp;activation&nbsp;function.&nbsp;Returns&nbsp;the&nbsp;input&nbsp;directly&nbsp;if&nbsp;it's&nbsp;positive,&nbsp;otherwise&nbsp;returns&nbsp;0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;leaky_relu:&nbsp;Leaky&nbsp;ReLU&nbsp;activation&nbsp;function.&nbsp;A&nbsp;variant&nbsp;of&nbsp;ReLU&nbsp;that&nbsp;allows&nbsp;a&nbsp;small&nbsp;gradient&nbsp;when&nbsp;the&nbsp;input&nbsp;is&nbsp;negative.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tanh:&nbsp;Hyperbolic&nbsp;tangent&nbsp;activation&nbsp;function.&nbsp;Maps&nbsp;input&nbsp;to&nbsp;range&nbsp;[-1,&nbsp;1].&nbsp;Commonly&nbsp;used&nbsp;for&nbsp;normalized&nbsp;input.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sigmoid:&nbsp;Sigmoid&nbsp;activation&nbsp;function.&nbsp;Maps&nbsp;input&nbsp;to&nbsp;range&nbsp;[0,&nbsp;1].&nbsp;Commonly&nbsp;used&nbsp;for&nbsp;binary&nbsp;classification.<br>
&nbsp;&nbsp;&nbsp;&nbsp;softmax:&nbsp;Softmax&nbsp;activation&nbsp;function.&nbsp;Maps&nbsp;input&nbsp;into&nbsp;a&nbsp;probability&nbsp;distribution&nbsp;over&nbsp;multiple&nbsp;classes.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Static methods defined here:<br>
<dl><dt><a name="Activation-leaky_relu"><strong>leaky_relu</strong></a>(z, alpha=0.01)</dt><dd><span class="code">Leaky&nbsp;ReLU&nbsp;activation&nbsp;function:&nbsp;f(z)&nbsp;=&nbsp;z&nbsp;if&nbsp;z&nbsp;&gt;&nbsp;0,&nbsp;else&nbsp;alpha&nbsp;*&nbsp;z.<br>
&nbsp;<br>
Allows&nbsp;a&nbsp;small,&nbsp;non-zero&nbsp;gradient&nbsp;when&nbsp;the&nbsp;input&nbsp;is&nbsp;negative&nbsp;to&nbsp;address&nbsp;the&nbsp;dying&nbsp;ReLU&nbsp;problem.</span></dd></dl>

<dl><dt><a name="Activation-leaky_relu_derivative"><strong>leaky_relu_derivative</strong></a>(z, alpha=0.01)</dt><dd><span class="code">Derivative&nbsp;of&nbsp;the&nbsp;Leaky&nbsp;ReLU&nbsp;function:&nbsp;f'(z)&nbsp;=&nbsp;1&nbsp;if&nbsp;z&nbsp;&gt;&nbsp;0,&nbsp;else&nbsp;alpha.<br>
&nbsp;<br>
Returns&nbsp;1&nbsp;for&nbsp;positive&nbsp;input,&nbsp;and&nbsp;alpha&nbsp;for&nbsp;negative&nbsp;input.</span></dd></dl>

<dl><dt><a name="Activation-relu"><strong>relu</strong></a>(z)</dt><dd><span class="code">ReLU&nbsp;(Rectified&nbsp;Linear&nbsp;Unit)&nbsp;activation&nbsp;function:&nbsp;f(z)&nbsp;=&nbsp;max(0,&nbsp;z).<br>
&nbsp;<br>
Returns&nbsp;the&nbsp;input&nbsp;directly&nbsp;if&nbsp;it's&nbsp;positive,&nbsp;otherwise&nbsp;returns&nbsp;0.</span></dd></dl>

<dl><dt><a name="Activation-relu_derivative"><strong>relu_derivative</strong></a>(z)</dt><dd><span class="code">Derivative&nbsp;of&nbsp;the&nbsp;ReLU&nbsp;function:&nbsp;f'(z)&nbsp;=&nbsp;1&nbsp;if&nbsp;z&nbsp;&gt;&nbsp;0,&nbsp;else&nbsp;0.<br>
&nbsp;<br>
Returns&nbsp;1&nbsp;for&nbsp;positive&nbsp;input,&nbsp;and&nbsp;0&nbsp;for&nbsp;negative&nbsp;input.</span></dd></dl>

<dl><dt><a name="Activation-sigmoid"><strong>sigmoid</strong></a>(z)</dt><dd><span class="code">Sigmoid&nbsp;activation&nbsp;function:&nbsp;f(z)&nbsp;=&nbsp;1&nbsp;/&nbsp;(1&nbsp;+&nbsp;exp(-z)).<br>
&nbsp;<br>
Maps&nbsp;input&nbsp;to&nbsp;the&nbsp;range&nbsp;[0,&nbsp;1],&nbsp;commonly&nbsp;used&nbsp;for&nbsp;binary&nbsp;classification.</span></dd></dl>

<dl><dt><a name="Activation-sigmoid_derivative"><strong>sigmoid_derivative</strong></a>(z)</dt><dd><span class="code">Derivative&nbsp;of&nbsp;the&nbsp;sigmoid&nbsp;function:&nbsp;f'(z)&nbsp;=&nbsp;<a href="#Activation-sigmoid">sigmoid</a>(z)&nbsp;*&nbsp;(1&nbsp;-&nbsp;<a href="#Activation-sigmoid">sigmoid</a>(z)).<br>
&nbsp;<br>
Used&nbsp;for&nbsp;backpropagation&nbsp;through&nbsp;the&nbsp;sigmoid&nbsp;activation.</span></dd></dl>

<dl><dt><a name="Activation-softmax"><strong>softmax</strong></a>(z)</dt><dd><span class="code">Softmax&nbsp;activation&nbsp;function:&nbsp;f(z)_i&nbsp;=&nbsp;exp(z_i)&nbsp;/&nbsp;sum(exp(z_j))&nbsp;for&nbsp;all&nbsp;j.<br>
&nbsp;<br>
Maps&nbsp;input&nbsp;into&nbsp;a&nbsp;probability&nbsp;distribution&nbsp;over&nbsp;multiple&nbsp;classes.&nbsp;Used&nbsp;for&nbsp;multiclass&nbsp;classification.</span></dd></dl>

<dl><dt><a name="Activation-tanh"><strong>tanh</strong></a>(z)</dt><dd><span class="code">Hyperbolic&nbsp;tangent&nbsp;(tanh)&nbsp;activation&nbsp;function:&nbsp;f(z)&nbsp;=&nbsp;(exp(z)&nbsp;-&nbsp;exp(-z))&nbsp;/&nbsp;(exp(z)&nbsp;+&nbsp;exp(-z)).<br>
&nbsp;<br>
Maps&nbsp;input&nbsp;to&nbsp;the&nbsp;range&nbsp;[-1,&nbsp;1],&nbsp;typically&nbsp;used&nbsp;for&nbsp;normalized&nbsp;input.</span></dd></dl>

<dl><dt><a name="Activation-tanh_derivative"><strong>tanh_derivative</strong></a>(z)</dt><dd><span class="code">Derivative&nbsp;of&nbsp;the&nbsp;tanh&nbsp;function:&nbsp;f'(z)&nbsp;=&nbsp;1&nbsp;-&nbsp;<a href="#Activation-tanh">tanh</a>(z)^2.<br>
&nbsp;<br>
Used&nbsp;for&nbsp;backpropagation&nbsp;through&nbsp;the&nbsp;tanh&nbsp;activation.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="AdaBoostClassifier">class <strong>AdaBoostClassifier</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#AdaBoostClassifier">AdaBoostClassifier</a>(base_estimator=None,&nbsp;n_estimators=50,&nbsp;learning_rate=1.0,&nbsp;random_state=None,&nbsp;max_depth=3,&nbsp;min_samples_split=2)<br>
&nbsp;<br>
AdaBoost&nbsp;classifier.<br>
&nbsp;<br>
Builds&nbsp;an&nbsp;additive&nbsp;model&nbsp;by&nbsp;sequentially&nbsp;fitting&nbsp;weak&nbsp;classifiers&nbsp;(default:&nbsp;decision&nbsp;stumps)<br>
on&nbsp;modified&nbsp;versions&nbsp;of&nbsp;the&nbsp;data.&nbsp;Each&nbsp;subsequent&nbsp;classifier&nbsp;focuses&nbsp;more&nbsp;on&nbsp;samples<br>
that&nbsp;were&nbsp;misclassified&nbsp;by&nbsp;the&nbsp;previous&nbsp;ensemble.<br>
&nbsp;<br>
Uses&nbsp;the&nbsp;SAMME&nbsp;algorithm&nbsp;which&nbsp;supports&nbsp;multi-class&nbsp;classification.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;base_estimator_&nbsp;(<a href="builtins.html#object">object</a>):&nbsp;The&nbsp;base&nbsp;estimator&nbsp;template&nbsp;used&nbsp;for&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;estimators&nbsp;at&nbsp;which&nbsp;boosting&nbsp;is&nbsp;terminated.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Weight&nbsp;applied&nbsp;to&nbsp;each&nbsp;classifier's&nbsp;contribution.<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimators_&nbsp;(list):&nbsp;The&nbsp;collection&nbsp;of&nbsp;fitted&nbsp;base&nbsp;estimators.<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimator_weights_&nbsp;(np.ndarray):&nbsp;Weights&nbsp;for&nbsp;each&nbsp;estimator.<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimator_errors_&nbsp;(np.ndarray):&nbsp;Classification&nbsp;error&nbsp;for&nbsp;each&nbsp;estimator.<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes_&nbsp;(np.ndarray):&nbsp;The&nbsp;class&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_classes_&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;classes.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="AdaBoostClassifier-__init__"><strong>__init__</strong></a>(self, base_estimator=None, n_estimators=50, learning_rate=1.0, random_state=None, max_depth=3, min_samples_split=2)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#AdaBoostClassifier">AdaBoostClassifier</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;base_estimator&nbsp;(<a href="builtins.html#object">object</a>,&nbsp;optional):&nbsp;The&nbsp;base&nbsp;estimator&nbsp;from&nbsp;which&nbsp;the&nbsp;boosted&nbsp;ensemble&nbsp;is&nbsp;built.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Support&nbsp;for&nbsp;sample&nbsp;weighting&nbsp;is&nbsp;required.&nbsp;If&nbsp;None,&nbsp;then<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;base&nbsp;estimator&nbsp;is&nbsp;DecisionTreeClassifier(max_depth=1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;estimators&nbsp;at&nbsp;which&nbsp;boosting&nbsp;is&nbsp;terminated.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In&nbsp;case&nbsp;of&nbsp;perfect&nbsp;fit,&nbsp;the&nbsp;learning&nbsp;procedure&nbsp;is&nbsp;stopped&nbsp;early.&nbsp;Defaults&nbsp;to&nbsp;50.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;Weight&nbsp;applied&nbsp;to&nbsp;each&nbsp;classifier's&nbsp;contribution.&nbsp;Defaults&nbsp;to&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int,&nbsp;optional):&nbsp;Controls&nbsp;the&nbsp;random&nbsp;seed&nbsp;given&nbsp;to&nbsp;the&nbsp;base&nbsp;estimator&nbsp;at&nbsp;each&nbsp;boosting&nbsp;iteration.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;base&nbsp;estimator.&nbsp;Defaults&nbsp;to&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;when&nbsp;using&nbsp;the&nbsp;default&nbsp;`<a href="#ClassifierTree">ClassifierTree</a>`&nbsp;base&nbsp;estimator.&nbsp;Defaults&nbsp;to&nbsp;2.</span></dd></dl>

<dl><dt><a name="AdaBoostClassifier-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;the&nbsp;decision&nbsp;function&nbsp;of&nbsp;X.</span></dd></dl>

<dl><dt><a name="AdaBoostClassifier-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Build&nbsp;a&nbsp;boosted&nbsp;classifier&nbsp;from&nbsp;the&nbsp;training&nbsp;set&nbsp;(X,&nbsp;y).</span></dd></dl>

<dl><dt><a name="AdaBoostClassifier-get_stats"><strong>get_stats</strong></a>(self, y_true, X=None, y_pred=None, verbose=False)</dt><dd><span class="code">Calculate&nbsp;and&nbsp;optionally&nbsp;print&nbsp;evaluation&nbsp;metrics.&nbsp;Requires&nbsp;either&nbsp;X&nbsp;or&nbsp;y_pred.</span></dd></dl>

<dl><dt><a name="AdaBoostClassifier-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;classes&nbsp;for&nbsp;X.</span></dd></dl>

<dl><dt><a name="AdaBoostClassifier-predict_proba"><strong>predict_proba</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;class&nbsp;probabilities&nbsp;for&nbsp;X.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="AdaBoostRegressor">class <strong>AdaBoostRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#AdaBoostRegressor">AdaBoostRegressor</a>(base_estimator=None,&nbsp;n_estimators=50,&nbsp;learning_rate=1.0,&nbsp;loss='linear',&nbsp;random_state=None,&nbsp;max_depth=3,&nbsp;min_samples_split=2)<br>
&nbsp;<br>
AdaBoost&nbsp;regressor.<br>
&nbsp;<br>
Builds&nbsp;an&nbsp;additive&nbsp;model&nbsp;by&nbsp;sequentially&nbsp;fitting&nbsp;weak&nbsp;regressors&nbsp;(default:&nbsp;decision&nbsp;trees)<br>
on&nbsp;modified&nbsp;versions&nbsp;of&nbsp;the&nbsp;data.&nbsp;The&nbsp;weights&nbsp;of&nbsp;instances&nbsp;are&nbsp;adjusted&nbsp;at&nbsp;each&nbsp;iteration<br>
so&nbsp;that&nbsp;subsequent&nbsp;regressors&nbsp;focus&nbsp;more&nbsp;on&nbsp;instances&nbsp;with&nbsp;larger&nbsp;errors.<br>
&nbsp;<br>
Uses&nbsp;the&nbsp;AdaBoost.R2&nbsp;algorithm.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;base_estimator_&nbsp;(<a href="builtins.html#object">object</a>):&nbsp;The&nbsp;base&nbsp;estimator&nbsp;template&nbsp;used&nbsp;for&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;estimators&nbsp;at&nbsp;which&nbsp;boosting&nbsp;is&nbsp;terminated.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Contribution&nbsp;of&nbsp;each&nbsp;regressor&nbsp;to&nbsp;the&nbsp;final&nbsp;prediction.<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss&nbsp;(str):&nbsp;The&nbsp;loss&nbsp;function&nbsp;to&nbsp;use&nbsp;when&nbsp;updating&nbsp;the&nbsp;weights&nbsp;('linear',&nbsp;'square',&nbsp;'exponential').<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimators_&nbsp;(list):&nbsp;The&nbsp;collection&nbsp;of&nbsp;fitted&nbsp;base&nbsp;estimators.<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimator_weights_&nbsp;(np.ndarray):&nbsp;Weights&nbsp;for&nbsp;each&nbsp;estimator&nbsp;(alpha&nbsp;values,&nbsp;specifically&nbsp;log(1/beta)).<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimator_errors_&nbsp;(np.ndarray):&nbsp;Loss&nbsp;value&nbsp;for&nbsp;each&nbsp;estimator&nbsp;on&nbsp;the&nbsp;weighted&nbsp;training&nbsp;data.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="AdaBoostRegressor-__init__"><strong>__init__</strong></a>(self, base_estimator=None, n_estimators=50, learning_rate=1.0, loss='linear', random_state=None, max_depth=3, min_samples_split=2)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#AdaBoostRegressor">AdaBoostRegressor</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;base_estimator&nbsp;(<a href="builtins.html#object">object</a>,&nbsp;optional):&nbsp;The&nbsp;base&nbsp;estimator&nbsp;from&nbsp;which&nbsp;the&nbsp;boosted&nbsp;ensemble&nbsp;is&nbsp;built.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Support&nbsp;for&nbsp;sample&nbsp;weighting&nbsp;is&nbsp;required.&nbsp;If&nbsp;None,&nbsp;then<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;base&nbsp;estimator&nbsp;is&nbsp;DecisionTreeRegressor(max_depth=3).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;estimators.&nbsp;Defaults&nbsp;to&nbsp;50.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;Shrinks&nbsp;the&nbsp;contribution&nbsp;of&nbsp;each&nbsp;regressor&nbsp;by&nbsp;learning_rate.&nbsp;Defaults&nbsp;to&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss&nbsp;(str,&nbsp;optional):&nbsp;The&nbsp;loss&nbsp;function&nbsp;to&nbsp;use&nbsp;when&nbsp;updating&nbsp;sample&nbsp;weights&nbsp;('linear',&nbsp;'square',&nbsp;'exponential').<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;'linear'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int,&nbsp;optional):&nbsp;Controls&nbsp;the&nbsp;random&nbsp;seed.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int,&nbsp;optional):&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;base&nbsp;estimator.&nbsp;Defaults&nbsp;to&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int,&nbsp;optional):&nbsp;Minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node.&nbsp;Defaults&nbsp;to&nbsp;2.</span></dd></dl>

<dl><dt><a name="AdaBoostRegressor-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Build&nbsp;a&nbsp;boosted&nbsp;regressor&nbsp;from&nbsp;the&nbsp;training&nbsp;set&nbsp;(X,&nbsp;y).</span></dd></dl>

<dl><dt><a name="AdaBoostRegressor-get_stats"><strong>get_stats</strong></a>(self, y_true, X=None, y_pred=None, verbose=False)</dt><dd><span class="code">Calculate&nbsp;and&nbsp;optionally&nbsp;print&nbsp;evaluation&nbsp;metrics.&nbsp;Requires&nbsp;either&nbsp;X&nbsp;or&nbsp;y_pred.</span></dd></dl>

<dl><dt><a name="AdaBoostRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;regression&nbsp;target&nbsp;for&nbsp;X.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="AdadeltaOptimizer">class <strong>AdadeltaOptimizer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#AdadeltaOptimizer">AdadeltaOptimizer</a>(learning_rate=1.0,&nbsp;rho=0.95,&nbsp;epsilon=1e-06,&nbsp;reg_lambda=0.0)<br>
&nbsp;<br>
Adadelta&nbsp;optimizer&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
Formula:<br>
&nbsp;&nbsp;&nbsp;&nbsp;E[g^2]_t&nbsp;=&nbsp;rho&nbsp;*&nbsp;E[g^2]_{t-1}&nbsp;+&nbsp;(1&nbsp;-&nbsp;rho)&nbsp;*&nbsp;g^2<br>
&nbsp;&nbsp;&nbsp;&nbsp;Delta_x&nbsp;=&nbsp;-&nbsp;(sqrt(E[delta_x^2]_{t-1}&nbsp;+&nbsp;epsilon)&nbsp;/&nbsp;sqrt(E[g^2]_t&nbsp;+&nbsp;epsilon))&nbsp;*&nbsp;g<br>
&nbsp;&nbsp;&nbsp;&nbsp;E[delta_x^2]_t&nbsp;=&nbsp;rho&nbsp;*&nbsp;E[delta_x^2]_{t-1}&nbsp;+&nbsp;(1&nbsp;-&nbsp;rho)&nbsp;*&nbsp;Delta_x^2<br>
Derived&nbsp;from:&nbsp;<a href="https://arxiv.org/abs/1212.5701">https://arxiv.org/abs/1212.5701</a><br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;rho&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;decay&nbsp;rate.&nbsp;Defaults&nbsp;to&nbsp;0.95.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float,&nbsp;optional):&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero.&nbsp;Defaults&nbsp;to&nbsp;1e-6.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter.&nbsp;Defaults&nbsp;to&nbsp;0.0.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="AdadeltaOptimizer-__init__"><strong>__init__</strong></a>(self, learning_rate=1.0, rho=0.95, epsilon=1e-06, reg_lambda=0.0)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;optimizer&nbsp;with&nbsp;the&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;rho&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;running&nbsp;averages.&nbsp;Defaults&nbsp;to&nbsp;0.95.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float,&nbsp;optional):&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero.&nbsp;Defaults&nbsp;to&nbsp;1e-6.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter&nbsp;for&nbsp;weight&nbsp;decay.&nbsp;Defaults&nbsp;to&nbsp;0.0.</span></dd></dl>

<dl><dt><a name="AdadeltaOptimizer-initialize"><strong>initialize</strong></a>(self, layers)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;running&nbsp;averages&nbsp;for&nbsp;each&nbsp;layer's&nbsp;weights.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers&nbsp;(list):&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="AdadeltaOptimizer-update"><strong>update</strong></a>(self, layer, dW, db, index)</dt><dd><span class="code">Updates&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;a&nbsp;layer&nbsp;using&nbsp;the&nbsp;Adadelta&nbsp;optimization&nbsp;algorithm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer&nbsp;(Layer):&nbsp;The&nbsp;layer&nbsp;to&nbsp;update.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dW&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;db&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;index&nbsp;(int):&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="AdamOptimizer">class <strong>AdamOptimizer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#AdamOptimizer">AdamOptimizer</a>(learning_rate=0.001,&nbsp;beta1=0.9,&nbsp;beta2=0.999,&nbsp;epsilon=1e-08,&nbsp;reg_lambda=0.01)<br>
&nbsp;<br>
Adam&nbsp;optimizer&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
Formula:&nbsp;w&nbsp;=&nbsp;w&nbsp;-&nbsp;alpha&nbsp;*&nbsp;m_hat&nbsp;/&nbsp;(sqrt(v_hat)&nbsp;+&nbsp;epsilon)&nbsp;-&nbsp;lambda&nbsp;*&nbsp;w<br>
Derived&nbsp;from:&nbsp;<a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a><br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;0.001.<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta1&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;first&nbsp;moment&nbsp;estimates.&nbsp;Defaults&nbsp;to&nbsp;0.9.<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta2&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;second&nbsp;moment&nbsp;estimates.&nbsp;Defaults&nbsp;to&nbsp;0.999.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float,&nbsp;optional):&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero.&nbsp;Defaults&nbsp;to&nbsp;1e-8.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter.&nbsp;Defaults&nbsp;to&nbsp;0.01.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="AdamOptimizer-__init__"><strong>__init__</strong></a>(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, reg_lambda=0.01)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;optimizer&nbsp;with&nbsp;the&nbsp;given&nbsp;hyperparameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;(alpha)&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;0.001.<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta1&nbsp;(float,&nbsp;optional):&nbsp;Exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;first&nbsp;moment&nbsp;estimates.&nbsp;Defaults&nbsp;to&nbsp;0.9.<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta2&nbsp;(float,&nbsp;optional):&nbsp;Exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;second&nbsp;moment&nbsp;estimates.&nbsp;Defaults&nbsp;to&nbsp;0.999.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float,&nbsp;optional):&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero.&nbsp;Defaults&nbsp;to&nbsp;1e-8.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;Regularization&nbsp;parameter;&nbsp;higher&nbsp;values&nbsp;indicate&nbsp;stronger&nbsp;regularization.&nbsp;Defaults&nbsp;to&nbsp;0.01.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta1&nbsp;(float):&nbsp;Exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;first&nbsp;moment&nbsp;estimates.<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta2&nbsp;(float):&nbsp;Exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;second&nbsp;moment&nbsp;estimates.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float):&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float):&nbsp;Regularization&nbsp;parameter&nbsp;for&nbsp;controlling&nbsp;overfitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;m&nbsp;(list):&nbsp;List&nbsp;to&nbsp;store&nbsp;first&nbsp;moment&nbsp;estimates&nbsp;for&nbsp;each&nbsp;parameter.<br>
&nbsp;&nbsp;&nbsp;&nbsp;v&nbsp;(list):&nbsp;List&nbsp;to&nbsp;store&nbsp;second&nbsp;moment&nbsp;estimates&nbsp;for&nbsp;each&nbsp;parameter.<br>
&nbsp;&nbsp;&nbsp;&nbsp;t&nbsp;(int):&nbsp;Time&nbsp;step&nbsp;counter&nbsp;for&nbsp;the&nbsp;optimizer.</span></dd></dl>

<dl><dt><a name="AdamOptimizer-initialize"><strong>initialize</strong></a>(self, layers)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;first&nbsp;and&nbsp;second&nbsp;moment&nbsp;estimates&nbsp;for&nbsp;each&nbsp;layer's&nbsp;weights.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers&nbsp;(list):&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="AdamOptimizer-update"><strong>update</strong></a>(self, layer, dW, db, index)</dt><dd><span class="code">Updates&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;a&nbsp;layer&nbsp;using&nbsp;the&nbsp;Adam&nbsp;optimization&nbsp;algorithm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer&nbsp;(Layer):&nbsp;The&nbsp;layer&nbsp;to&nbsp;update.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dW&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;db&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;index&nbsp;(int):&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;layer.<br>
Returns:&nbsp;None</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Augmenter">class <strong>Augmenter</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#Augmenter">Augmenter</a>(techniques,&nbsp;verbose=False)<br>
&nbsp;<br>
General&nbsp;class&nbsp;for&nbsp;data&nbsp;augmentation&nbsp;techniques.<br>
&nbsp;<br>
This&nbsp;class&nbsp;allows&nbsp;for&nbsp;the&nbsp;application&nbsp;of&nbsp;multiple&nbsp;augmentation&nbsp;techniques&nbsp;in&nbsp;sequence.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="Augmenter-__init__"><strong>__init__</strong></a>(self, techniques, verbose=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#Augmenter">Augmenter</a>&nbsp;with&nbsp;a&nbsp;list&nbsp;of&nbsp;techniques&nbsp;and&nbsp;verbosity&nbsp;option.</span></dd></dl>

<dl><dt><a name="Augmenter-augment"><strong>augment</strong></a>(self, X, y)</dt><dd><span class="code">Applies&nbsp;multiple&nbsp;augmentation&nbsp;techniques&nbsp;in&nbsp;sequence.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Feature&nbsp;matrix.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Target&nbsp;vector.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuple:&nbsp;(np.ndarray,&nbsp;np.ndarray)&nbsp;-&nbsp;Augmented&nbsp;feature&nbsp;matrix&nbsp;and&nbsp;target&nbsp;vector.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="AutoClassifier">class <strong>AutoClassifier</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#AutoClassifier">AutoClassifier</a>(all_kernels=False,&nbsp;tune_hyperparameters=False,&nbsp;tuning_method='random',&nbsp;tuning_iterations=10,&nbsp;cv=3,&nbsp;tuning_metric='f1')<br>
&nbsp;<br>
A&nbsp;class&nbsp;to&nbsp;automatically&nbsp;select&nbsp;and&nbsp;evaluate&nbsp;the&nbsp;best&nbsp;classification&nbsp;model.<br>
&nbsp;<br>
Includes&nbsp;optional&nbsp;automated&nbsp;hyperparameter&nbsp;tuning&nbsp;using&nbsp;<a href="#GridSearchCV">GridSearchCV</a>&nbsp;or&nbsp;<a href="#RandomSearchCV">RandomSearchCV</a>.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="AutoClassifier-__init__"><strong>__init__</strong></a>(self, all_kernels=False, tune_hyperparameters=False, tuning_method='random', tuning_iterations=10, cv=3, tuning_metric='f1')</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#AutoClassifier">AutoClassifier</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;all_kernels&nbsp;(bool):&nbsp;If&nbsp;True,&nbsp;include&nbsp;all&nbsp;SVM&nbsp;kernels.&nbsp;Default&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tune_hyperparameters&nbsp;(bool):&nbsp;If&nbsp;True,&nbsp;perform&nbsp;hyperparameter&nbsp;tuning.&nbsp;Default&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuning_method&nbsp;(str):&nbsp;Method&nbsp;for&nbsp;tuning&nbsp;('random'&nbsp;or&nbsp;'grid').&nbsp;Default&nbsp;'random'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuning_iterations&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;Random&nbsp;Search.&nbsp;Default&nbsp;10.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cv&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;cross-validation&nbsp;folds&nbsp;for&nbsp;tuning.&nbsp;Default&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuning_metric&nbsp;(str):&nbsp;Metric&nbsp;to&nbsp;optimize&nbsp;('accuracy',&nbsp;'precision',&nbsp;'recall',&nbsp;'f1').&nbsp;Default&nbsp;'f1'.</span></dd></dl>

<dl><dt><a name="AutoClassifier-evaluate"><strong>evaluate</strong></a>(self, y_true, custom_metrics=None, model=None)</dt><dd><span class="code">Evaluates&nbsp;the&nbsp;performance&nbsp;using&nbsp;stored&nbsp;predictions.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;custom_metrics:&nbsp;(dict),&nbsp;optional&nbsp;-&nbsp;Custom&nbsp;metrics.&nbsp;Default&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;(str),&nbsp;optional&nbsp;-&nbsp;Specific&nbsp;model&nbsp;name.&nbsp;Default&nbsp;None&nbsp;(evaluate&nbsp;all).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;Evaluation&nbsp;metrics&nbsp;for&nbsp;the&nbsp;specified&nbsp;model(s).</span></dd></dl>

<dl><dt><a name="AutoClassifier-fit"><strong>fit</strong></a>(self, X_train, y_train, X_test=None, y_test=None, custom_metrics=None, verbose=False)</dt><dd><span class="code">Fits&nbsp;the&nbsp;classification&nbsp;models,&nbsp;optionally&nbsp;performing&nbsp;hyperparameter&nbsp;tuning.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;feature&nbsp;data.&nbsp;Default&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;target&nbsp;data.&nbsp;Default&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;custom_metrics:&nbsp;(dict:&nbsp;str&nbsp;-&gt;&nbsp;callable),&nbsp;optional&nbsp;-&nbsp;Custom&nbsp;metrics&nbsp;for&nbsp;evaluation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;If&nbsp;True,&nbsp;prints&nbsp;progress.&nbsp;Default&nbsp;False.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;results:&nbsp;(list)&nbsp;-&nbsp;A&nbsp;list&nbsp;of&nbsp;dictionaries&nbsp;containing&nbsp;model&nbsp;performance&nbsp;metrics.<br>
&nbsp;&nbsp;&nbsp;&nbsp;predictions:&nbsp;(dict)&nbsp;-&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;predictions&nbsp;for&nbsp;each&nbsp;model&nbsp;on&nbsp;the&nbsp;test/train&nbsp;set.</span></dd></dl>

<dl><dt><a name="AutoClassifier-get_model"><strong>get_model</strong></a>(self, model_name)</dt><dd><span class="code">Returns&nbsp;the&nbsp;final&nbsp;fitted&nbsp;model&nbsp;instance&nbsp;(potentially&nbsp;tuned).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;model_name&nbsp;(str):&nbsp;The&nbsp;name&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;model_instance:&nbsp;The&nbsp;fitted&nbsp;model&nbsp;instance.</span></dd></dl>

<dl><dt><a name="AutoClassifier-predict"><strong>predict</strong></a>(self, X, model=None)</dt><dd><span class="code">Generates&nbsp;predictions&nbsp;using&nbsp;fitted&nbsp;models.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;(str),&nbsp;optional&nbsp;-&nbsp;Specific&nbsp;model&nbsp;name.&nbsp;Default&nbsp;None&nbsp;(predict&nbsp;with&nbsp;all).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict&nbsp;or&nbsp;np.ndarray:&nbsp;Predictions&nbsp;for&nbsp;specified&nbsp;model(s).</span></dd></dl>

<dl><dt><a name="AutoClassifier-summary"><strong>summary</strong></a>(self)</dt><dd><span class="code">Prints&nbsp;a&nbsp;summary&nbsp;of&nbsp;model&nbsp;performance,&nbsp;including&nbsp;tuning&nbsp;results&nbsp;if&nbsp;available.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="AutoRegressor">class <strong>AutoRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#AutoRegressor">AutoRegressor</a>(all_kernels=False,&nbsp;tune_hyperparameters=False,&nbsp;tuning_method='random',&nbsp;tuning_iterations=10,&nbsp;cv=3,&nbsp;tuning_metric='r2')<br>
&nbsp;<br>
A&nbsp;class&nbsp;to&nbsp;automatically&nbsp;select&nbsp;and&nbsp;evaluate&nbsp;the&nbsp;best&nbsp;regression&nbsp;model.<br>
&nbsp;<br>
Includes&nbsp;optional&nbsp;automated&nbsp;hyperparameter&nbsp;tuning&nbsp;using&nbsp;<a href="#GridSearchCV">GridSearchCV</a>&nbsp;or&nbsp;<a href="#RandomSearchCV">RandomSearchCV</a>.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="AutoRegressor-__init__"><strong>__init__</strong></a>(self, all_kernels=False, tune_hyperparameters=False, tuning_method='random', tuning_iterations=10, cv=3, tuning_metric='r2')</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#AutoRegressor">AutoRegressor</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;all_kernels&nbsp;(bool):&nbsp;If&nbsp;True,&nbsp;include&nbsp;all&nbsp;SVM&nbsp;kernels.&nbsp;Default&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tune_hyperparameters&nbsp;(bool):&nbsp;If&nbsp;True,&nbsp;perform&nbsp;hyperparameter&nbsp;tuning.&nbsp;Default&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuning_method&nbsp;(str):&nbsp;Method&nbsp;for&nbsp;tuning&nbsp;('random'&nbsp;or&nbsp;'grid').&nbsp;Default&nbsp;'random'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuning_iterations&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;Random&nbsp;Search.&nbsp;Default&nbsp;10.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cv&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;cross-validation&nbsp;folds&nbsp;for&nbsp;tuning.&nbsp;Default&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuning_metric&nbsp;(str):&nbsp;Metric&nbsp;to&nbsp;optimize&nbsp;('r2',&nbsp;'neg_mean_squared_error',&nbsp;'rmse',&nbsp;'mae',&nbsp;'mape').&nbsp;Default&nbsp;'r2'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Note:&nbsp;for&nbsp;minimization&nbsp;use&nbsp;'neg_mean_squared_error',&nbsp;'rmse',&nbsp;'mae',&nbsp;'mape'.</span></dd></dl>

<dl><dt><a name="AutoRegressor-evaluate"><strong>evaluate</strong></a>(self, y_true, custom_metrics=None, model=None)</dt><dd><span class="code">Evaluates&nbsp;performance&nbsp;using&nbsp;stored&nbsp;predictions.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;custom_metrics:&nbsp;(dict),&nbsp;optional&nbsp;-&nbsp;Custom&nbsp;metrics.&nbsp;Default&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;(str),&nbsp;optional&nbsp;-&nbsp;Specific&nbsp;model&nbsp;name.&nbsp;Default&nbsp;None&nbsp;(evaluate&nbsp;all).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;Evaluation&nbsp;metrics.</span></dd></dl>

<dl><dt><a name="AutoRegressor-fit"><strong>fit</strong></a>(self, X_train, y_train, X_test=None, y_test=None, custom_metrics=None, verbose=False)</dt><dd><span class="code">Fits&nbsp;the&nbsp;regression&nbsp;models,&nbsp;optionally&nbsp;performing&nbsp;hyperparameter&nbsp;tuning.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;feature&nbsp;data.&nbsp;Default&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;target&nbsp;data.&nbsp;Default&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;custom_metrics:&nbsp;(dict:&nbsp;str&nbsp;-&gt;&nbsp;callable),&nbsp;optional&nbsp;-&nbsp;Custom&nbsp;metrics.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;If&nbsp;True,&nbsp;prints&nbsp;progress.&nbsp;Default&nbsp;False.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;results:&nbsp;(list)&nbsp;-&nbsp;Performance&nbsp;metrics&nbsp;for&nbsp;each&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;predictions:&nbsp;(dict)&nbsp;-&nbsp;Predictions&nbsp;for&nbsp;each&nbsp;model&nbsp;on&nbsp;the&nbsp;test/train&nbsp;set.</span></dd></dl>

<dl><dt><a name="AutoRegressor-get_model"><strong>get_model</strong></a>(self, model_name)</dt><dd><span class="code">Returns&nbsp;the&nbsp;final&nbsp;fitted&nbsp;model&nbsp;instance&nbsp;(potentially&nbsp;tuned).</span></dd></dl>

<dl><dt><a name="AutoRegressor-predict"><strong>predict</strong></a>(self, X, model=None)</dt><dd><span class="code">Generates&nbsp;predictions&nbsp;using&nbsp;fitted&nbsp;models.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;(str),&nbsp;optional&nbsp;-&nbsp;Specific&nbsp;model&nbsp;name.&nbsp;Default&nbsp;None&nbsp;(predict&nbsp;with&nbsp;all).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict&nbsp;or&nbsp;np.ndarray:&nbsp;Predictions&nbsp;for&nbsp;specified&nbsp;model(s).</span></dd></dl>

<dl><dt><a name="AutoRegressor-summary"><strong>summary</strong></a>(self)</dt><dd><span class="code">Prints&nbsp;a&nbsp;summary&nbsp;of&nbsp;model&nbsp;performance,&nbsp;including&nbsp;tuning&nbsp;results.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="BCEWithLogitsLoss">class <strong>BCEWithLogitsLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss&nbsp;with&nbsp;logits&nbsp;implementation&nbsp;using&nbsp;numpy.<br>
&nbsp;<br>
Formula:&nbsp;-mean(y&nbsp;*&nbsp;log(p)&nbsp;+&nbsp;(1&nbsp;-&nbsp;y)&nbsp;*&nbsp;log(1&nbsp;-&nbsp;p))<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BCEWithLogitsLoss-__call__">__call__</a>(self,&nbsp;logits,&nbsp;targets):&nbsp;Calculate&nbsp;the&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="BCEWithLogitsLoss-__call__"><strong>__call__</strong></a>(self, logits, targets)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;logits&nbsp;(np.ndarray):&nbsp;The&nbsp;logits&nbsp;(predicted&nbsp;values)&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;targets&nbsp;(np.ndarray):&nbsp;The&nbsp;target&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="BaseBackendNeuralNetwork">class <strong>BaseBackendNeuralNetwork</strong></a>(<a href="sega_learn.neural_networks.neuralNetworkBase.html#NeuralNetworkBase">sega_learn.neural_networks.neuralNetworkBase.NeuralNetworkBase</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#BaseBackendNeuralNetwork">BaseBackendNeuralNetwork</a>(layers,&nbsp;dropout_rate=0.2,&nbsp;reg_lambda=0.01,&nbsp;activations=None,&nbsp;loss_function=None,&nbsp;regressor=False)<br>
&nbsp;<br>
A&nbsp;class&nbsp;representing&nbsp;a&nbsp;backend&nbsp;implementation&nbsp;of&nbsp;a&nbsp;neural&nbsp;network&nbsp;with&nbsp;support&nbsp;for&nbsp;forward&nbsp;propagation,&nbsp;backward&nbsp;propagation,&nbsp;training,&nbsp;evaluation,&nbsp;and&nbsp;hyperparameter&nbsp;tuning.<br>
&nbsp;<br>
This&nbsp;class&nbsp;extends&nbsp;the&nbsp;`<a href="#NeuralNetworkBase">NeuralNetworkBase</a>`&nbsp;class&nbsp;and&nbsp;provides&nbsp;additional&nbsp;functionality<br>
for&nbsp;managing&nbsp;layers,&nbsp;applying&nbsp;dropout,&nbsp;calculating&nbsp;loss,&nbsp;and&nbsp;optimizing&nbsp;weights&nbsp;and&nbsp;biases.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers&nbsp;(list):&nbsp;List&nbsp;of&nbsp;layer&nbsp;objects&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer_outputs&nbsp;(list):&nbsp;Outputs&nbsp;of&nbsp;each&nbsp;layer&nbsp;during&nbsp;forward&nbsp;propagation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights&nbsp;(list):&nbsp;Weights&nbsp;of&nbsp;each&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;biases&nbsp;(list):&nbsp;Biases&nbsp;of&nbsp;each&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;train_loss&nbsp;(list):&nbsp;Training&nbsp;loss&nbsp;values&nbsp;over&nbsp;epochs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;train_accuracy&nbsp;(list):&nbsp;Training&nbsp;accuracy&nbsp;values&nbsp;over&nbsp;epochs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;val_loss&nbsp;(list):&nbsp;Validation&nbsp;loss&nbsp;values&nbsp;over&nbsp;epochs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;val_accuracy&nbsp;(list):&nbsp;Validation&nbsp;accuracy&nbsp;values&nbsp;over&nbsp;epochs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;train_precision&nbsp;(list):&nbsp;Training&nbsp;precision&nbsp;values&nbsp;over&nbsp;epochs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;train_recall&nbsp;(list):&nbsp;Training&nbsp;recall&nbsp;values&nbsp;over&nbsp;epochs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;train_f1&nbsp;(list):&nbsp;Training&nbsp;F1-score&nbsp;values&nbsp;over&nbsp;epochs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;val_precision&nbsp;(list):&nbsp;Validation&nbsp;precision&nbsp;values&nbsp;over&nbsp;epochs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;val_recall&nbsp;(list):&nbsp;Validation&nbsp;recall&nbsp;values&nbsp;over&nbsp;epochs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;val_f1&nbsp;(list):&nbsp;Validation&nbsp;F1-score&nbsp;values&nbsp;over&nbsp;epochs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rates&nbsp;(list):&nbsp;Learning&nbsp;rates&nbsp;over&nbsp;epochs.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-__init__">__init__</a>(layers,&nbsp;dropout_rate=0.2,&nbsp;reg_lambda=0.01,&nbsp;activations=None,&nbsp;loss_function=None,&nbsp;regressor=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;neural&nbsp;network&nbsp;with&nbsp;the&nbsp;specified&nbsp;layers,&nbsp;dropout&nbsp;rate,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;regularization&nbsp;parameter,&nbsp;activation&nbsp;functions,&nbsp;and&nbsp;optional&nbsp;loss&nbsp;function.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-initialize_new_layers">initialize_new_layers</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;layers&nbsp;of&nbsp;the&nbsp;neural&nbsp;network&nbsp;with&nbsp;random&nbsp;weights&nbsp;and&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-forward">forward</a>(X,&nbsp;training=True):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Performs&nbsp;forward&nbsp;propagation&nbsp;through&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-backward">backward</a>(y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Performs&nbsp;backward&nbsp;propagation&nbsp;to&nbsp;calculate&nbsp;gradients&nbsp;for&nbsp;weight&nbsp;and&nbsp;bias&nbsp;updates.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-fit">fit</a>(X_train,&nbsp;y_train,&nbsp;X_val=None,&nbsp;y_val=None,&nbsp;optimizer=None,&nbsp;epochs=100,&nbsp;batch_size=32,&nbsp;...):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;the&nbsp;neural&nbsp;network&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-train">train</a>(X_train,&nbsp;y_train,&nbsp;X_val=None,&nbsp;y_val=None,&nbsp;optimizer=None,&nbsp;epochs=100,&nbsp;batch_size=32,&nbsp;...):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Trains&nbsp;the&nbsp;neural&nbsp;network&nbsp;model&nbsp;with&nbsp;optional&nbsp;validation&nbsp;and&nbsp;early&nbsp;stopping.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-evaluate">evaluate</a>(X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Evaluates&nbsp;the&nbsp;model&nbsp;on&nbsp;the&nbsp;given&nbsp;data&nbsp;and&nbsp;returns&nbsp;accuracy&nbsp;and&nbsp;predictions.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-predict">predict</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predicts&nbsp;the&nbsp;output&nbsp;for&nbsp;the&nbsp;given&nbsp;input&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-calculate_loss">calculate_loss</a>(X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Calculates&nbsp;the&nbsp;loss&nbsp;with&nbsp;L2&nbsp;regularization&nbsp;for&nbsp;the&nbsp;given&nbsp;input&nbsp;and&nbsp;target&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_create_optimizer(optimizer_type,&nbsp;learning_rate,&nbsp;JIT=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Helper&nbsp;method&nbsp;to&nbsp;create&nbsp;optimizer&nbsp;instances&nbsp;based&nbsp;on&nbsp;the&nbsp;specified&nbsp;type.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-tune_hyperparameters">tune_hyperparameters</a>(X_train,&nbsp;y_train,&nbsp;X_val,&nbsp;y_val,&nbsp;param_grid,&nbsp;...):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Performs&nbsp;hyperparameter&nbsp;tuning&nbsp;using&nbsp;grid&nbsp;search.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseBackendNeuralNetwork-train_with_animation_capture">train_with_animation_capture</a>(X_train,&nbsp;y_train,&nbsp;X_val=None,&nbsp;y_val=None,&nbsp;...):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Trains&nbsp;the&nbsp;neural&nbsp;network&nbsp;while&nbsp;capturing&nbsp;training&nbsp;metrics&nbsp;in&nbsp;real-time&nbsp;animation.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.neural_networks.neuralNetworkBaseBackend.html#BaseBackendNeuralNetwork">BaseBackendNeuralNetwork</a></dd>
<dd><a href="sega_learn.neural_networks.neuralNetworkBase.html#NeuralNetworkBase">sega_learn.neural_networks.neuralNetworkBase.NeuralNetworkBase</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="BaseBackendNeuralNetwork-__init__"><strong>__init__</strong></a>(self, layers, dropout_rate=0.2, reg_lambda=0.01, activations=None, loss_function=None, regressor=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;Numba&nbsp;backend&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;layer&nbsp;sizes&nbsp;or&nbsp;Layer&nbsp;objects.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dropout_rate:&nbsp;(float)&nbsp;-&nbsp;Dropout&nbsp;rate&nbsp;for&nbsp;regularization.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda:&nbsp;(float)&nbsp;-&nbsp;L2&nbsp;regularization&nbsp;parameter.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activations:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;activation&nbsp;functions&nbsp;for&nbsp;each&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss_function:&nbsp;(callable)&nbsp;optional&nbsp;-&nbsp;Custom&nbsp;loss&nbsp;function&nbsp;to&nbsp;use&nbsp;(default&nbsp;is&nbsp;None,&nbsp;which&nbsp;uses&nbsp;the&nbsp;default&nbsp;calculate_loss&nbsp;implementation).<br>
&nbsp;&nbsp;&nbsp;&nbsp;regressor:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;the&nbsp;model&nbsp;is&nbsp;a&nbsp;regressor&nbsp;(default&nbsp;is&nbsp;False).</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-backward"><strong>backward</strong></a>(self, y)</dt><dd><span class="code">Performs&nbsp;backward&nbsp;propagation&nbsp;to&nbsp;calculate&nbsp;the&nbsp;gradients.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(ndarray)&nbsp;-&nbsp;Target&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(m,&nbsp;output_size).</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-calculate_loss"><strong>calculate_loss</strong></a>(self, X, y)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;loss&nbsp;with&nbsp;L2&nbsp;regularization.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Target&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;calculated&nbsp;loss&nbsp;value&nbsp;with&nbsp;L2&nbsp;regularization.</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-evaluate"><strong>evaluate</strong></a>(self, X, y)</dt><dd><span class="code">Evaluates&nbsp;the&nbsp;model's&nbsp;performance&nbsp;on&nbsp;the&nbsp;given&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;feature&nbsp;data&nbsp;for&nbsp;evaluation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;True&nbsp;target&nbsp;labels&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;metric:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;evaluation&nbsp;metric&nbsp;(accuracy&nbsp;for&nbsp;classification,&nbsp;MSE&nbsp;for&nbsp;regression).<br>
&nbsp;&nbsp;&nbsp;&nbsp;predicted:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;labels&nbsp;or&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;data.</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-fit"><strong>fit</strong></a>(self, X_train, y_train, X_val=None, y_val=None, optimizer=None, epochs=100, batch_size=32, early_stopping_threshold=10, lr_scheduler=None, p=False, use_tqdm=False, n_jobs=1, track_metrics=False, track_adv_metrics=False, save_animation=False, save_path='training_animation.mp4', fps=1, dpi=100, frame_every=1)</dt><dd><span class="code">Fits&nbsp;the&nbsp;neural&nbsp;network&nbsp;to&nbsp;the&nbsp;training&nbsp;data.</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-forward"><strong>forward</strong></a>(self, X, training=True)</dt><dd><span class="code">Performs&nbsp;forward&nbsp;propagation&nbsp;through&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(ndarray):&nbsp;-&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(batch_size,&nbsp;input_size).<br>
&nbsp;&nbsp;&nbsp;&nbsp;training:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;the&nbsp;network&nbsp;is&nbsp;in&nbsp;training&nbsp;mode&nbsp;(applies&nbsp;dropout).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ndarray:&nbsp;Output&nbsp;predictions&nbsp;of&nbsp;shape&nbsp;(batch_size,&nbsp;output_size).</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-initialize_new_layers"><strong>initialize_new_layers</strong></a>(self)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;layers&nbsp;of&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Each&nbsp;layer&nbsp;is&nbsp;created&nbsp;with&nbsp;the&nbsp;specified&nbsp;number&nbsp;of&nbsp;neurons&nbsp;and&nbsp;activation&nbsp;function.</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Generates&nbsp;predictions&nbsp;for&nbsp;the&nbsp;given&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;feature&nbsp;data&nbsp;for&nbsp;which&nbsp;predictions&nbsp;are&nbsp;to&nbsp;be&nbsp;made.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;outputs:&nbsp;(np.ndarray)&nbsp;-&nbsp;Predicted&nbsp;outputs.&nbsp;If&nbsp;the&nbsp;model&nbsp;is&nbsp;binary,&nbsp;returns&nbsp;the&nbsp;raw&nbsp;outputs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Otherwise,&nbsp;returns&nbsp;the&nbsp;class&nbsp;indices&nbsp;with&nbsp;the&nbsp;highest&nbsp;probability.</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-train"><strong>train</strong></a>(self, X_train, y_train, X_val=None, y_val=None, optimizer=None, epochs=100, batch_size=32, early_stopping_threshold=10, lr_scheduler=None, p=True, use_tqdm=True, n_jobs=1, track_metrics=False, track_adv_metrics=False, save_animation=False, save_path='training_animation.mp4', fps=1, dpi=100, frame_every=1)</dt><dd><span class="code">Trains&nbsp;the&nbsp;neural&nbsp;network&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(ndarray)&nbsp;-&nbsp;Training&nbsp;data&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(ndarray)&nbsp;-&nbsp;Training&nbsp;data&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_val:&nbsp;(ndarray)&nbsp;-&nbsp;Validation&nbsp;data&nbsp;features,&nbsp;optional.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_val:&nbsp;(ndarray)&nbsp;-&nbsp;Validation&nbsp;data&nbsp;labels,&nbsp;optional.<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer:&nbsp;(Optimizer)&nbsp;-&nbsp;Optimizer&nbsp;for&nbsp;updating&nbsp;parameters&nbsp;(default:&nbsp;Adam,&nbsp;lr=0.0001).<br>
&nbsp;&nbsp;&nbsp;&nbsp;epochs:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;training&nbsp;epochs&nbsp;(default:&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;batch_size:&nbsp;(int)&nbsp;-&nbsp;Batch&nbsp;size&nbsp;for&nbsp;mini-batch&nbsp;gradient&nbsp;descent&nbsp;(default:&nbsp;32).<br>
&nbsp;&nbsp;&nbsp;&nbsp;early_stopping_threshold:&nbsp;(int)&nbsp;-&nbsp;Patience&nbsp;for&nbsp;early&nbsp;stopping&nbsp;(default:&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_scheduler:&nbsp;(Scheduler)&nbsp;-&nbsp;Learning&nbsp;rate&nbsp;scheduler&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;p:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;print&nbsp;training&nbsp;progress&nbsp;(default:&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;use_tqdm:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;use&nbsp;tqdm&nbsp;for&nbsp;progress&nbsp;bar&nbsp;(default:&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;jobs&nbsp;for&nbsp;parallel&nbsp;processing&nbsp;(default:&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;track_metrics:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;track&nbsp;training&nbsp;metrics&nbsp;(default:&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;track_adv_metrics:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;track&nbsp;advanced&nbsp;metrics&nbsp;(default:&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_animation:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;save&nbsp;the&nbsp;animation&nbsp;of&nbsp;metrics&nbsp;(default:&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_path:&nbsp;(str)&nbsp;-&nbsp;Path&nbsp;to&nbsp;save&nbsp;the&nbsp;animation&nbsp;file.&nbsp;File&nbsp;extension&nbsp;must&nbsp;be&nbsp;.mp4&nbsp;or&nbsp;.gif&nbsp;(default:&nbsp;'training_animation.mp4').<br>
&nbsp;&nbsp;&nbsp;&nbsp;fps:&nbsp;(int)&nbsp;-&nbsp;Frames&nbsp;per&nbsp;second&nbsp;for&nbsp;the&nbsp;saved&nbsp;animation&nbsp;(default:&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;dpi:&nbsp;(int)&nbsp;-&nbsp;DPI&nbsp;for&nbsp;the&nbsp;saved&nbsp;animation&nbsp;(default:&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;frame_every:&nbsp;(int)&nbsp;-&nbsp;Capture&nbsp;frame&nbsp;every&nbsp;N&nbsp;epochs&nbsp;(to&nbsp;reduce&nbsp;file&nbsp;size)&nbsp;(default:&nbsp;1).</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-train_with_animation_capture"><strong>train_with_animation_capture</strong></a>(self, X_train, y_train, X_val=None, y_val=None, optimizer=None, epochs=100, batch_size=32, early_stopping_threshold=10, lr_scheduler=None, save_path='training_animation.mp4', fps=1, dpi=100, frame_every=1)</dt><dd><span class="code">Trains&nbsp;the&nbsp;neural&nbsp;network&nbsp;model&nbsp;while&nbsp;capturing&nbsp;training&nbsp;metrics&nbsp;in&nbsp;real-time&nbsp;animation.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_val:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Validation&nbsp;feature&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_val:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Validation&nbsp;target&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer:&nbsp;(Optimizer),&nbsp;optional&nbsp;-&nbsp;Optimizer&nbsp;for&nbsp;updating&nbsp;parameters&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;epochs:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Number&nbsp;of&nbsp;training&nbsp;epochs&nbsp;(default&nbsp;is&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;batch_size:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Batch&nbsp;size&nbsp;for&nbsp;mini-batch&nbsp;gradient&nbsp;descent&nbsp;(default&nbsp;is&nbsp;32).<br>
&nbsp;&nbsp;&nbsp;&nbsp;early_stopping_threshold:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Patience&nbsp;for&nbsp;early&nbsp;stopping&nbsp;(default&nbsp;is&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_scheduler:&nbsp;(Scheduler),&nbsp;optional&nbsp;-&nbsp;Learning&nbsp;rate&nbsp;scheduler&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_path:&nbsp;(str),&nbsp;optional&nbsp;-&nbsp;Path&nbsp;to&nbsp;save&nbsp;the&nbsp;animation&nbsp;file&nbsp;(default&nbsp;is&nbsp;'training_animation.mp4').<br>
&nbsp;&nbsp;&nbsp;&nbsp;fps:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Frames&nbsp;per&nbsp;second&nbsp;for&nbsp;the&nbsp;saved&nbsp;animation&nbsp;(default&nbsp;is&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;dpi:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;DPI&nbsp;for&nbsp;the&nbsp;saved&nbsp;animation&nbsp;(default&nbsp;is&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;frame_every:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Capture&nbsp;frame&nbsp;every&nbsp;N&nbsp;epochs&nbsp;(default&nbsp;is&nbsp;1).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-tune_hyperparameters"><strong>tune_hyperparameters</strong></a>(self, X_train, y_train, X_val, y_val, param_grid, layer_configs=None, optimizer_types=None, lr_range=(0.0001, 0.01, 5), epochs=30, batch_size=32)</dt><dd><span class="code">Performs&nbsp;hyperparameter&nbsp;tuning&nbsp;using&nbsp;grid&nbsp;search.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_val:&nbsp;(np.ndarray)&nbsp;-&nbsp;Validation&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_val:&nbsp;(np.ndarray)&nbsp;-&nbsp;Validation&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;param_grid:&nbsp;(dict)&nbsp;-&nbsp;Dictionary&nbsp;of&nbsp;parameters&nbsp;to&nbsp;try.<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer_configs:&nbsp;(list),&nbsp;optional&nbsp;-&nbsp;List&nbsp;of&nbsp;layer&nbsp;configurations&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer_types:&nbsp;(list),&nbsp;optional&nbsp;-&nbsp;List&nbsp;of&nbsp;optimizer&nbsp;types&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_range:&nbsp;(tuple)&nbsp;-&nbsp;Tuple&nbsp;of&nbsp;(min_lr,&nbsp;max_lr,&nbsp;num_steps)&nbsp;for&nbsp;learning&nbsp;rates.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epochs:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;epochs&nbsp;for&nbsp;each&nbsp;trial.<br>
&nbsp;&nbsp;&nbsp;&nbsp;batch_size:&nbsp;(int)&nbsp;-&nbsp;Batch&nbsp;size&nbsp;for&nbsp;training.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_params:&nbsp;(dict)&nbsp;-&nbsp;Best&nbsp;hyperparameters&nbsp;found.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_accuracy:&nbsp;(float)&nbsp;-&nbsp;Best&nbsp;validation&nbsp;accuracy.</span></dd></dl>

<hr>
Methods inherited from <a href="sega_learn.neural_networks.neuralNetworkBase.html#NeuralNetworkBase">sega_learn.neural_networks.neuralNetworkBase.NeuralNetworkBase</a>:<br>
<dl><dt><a name="BaseBackendNeuralNetwork-apply_dropout"><strong>apply_dropout</strong></a>(self, X)</dt><dd><span class="code">Applies&nbsp;dropout&nbsp;to&nbsp;the&nbsp;activation&nbsp;X.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(ndarray)&nbsp;-&nbsp;<a href="#Activation">Activation</a>&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ndarray:&nbsp;<a href="#Activation">Activation</a>&nbsp;values&nbsp;after&nbsp;applying&nbsp;dropout.</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-calculate_precision_recall_f1"><strong>calculate_precision_recall_f1</strong></a>(self, X, y)</dt><dd><span class="code">Calculates&nbsp;precision,&nbsp;recall,&nbsp;and&nbsp;F1&nbsp;score.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(ndarray)&nbsp;-&nbsp;Input&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(ndarray)&nbsp;-&nbsp;Target&nbsp;labels<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;precision:&nbsp;(float)&nbsp;-&nbsp;Precision&nbsp;score<br>
&nbsp;&nbsp;&nbsp;&nbsp;recall:&nbsp;(float)&nbsp;-&nbsp;Recall&nbsp;score<br>
&nbsp;&nbsp;&nbsp;&nbsp;f1:&nbsp;(float)&nbsp;-&nbsp;F1&nbsp;score</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-compute_l2_reg"><strong>compute_l2_reg</strong></a>(self, weights)</dt><dd><span class="code">Computes&nbsp;the&nbsp;L2&nbsp;regularization&nbsp;term.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;weight&nbsp;matrices.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;L2&nbsp;regularization&nbsp;term.</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-create_scheduler"><strong>create_scheduler</strong></a>(self, scheduler_type, optimizer, **kwargs)</dt><dd><span class="code">Creates&nbsp;a&nbsp;learning&nbsp;rate&nbsp;scheduler.</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-initialize_layers"><strong>initialize_layers</strong></a>(self)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;the&nbsp;layers.</span></dd></dl>

<dl><dt><a name="BaseBackendNeuralNetwork-plot_metrics"><strong>plot_metrics</strong></a>(self, save_dir=None)</dt><dd><span class="code">Plots&nbsp;the&nbsp;training&nbsp;and&nbsp;validation&nbsp;metrics.</span></dd></dl>

<hr>
Data descriptors inherited from <a href="sega_learn.neural_networks.neuralNetworkBase.html#NeuralNetworkBase">sega_learn.neural_networks.neuralNetworkBase.NeuralNetworkBase</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="BaseSVM">class <strong>BaseSVM</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#BaseSVM">BaseSVM</a>(C=1.0,&nbsp;tol=0.0001,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;kernel='linear',&nbsp;degree=3,&nbsp;gamma='scale',&nbsp;coef0=0.0,&nbsp;regression=False)<br>
&nbsp;<br>
<a href="#BaseSVM">BaseSVM</a>:&nbsp;A&nbsp;base&nbsp;class&nbsp;for&nbsp;Support&nbsp;Vector&nbsp;Machines&nbsp;(SVM)&nbsp;with&nbsp;kernel&nbsp;support.<br>
&nbsp;<br>
This&nbsp;class&nbsp;provides&nbsp;the&nbsp;foundation&nbsp;for&nbsp;implementing&nbsp;SVM&nbsp;models&nbsp;with&nbsp;various&nbsp;kernels<br>
and&nbsp;supports&nbsp;both&nbsp;classification&nbsp;and&nbsp;regression&nbsp;tasks.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C&nbsp;(float):&nbsp;Regularization&nbsp;parameter.&nbsp;Default&nbsp;is&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol&nbsp;(float):&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria.&nbsp;Default&nbsp;is&nbsp;1e-4.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter&nbsp;(int):&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;optimization.&nbsp;Default&nbsp;is&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Step&nbsp;size&nbsp;for&nbsp;optimization.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel&nbsp;(str):&nbsp;Kernel&nbsp;type&nbsp;('linear',&nbsp;'poly',&nbsp;'rbf',&nbsp;or&nbsp;'sigmoid').&nbsp;Default&nbsp;is&nbsp;'linear'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;degree&nbsp;(int):&nbsp;Degree&nbsp;for&nbsp;polynomial&nbsp;kernel.&nbsp;Default&nbsp;is&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;gamma&nbsp;(str&nbsp;or&nbsp;float):&nbsp;Kernel&nbsp;coefficient&nbsp;('scale',&nbsp;'auto',&nbsp;or&nbsp;float).&nbsp;Default&nbsp;is&nbsp;'scale'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef0&nbsp;(float):&nbsp;Independent&nbsp;term&nbsp;in&nbsp;poly&nbsp;and&nbsp;sigmoid&nbsp;kernels.&nbsp;Default&nbsp;is&nbsp;0.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;regression&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;use&nbsp;regression&nbsp;(SVR)&nbsp;or&nbsp;classification&nbsp;(SVC).&nbsp;Default&nbsp;is&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;(ndarray):&nbsp;Weight&nbsp;vector&nbsp;for&nbsp;linear&nbsp;kernel.<br>
&nbsp;&nbsp;&nbsp;&nbsp;b&nbsp;(float):&nbsp;Bias&nbsp;term.<br>
&nbsp;&nbsp;&nbsp;&nbsp;support_vectors_&nbsp;(ndarray):&nbsp;Support&nbsp;vectors&nbsp;identified&nbsp;during&nbsp;training.<br>
&nbsp;&nbsp;&nbsp;&nbsp;support_vector_labels_&nbsp;(ndarray):&nbsp;Labels&nbsp;of&nbsp;the&nbsp;support&nbsp;vectors.<br>
&nbsp;&nbsp;&nbsp;&nbsp;support_vector_alphas_&nbsp;(ndarray):&nbsp;Lagrange&nbsp;multipliers&nbsp;for&nbsp;the&nbsp;support&nbsp;vectors.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseSVM-__init__">__init__</a>(self,&nbsp;C=1.0,&nbsp;tol=1e-4,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;kernel='linear',&nbsp;degree=3,&nbsp;gamma='scale',&nbsp;coef0=0.0,&nbsp;regression=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;<a href="#BaseSVM">BaseSVM</a>&nbsp;instance&nbsp;with&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseSVM-fit">fit</a>(self,&nbsp;X,&nbsp;y=None):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;the&nbsp;SVM&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_fit(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abstract&nbsp;method&nbsp;to&nbsp;be&nbsp;implemented&nbsp;by&nbsp;subclasses&nbsp;for&nbsp;training.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_compute_kernel(self,&nbsp;X1,&nbsp;X2):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;the&nbsp;kernel&nbsp;function&nbsp;between&nbsp;two&nbsp;input&nbsp;matrices.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseSVM-decision_function">decision_function</a>(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;the&nbsp;decision&nbsp;function&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseSVM-predict">predict</a>(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseSVM-score">score</a>(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;the&nbsp;mean&nbsp;accuracy&nbsp;of&nbsp;the&nbsp;model&nbsp;on&nbsp;the&nbsp;given&nbsp;test&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseSVM-get_params">get_params</a>(self,&nbsp;deep=True):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieves&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseSVM-set_params">set_params</a>(self,&nbsp;**parameters):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sets&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BaseSVM-__sklearn_is_fitted__">__sklearn_is_fitted__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Checks&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted&nbsp;(for&nbsp;sklearn&nbsp;compatibility).<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="BaseSVM-__init__"><strong>__init__</strong></a>(self, C=1.0, tol=0.0001, max_iter=1000, learning_rate=0.01, kernel='linear', degree=3, gamma='scale', coef0=0.0, regression=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#BaseSVM">BaseSVM</a>&nbsp;instance&nbsp;with&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C:&nbsp;(float)&nbsp;-&nbsp;Regularization&nbsp;parameter.&nbsp;Default&nbsp;is&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float)&nbsp;-&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria.&nbsp;Default&nbsp;is&nbsp;1e-4.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;optimization.&nbsp;Default&nbsp;is&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float)&nbsp;-&nbsp;Step&nbsp;size&nbsp;for&nbsp;optimization.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel:&nbsp;(str)&nbsp;-&nbsp;Kernel&nbsp;type&nbsp;('linear',&nbsp;'poly',&nbsp;'rbf',&nbsp;or&nbsp;'sigmoid').&nbsp;Default&nbsp;is&nbsp;'linear'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;degree:&nbsp;(int)&nbsp;-&nbsp;Degree&nbsp;for&nbsp;polynomial&nbsp;kernel.&nbsp;Default&nbsp;is&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;gamma:&nbsp;(str&nbsp;or&nbsp;float)&nbsp;-&nbsp;Kernel&nbsp;coefficient&nbsp;('scale',&nbsp;'auto',&nbsp;or&nbsp;float).&nbsp;Default&nbsp;is&nbsp;'scale'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef0:&nbsp;(float)&nbsp;-&nbsp;Independent&nbsp;term&nbsp;in&nbsp;poly&nbsp;and&nbsp;sigmoid&nbsp;kernels.&nbsp;Default&nbsp;is&nbsp;0.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;regression:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;use&nbsp;regression&nbsp;(SVR)&nbsp;or&nbsp;classification&nbsp;(SVC).&nbsp;Default&nbsp;is&nbsp;False.</span></dd></dl>

<dl><dt><a name="BaseSVM-__sklearn_is_fitted__"><strong>__sklearn_is_fitted__</strong></a>(self)</dt><dd><span class="code">Checks&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted&nbsp;(for&nbsp;sklearn&nbsp;compatibility).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fitted:&nbsp;(bool)&nbsp;-&nbsp;True&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted,&nbsp;otherwise&nbsp;False.</span></dd></dl>

<dl><dt><a name="BaseSVM-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Computes&nbsp;the&nbsp;decision&nbsp;function&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Input&nbsp;samples.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;decision_values:&nbsp;(ndarray&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Decision&nbsp;function&nbsp;values.</span></dd></dl>

<dl><dt><a name="BaseSVM-fit"><strong>fit</strong></a>(self, X, y=None)</dt><dd><span class="code">Fits&nbsp;the&nbsp;SVM&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Training&nbsp;vectors.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Target&nbsp;values.&nbsp;Default&nbsp;is&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;fitted&nbsp;instance.</span></dd></dl>

<dl><dt><a name="BaseSVM-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><span class="code">Retrieves&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;deep:&nbsp;(bool)&nbsp;-&nbsp;If&nbsp;True,&nbsp;returns&nbsp;parameters&nbsp;of&nbsp;subobjects&nbsp;as&nbsp;well.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;params:&nbsp;(dict)&nbsp;-&nbsp;Dictionary&nbsp;of&nbsp;hyperparameter&nbsp;names&nbsp;and&nbsp;values.</span></dd></dl>

<dl><dt><a name="BaseSVM-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Input&nbsp;samples.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;predicted_labels:&nbsp;(ndarray&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Predicted&nbsp;class&nbsp;labels.</span></dd></dl>

<dl><dt><a name="BaseSVM-score"><strong>score</strong></a>(self, X, y)</dt><dd><span class="code">Computes&nbsp;the&nbsp;mean&nbsp;accuracy&nbsp;of&nbsp;the&nbsp;model&nbsp;on&nbsp;the&nbsp;given&nbsp;test&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Test&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;True&nbsp;class&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;score:&nbsp;(float)&nbsp;-&nbsp;Mean&nbsp;accuracy&nbsp;of&nbsp;predictions.</span></dd></dl>

<dl><dt><a name="BaseSVM-set_params"><strong>set_params</strong></a>(self, **parameters)</dt><dd><span class="code">Sets&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;**parameters:&nbsp;(dict)&nbsp;-&nbsp;Hyperparameter&nbsp;names&nbsp;and&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;updated&nbsp;estimator&nbsp;instance.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Bayesian">class <strong>Bayesian</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#Bayesian">Bayesian</a>(max_iter=300,&nbsp;tol=0.001,&nbsp;alpha_1=1e-06,&nbsp;alpha_2=1e-06,&nbsp;lambda_1=1e-06,&nbsp;lambda_2=1e-06,&nbsp;fit_intercept=None)<br>
&nbsp;<br>
Fits&nbsp;the&nbsp;<a href="#Bayesian">Bayesian</a>&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data&nbsp;using&nbsp;Coordinate&nbsp;Descent.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;feature&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;target&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;to&nbsp;perform&nbsp;(default&nbsp;is&nbsp;300).<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;convergence&nbsp;threshold.&nbsp;The&nbsp;algorithm&nbsp;stops&nbsp;when&nbsp;the&nbsp;coefficients&nbsp;change&nbsp;less&nbsp;than&nbsp;this&nbsp;threshold&nbsp;(default&nbsp;is&nbsp;0.001).<br>
&nbsp;&nbsp;&nbsp;&nbsp;alpha_1:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;shape&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;weights&nbsp;(default&nbsp;is&nbsp;1e-06).<br>
&nbsp;&nbsp;&nbsp;&nbsp;alpha_2:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;scale&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;weights&nbsp;(default&nbsp;is&nbsp;1e-06).<br>
&nbsp;&nbsp;&nbsp;&nbsp;lambda_1:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;shape&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;noise&nbsp;(default&nbsp;is&nbsp;1e-06).<br>
&nbsp;&nbsp;&nbsp;&nbsp;lambda_2:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;scale&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;noise&nbsp;(default&nbsp;is&nbsp;1e-06).<br>
&nbsp;&nbsp;&nbsp;&nbsp;fit_intercept:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model&nbsp;(default&nbsp;is&nbsp;True).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;intercept_:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;intercept&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef_:&nbsp;(np.ndarray)&nbsp;-&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;linear&nbsp;regression&nbsp;problem.&nbsp;If&nbsp;`fit_intercept`&nbsp;is&nbsp;True,&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;the&nbsp;intercept.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_iter_:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;iterations&nbsp;performed.<br>
&nbsp;&nbsp;&nbsp;&nbsp;alpha_:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;precision&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lambda_:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;precision&nbsp;of&nbsp;the&nbsp;noise.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sigma_:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;posterior&nbsp;covariance&nbsp;of&nbsp;the&nbsp;weights.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="Bayesian-__init__"><strong>__init__</strong></a>(self, max_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, fit_intercept=None)</dt><dd><span class="code">Implements&nbsp;<a href="#Bayesian">Bayesian</a>&nbsp;Regression&nbsp;using&nbsp;Coordinate&nbsp;Descent.<br>
&nbsp;<br>
<a href="#Bayesian">Bayesian</a>&nbsp;regression&nbsp;applies&nbsp;both&nbsp;L1&nbsp;and&nbsp;L2&nbsp;regularization&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;penalty&nbsp;terms&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;to&nbsp;perform&nbsp;(default&nbsp;is&nbsp;300).<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;convergence&nbsp;threshold.&nbsp;The&nbsp;algorithm&nbsp;stops&nbsp;when&nbsp;the&nbsp;coefficients&nbsp;change&nbsp;less&nbsp;than&nbsp;this&nbsp;threshold&nbsp;(default&nbsp;is&nbsp;0.001).<br>
&nbsp;&nbsp;&nbsp;&nbsp;alpha_1:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;shape&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;weights&nbsp;(default&nbsp;is&nbsp;1e-06).<br>
&nbsp;&nbsp;&nbsp;&nbsp;alpha_2:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;scale&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;weights&nbsp;(default&nbsp;is&nbsp;1e-06).<br>
&nbsp;&nbsp;&nbsp;&nbsp;lambda_1:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;shape&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;noise&nbsp;(default&nbsp;is&nbsp;1e-06).<br>
&nbsp;&nbsp;&nbsp;&nbsp;lambda_2:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;scale&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;noise&nbsp;(default&nbsp;is&nbsp;1e-06).<br>
&nbsp;&nbsp;&nbsp;&nbsp;fit_intercept:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model&nbsp;(default&nbsp;is&nbsp;True).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;intercept_:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;intercept&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef_:&nbsp;(np.ndarray)&nbsp;-&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;linear&nbsp;regression&nbsp;problem.&nbsp;If&nbsp;`fit_intercept`&nbsp;is&nbsp;True,&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;the&nbsp;intercept.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_iter_:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;iterations&nbsp;performed.<br>
&nbsp;&nbsp;&nbsp;&nbsp;alpha_:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;precision&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lambda_:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;precision&nbsp;of&nbsp;the&nbsp;noise.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sigma_:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;posterior&nbsp;covariance&nbsp;of&nbsp;the&nbsp;weights.</span></dd></dl>

<dl><dt><a name="Bayesian-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;the&nbsp;string&nbsp;representation&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="Bayesian-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fits&nbsp;the&nbsp;<a href="#Bayesian">Bayesian</a>&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#Bayesian">Bayesian</a>)&nbsp;-&nbsp;The&nbsp;fitted&nbsp;<a href="#Bayesian">Bayesian</a>&nbsp;Regression&nbsp;model.</span></dd></dl>

<dl><dt><a name="Bayesian-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Computes&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;formula:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;formula&nbsp;of&nbsp;the&nbsp;model&nbsp;as&nbsp;a&nbsp;string.</span></dd></dl>

<dl><dt><a name="Bayesian-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;using&nbsp;the&nbsp;<a href="#Bayesian">Bayesian</a>&nbsp;Regression&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;Predicted&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<dl><dt><a name="Bayesian-tune"><strong>tune</strong></a>(self, X, y, beta1=0.9, beta2=0.999, iter=1000)</dt><dd><span class="code">Tunes&nbsp;the&nbsp;hyperparameters&nbsp;alpha_1,&nbsp;alpha_2,&nbsp;lambda_1,&nbsp;and&nbsp;lambda_2&nbsp;using&nbsp;ADAM&nbsp;optimizer.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta1:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;first&nbsp;moment&nbsp;estimates&nbsp;(default&nbsp;is&nbsp;0.9).<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta2:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;second&nbsp;moment&nbsp;estimates&nbsp;(default&nbsp;is&nbsp;0.999).<br>
&nbsp;&nbsp;&nbsp;&nbsp;iter:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;to&nbsp;perform&nbsp;(default&nbsp;is&nbsp;1000).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_alpha_1:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;best&nbsp;value&nbsp;of&nbsp;alpha_1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_alpha_2:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;best&nbsp;value&nbsp;of&nbsp;alpha_2.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_lambda_1:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;best&nbsp;value&nbsp;of&nbsp;lambda_1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_lambda_2:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;best&nbsp;value&nbsp;of&nbsp;lambda_2.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="ClassifierTree">class <strong>ClassifierTree</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#ClassifierTree">ClassifierTree</a>(max_depth=5,&nbsp;min_samples_split=2)<br>
&nbsp;<br>
A&nbsp;class&nbsp;representing&nbsp;a&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#ClassifierTree-learn">learn</a>(X,&nbsp;y,&nbsp;par_node={},&nbsp;depth=0):&nbsp;Builds&nbsp;the&nbsp;decision&nbsp;tree&nbsp;based&nbsp;on&nbsp;the&nbsp;given&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#ClassifierTree-classify">classify</a>(record):&nbsp;Classifies&nbsp;a&nbsp;record&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="ClassifierTree-__init__"><strong>__init__</strong></a>(self, max_depth=5, min_samples_split=2)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#ClassifierTree">ClassifierTree</a>&nbsp;with&nbsp;a&nbsp;maximum&nbsp;depth.</span></dd></dl>

<dl><dt><a name="ClassifierTree-fit"><strong>fit</strong></a>(self, X, y, sample_weight=None)</dt><dd><span class="code">Fits&nbsp;the&nbsp;decision&nbsp;tree&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).</span></dd></dl>

<dl><dt><a name="ClassifierTree-learn"><strong>learn</strong></a>(self, X, y, par_node=None, depth=0, sample_weight=None)</dt><dd><span class="code">Builds&nbsp;the&nbsp;decision&nbsp;tree&nbsp;based&nbsp;on&nbsp;the&nbsp;given&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;par_node:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;parent&nbsp;node&nbsp;of&nbsp;the&nbsp;current&nbsp;subtree&nbsp;(default:&nbsp;{}).<br>
&nbsp;&nbsp;&nbsp;&nbsp;depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;current&nbsp;depth&nbsp;of&nbsp;the&nbsp;subtree&nbsp;(default:&nbsp;0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;The&nbsp;learned&nbsp;decision&nbsp;tree.</span></dd></dl>

<dl><dt><a name="ClassifierTree-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;labels&nbsp;for&nbsp;a&nbsp;given&nbsp;set&nbsp;of&nbsp;records&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;A&nbsp;list&nbsp;of&nbsp;predicted&nbsp;labels&nbsp;for&nbsp;each&nbsp;record.</span></dd></dl>

<dl><dt><a name="ClassifierTree-predict_proba"><strong>predict_proba</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;probabilities&nbsp;for&nbsp;a&nbsp;given&nbsp;set&nbsp;of&nbsp;records&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;A&nbsp;list&nbsp;of&nbsp;dictionaries&nbsp;where&nbsp;each&nbsp;dictionary&nbsp;represents&nbsp;the&nbsp;probability&nbsp;distribution<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;over&nbsp;the&nbsp;classes&nbsp;for&nbsp;a&nbsp;record.</span></dd></dl>

<hr>
Static methods defined here:<br>
<dl><dt><a name="ClassifierTree-classify"><strong>classify</strong></a>(tree, record)</dt><dd><span class="code">Classifies&nbsp;a&nbsp;given&nbsp;record&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;decision&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;record:&nbsp;(dict)&nbsp;-&nbsp;A&nbsp;dictionary&nbsp;representing&nbsp;the&nbsp;record&nbsp;to&nbsp;be&nbsp;classified.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;label&nbsp;assigned&nbsp;to&nbsp;the&nbsp;record&nbsp;based&nbsp;on&nbsp;the&nbsp;decision&nbsp;tree.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="ClassifierTreeUtility">class <strong>ClassifierTreeUtility</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#ClassifierTreeUtility">ClassifierTreeUtility</a>(min_samples_split=2)<br>
&nbsp;<br>
Utility&nbsp;class&nbsp;for&nbsp;computing&nbsp;entropy,&nbsp;partitioning&nbsp;classes,&nbsp;and&nbsp;calculating&nbsp;information&nbsp;gain.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="ClassifierTreeUtility-__init__"><strong>__init__</strong></a>(self, min_samples_split=2)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;utility&nbsp;class.</span></dd></dl>

<dl><dt><a name="ClassifierTreeUtility-best_split"><strong>best_split</strong></a>(self, X, y, sample_weight=None)</dt><dd><span class="code">Finds&nbsp;the&nbsp;best&nbsp;attribute&nbsp;and&nbsp;value&nbsp;to&nbsp;split&nbsp;the&nbsp;data&nbsp;based&nbsp;on&nbsp;information&nbsp;gain.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;variable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;the&nbsp;best&nbsp;split&nbsp;attribute,&nbsp;split&nbsp;value,&nbsp;left&nbsp;and&nbsp;right&nbsp;subsets&nbsp;of&nbsp;X&nbsp;and&nbsp;y,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;the&nbsp;information&nbsp;gain&nbsp;achieved&nbsp;by&nbsp;the&nbsp;split.</span></dd></dl>

<dl><dt><a name="ClassifierTreeUtility-entropy"><strong>entropy</strong></a>(self, class_y, sample_weight=None)</dt><dd><span class="code">Computes&nbsp;the&nbsp;entropy&nbsp;for&nbsp;a&nbsp;given&nbsp;class.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;class_y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;class&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;entropy&nbsp;value.</span></dd></dl>

<dl><dt><a name="ClassifierTreeUtility-information_gain"><strong>information_gain</strong></a>(self, previous_y, current_y, sample_weight_prev=None, sample_weight_current=None)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;information&nbsp;gain&nbsp;between&nbsp;the&nbsp;previous&nbsp;and&nbsp;current&nbsp;values&nbsp;of&nbsp;y.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;previous_y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;previous&nbsp;values&nbsp;of&nbsp;y.<br>
&nbsp;&nbsp;&nbsp;&nbsp;current_y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;current&nbsp;values&nbsp;of&nbsp;y.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight_prev:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;for&nbsp;the&nbsp;previous&nbsp;y&nbsp;values&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight_current:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;for&nbsp;the&nbsp;current&nbsp;y&nbsp;values&nbsp;(default:&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;information&nbsp;gain&nbsp;between&nbsp;the&nbsp;previous&nbsp;and&nbsp;current&nbsp;values&nbsp;of&nbsp;y.</span></dd></dl>

<dl><dt><a name="ClassifierTreeUtility-partition_classes"><strong>partition_classes</strong></a>(self, X, y, split_attribute, split_val, sample_weight=None)</dt><dd><span class="code">Partitions&nbsp;the&nbsp;dataset&nbsp;into&nbsp;two&nbsp;subsets&nbsp;based&nbsp;on&nbsp;a&nbsp;given&nbsp;split&nbsp;attribute&nbsp;and&nbsp;value.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;split_attribute:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;attribute&nbsp;to&nbsp;split&nbsp;on.<br>
&nbsp;&nbsp;&nbsp;&nbsp;split_val:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;value&nbsp;to&nbsp;split&nbsp;the&nbsp;attribute&nbsp;on.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_left:&nbsp;&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;subset&nbsp;of&nbsp;input&nbsp;features&nbsp;where&nbsp;the&nbsp;split&nbsp;attribute&nbsp;is&nbsp;less&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;the&nbsp;split&nbsp;value.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_right:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;subset&nbsp;of&nbsp;input&nbsp;features&nbsp;where&nbsp;the&nbsp;split&nbsp;attribute&nbsp;is&nbsp;greater&nbsp;than&nbsp;the&nbsp;split&nbsp;value.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_left:&nbsp;&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;subset&nbsp;of&nbsp;target&nbsp;labels&nbsp;corresponding&nbsp;to&nbsp;X_left.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_right:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;subset&nbsp;of&nbsp;target&nbsp;labels&nbsp;corresponding&nbsp;to&nbsp;X_right.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="ConvLayer">class <strong>ConvLayer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#ConvLayer">ConvLayer</a>(in_channels,&nbsp;out_channels,&nbsp;kernel_size,&nbsp;stride=1,&nbsp;padding=0,&nbsp;activation='relu')<br>
&nbsp;<br>
A&nbsp;convolutional&nbsp;layer&nbsp;implementation&nbsp;for&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
This&nbsp;layer&nbsp;performs&nbsp;2D&nbsp;convolution&nbsp;operations,&nbsp;commonly&nbsp;used&nbsp;in&nbsp;convolutional&nbsp;neural&nbsp;networks&nbsp;(CNNs).<br>
The&nbsp;implementation&nbsp;uses&nbsp;the&nbsp;im2col&nbsp;technique&nbsp;for&nbsp;efficient&nbsp;computation,&nbsp;transforming&nbsp;the&nbsp;convolution&nbsp;operation&nbsp;into&nbsp;matrix&nbsp;multiplication.<br>
An&nbsp;optional&nbsp;activation&nbsp;function&nbsp;is&nbsp;applied&nbsp;element-wise&nbsp;to&nbsp;the&nbsp;output.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;in_channels&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;input&nbsp;channels&nbsp;(depth&nbsp;of&nbsp;input&nbsp;volume).<br>
&nbsp;&nbsp;&nbsp;&nbsp;out_channels&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;output&nbsp;channels&nbsp;(number&nbsp;of&nbsp;filters).<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel_size&nbsp;(int):&nbsp;Size&nbsp;of&nbsp;the&nbsp;convolutional&nbsp;kernel&nbsp;(square&nbsp;kernel&nbsp;assumed).<br>
&nbsp;&nbsp;&nbsp;&nbsp;stride&nbsp;(int,&nbsp;optional):&nbsp;Stride&nbsp;of&nbsp;the&nbsp;convolution.&nbsp;Default:&nbsp;1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;padding&nbsp;(int,&nbsp;optional):&nbsp;Zero-padding&nbsp;added&nbsp;to&nbsp;both&nbsp;sides&nbsp;of&nbsp;the&nbsp;input.&nbsp;Default:&nbsp;0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation&nbsp;(str,&nbsp;optional):&nbsp;<a href="#Activation">Activation</a>&nbsp;function&nbsp;to&nbsp;use.&nbsp;Options&nbsp;are&nbsp;"relu",&nbsp;"sigmoid",&nbsp;"tanh",&nbsp;or&nbsp;None.&nbsp;Default:&nbsp;"relu".<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;in_channels&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;input&nbsp;channels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;out_channels&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;output&nbsp;channels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel_size&nbsp;(int):&nbsp;Size&nbsp;of&nbsp;the&nbsp;square&nbsp;convolutional&nbsp;kernel.<br>
&nbsp;&nbsp;&nbsp;&nbsp;stride&nbsp;(int):&nbsp;Stride&nbsp;of&nbsp;the&nbsp;convolution.<br>
&nbsp;&nbsp;&nbsp;&nbsp;padding&nbsp;(int):&nbsp;Zero-padding&nbsp;added&nbsp;to&nbsp;both&nbsp;sides&nbsp;of&nbsp;the&nbsp;input.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights&nbsp;(numpy.ndarray):&nbsp;Learnable&nbsp;weights&nbsp;of&nbsp;shape&nbsp;(out_channels,&nbsp;in_channels,&nbsp;kernel_size,&nbsp;kernel_size).<br>
&nbsp;&nbsp;&nbsp;&nbsp;biases&nbsp;(numpy.ndarray):&nbsp;Learnable&nbsp;biases&nbsp;of&nbsp;shape&nbsp;(out_channels,&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation&nbsp;(str):&nbsp;Type&nbsp;of&nbsp;activation&nbsp;function.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weight_gradients&nbsp;(numpy.ndarray):&nbsp;Gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bias_gradients&nbsp;(numpy.ndarray):&nbsp;Gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_cache&nbsp;(numpy.ndarray):&nbsp;Cached&nbsp;input&nbsp;for&nbsp;use&nbsp;in&nbsp;backward&nbsp;pass.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_cols&nbsp;(numpy.ndarray):&nbsp;Cached&nbsp;column-transformed&nbsp;input.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_padded&nbsp;(numpy.ndarray):&nbsp;Cached&nbsp;padded&nbsp;input.<br>
&nbsp;&nbsp;&nbsp;&nbsp;h_out&nbsp;(int):&nbsp;Height&nbsp;of&nbsp;output&nbsp;feature&nbsp;maps.<br>
&nbsp;&nbsp;&nbsp;&nbsp;w_out&nbsp;(int):&nbsp;Width&nbsp;of&nbsp;output&nbsp;feature&nbsp;maps.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size&nbsp;(int):&nbsp;Size&nbsp;of&nbsp;input&nbsp;(same&nbsp;as&nbsp;in_channels).<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size&nbsp;(int):&nbsp;Size&nbsp;of&nbsp;output&nbsp;(same&nbsp;as&nbsp;out_channels).<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#ConvLayer-zero_grad">zero_grad</a>():&nbsp;Reset&nbsp;gradients&nbsp;to&nbsp;zero.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_im2col(x,&nbsp;h_out,&nbsp;w_out):&nbsp;Convert&nbsp;image&nbsp;regions&nbsp;to&nbsp;columns&nbsp;for&nbsp;efficient&nbsp;convolution.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#ConvLayer-forward">forward</a>(X):&nbsp;Perform&nbsp;forward&nbsp;pass&nbsp;of&nbsp;the&nbsp;convolutional&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_col2im(dcol,&nbsp;x_shape):&nbsp;Convert&nbsp;column&nbsp;back&nbsp;to&nbsp;image&nbsp;format&nbsp;for&nbsp;the&nbsp;backward&nbsp;pass.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#ConvLayer-backward">backward</a>(d_out,&nbsp;reg_lambda=0):&nbsp;Perform&nbsp;backward&nbsp;pass&nbsp;of&nbsp;the&nbsp;convolutional&nbsp;layer.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="ConvLayer-__init__"><strong>__init__</strong></a>(self, in_channels, out_channels, kernel_size, stride=1, padding=0, activation='relu')</dt><dd><span class="code">Initializes&nbsp;a&nbsp;convolutional&nbsp;layer&nbsp;<a href="builtins.html#object">object</a>&nbsp;for&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
This&nbsp;layer&nbsp;performs&nbsp;2D&nbsp;convolution&nbsp;operations,&nbsp;commonly&nbsp;used&nbsp;in&nbsp;convolutional&nbsp;neural&nbsp;networks&nbsp;(CNNs).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;in_channels:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;input&nbsp;channels&nbsp;(depth&nbsp;of&nbsp;input&nbsp;volume).<br>
&nbsp;&nbsp;&nbsp;&nbsp;out_channels:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;output&nbsp;channels&nbsp;(number&nbsp;of&nbsp;filters).<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel_size:&nbsp;(int)&nbsp;-&nbsp;Size&nbsp;of&nbsp;the&nbsp;convolutional&nbsp;kernel&nbsp;(square&nbsp;kernel&nbsp;assumed).<br>
&nbsp;&nbsp;&nbsp;&nbsp;stride:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Stride&nbsp;of&nbsp;the&nbsp;convolution&nbsp;(default&nbsp;is&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;padding:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Zero-padding&nbsp;added&nbsp;to&nbsp;both&nbsp;sides&nbsp;of&nbsp;the&nbsp;input&nbsp;(default&nbsp;is&nbsp;0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation:&nbsp;(str),&nbsp;optional&nbsp;-&nbsp;<a href="#Activation">Activation</a>&nbsp;function&nbsp;to&nbsp;use&nbsp;(default&nbsp;is&nbsp;"relu").<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;in_channels:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;input&nbsp;channels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;out_channels:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;output&nbsp;channels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel_size:&nbsp;(int)&nbsp;-&nbsp;Size&nbsp;of&nbsp;the&nbsp;square&nbsp;convolutional&nbsp;kernel.<br>
&nbsp;&nbsp;&nbsp;&nbsp;stride:&nbsp;(int)&nbsp;-&nbsp;Stride&nbsp;of&nbsp;the&nbsp;convolution.<br>
&nbsp;&nbsp;&nbsp;&nbsp;padding:&nbsp;(int)&nbsp;-&nbsp;Zero-padding&nbsp;added&nbsp;to&nbsp;both&nbsp;sides&nbsp;of&nbsp;the&nbsp;input.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights:&nbsp;(np.ndarray)&nbsp;-&nbsp;Learnable&nbsp;weights&nbsp;of&nbsp;shape&nbsp;(out_channels,&nbsp;in_channels,&nbsp;kernel_size,&nbsp;kernel_size).<br>
&nbsp;&nbsp;&nbsp;&nbsp;biases:&nbsp;(np.ndarray)&nbsp;-&nbsp;Learnable&nbsp;biases&nbsp;of&nbsp;shape&nbsp;(out_channels,&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation:&nbsp;(str)&nbsp;-&nbsp;Type&nbsp;of&nbsp;activation&nbsp;function.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weight_gradients:&nbsp;(np.ndarray&nbsp;or&nbsp;None)&nbsp;-&nbsp;Gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;weights,&nbsp;initialized&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bias_gradients:&nbsp;(np.ndarray&nbsp;or&nbsp;None)&nbsp;-&nbsp;Gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;biases,&nbsp;initialized&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_cache:&nbsp;(np.ndarray&nbsp;or&nbsp;None)&nbsp;-&nbsp;Cached&nbsp;input&nbsp;for&nbsp;use&nbsp;in&nbsp;backward&nbsp;pass.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size:&nbsp;(int)&nbsp;-&nbsp;Size&nbsp;of&nbsp;input&nbsp;(same&nbsp;as&nbsp;in_channels).<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int)&nbsp;-&nbsp;Size&nbsp;of&nbsp;output&nbsp;(same&nbsp;as&nbsp;out_channels).</span></dd></dl>

<dl><dt><a name="ConvLayer-activate"><strong>activate</strong></a>(self, Z)</dt><dd><span class="code">Apply&nbsp;activation&nbsp;function.</span></dd></dl>

<dl><dt><a name="ConvLayer-backward"><strong>backward</strong></a>(self, d_out, reg_lambda=0)</dt><dd><span class="code">Optimized&nbsp;backward&nbsp;pass&nbsp;using&nbsp;im2col&nbsp;technique.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;d_out:&nbsp;(np.ndarray)&nbsp;-&nbsp;Gradient&nbsp;of&nbsp;the&nbsp;loss&nbsp;with&nbsp;respect&nbsp;to&nbsp;the&nbsp;layer&nbsp;output,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shape&nbsp;(batch_size,&nbsp;out_channels,&nbsp;h_out,&nbsp;w_out)<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda:&nbsp;(float,&nbsp;optional)&nbsp;-&nbsp;Regularization&nbsp;parameter.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dX:&nbsp;Gradient&nbsp;with&nbsp;respect&nbsp;to&nbsp;the&nbsp;input&nbsp;X.</span></dd></dl>

<dl><dt><a name="ConvLayer-forward"><strong>forward</strong></a>(self, X)</dt><dd><span class="code">Perform&nbsp;forward&nbsp;pass&nbsp;of&nbsp;the&nbsp;convolutional&nbsp;layer.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;numpy&nbsp;array&nbsp;with&nbsp;shape&nbsp;(batch_size,&nbsp;in_channels,&nbsp;height,&nbsp;width)<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Output&nbsp;feature&nbsp;maps&nbsp;after&nbsp;convolution&nbsp;and&nbsp;activation.</span></dd></dl>

<dl><dt><a name="ConvLayer-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><span class="code">Reset&nbsp;the&nbsp;gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;to&nbsp;zero.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="CrossEntropyLoss">class <strong>CrossEntropyLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;cross&nbsp;entropy&nbsp;loss&nbsp;implementation&nbsp;using&nbsp;numpy&nbsp;for&nbsp;multi-class&nbsp;classification.<br>
&nbsp;<br>
Formula:&nbsp;-sum(y&nbsp;*&nbsp;log(p)&nbsp;+&nbsp;(1&nbsp;-&nbsp;y)&nbsp;*&nbsp;log(1&nbsp;-&nbsp;p))&nbsp;/&nbsp;m<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#CrossEntropyLoss-__call__">__call__</a>(self,&nbsp;logits,&nbsp;targets):&nbsp;Calculate&nbsp;the&nbsp;cross&nbsp;entropy&nbsp;loss.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="CrossEntropyLoss-__call__"><strong>__call__</strong></a>(self, logits, targets)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;cross&nbsp;entropy&nbsp;loss.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;logits&nbsp;(np.ndarray):&nbsp;The&nbsp;logits&nbsp;(predicted&nbsp;values)&nbsp;of&nbsp;shape&nbsp;(num_samples,&nbsp;num_classes).<br>
&nbsp;&nbsp;&nbsp;&nbsp;targets&nbsp;(np.ndarray):&nbsp;The&nbsp;target&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;cross&nbsp;entropy&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="DBSCAN">class <strong>DBSCAN</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#DBSCAN">DBSCAN</a>(X,&nbsp;eps=0.5,&nbsp;min_samples=5,&nbsp;compile_numba=False)<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;the&nbsp;Density-Based&nbsp;Spatial&nbsp;Clustering&nbsp;of&nbsp;Applications&nbsp;with&nbsp;Noise&nbsp;(<a href="#DBSCAN">DBSCAN</a>)&nbsp;algorithm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
&nbsp;&nbsp;&nbsp;&nbsp;eps:&nbsp;The&nbsp;maximum&nbsp;distance&nbsp;between&nbsp;two&nbsp;samples&nbsp;for&nbsp;one&nbsp;to&nbsp;be&nbsp;considered&nbsp;as&nbsp;in&nbsp;the&nbsp;neighborhood&nbsp;of&nbsp;the&nbsp;other.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples:&nbsp;The&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;a&nbsp;neighborhood&nbsp;for&nbsp;a&nbsp;point&nbsp;to&nbsp;be&nbsp;considered&nbsp;as&nbsp;a&nbsp;core&nbsp;point.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;__init__:&nbsp;Initializes&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;<a href="builtins.html#object">object</a>&nbsp;with&nbsp;the&nbsp;input&nbsp;parameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;fit:&nbsp;Fits&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;and&nbsp;assigns&nbsp;cluster&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;predict:&nbsp;Predicts&nbsp;the&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;new&nbsp;data&nbsp;points.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;fit_predict:&nbsp;Fits&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;model&nbsp;and&nbsp;returns&nbsp;cluster&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;silhouette_score:&nbsp;Calculates&nbsp;the&nbsp;Silhouette&nbsp;Score&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;_handle_categorical:&nbsp;Handles&nbsp;categorical&nbsp;columns&nbsp;by&nbsp;one-hot&nbsp;encoding.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;_convert_to_ndarray:&nbsp;Converts&nbsp;input&nbsp;data&nbsp;to&nbsp;a&nbsp;NumPy&nbsp;ndarray&nbsp;and&nbsp;handles&nbsp;categorical&nbsp;columns.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;_custom_distance_matrix:&nbsp;Calculates&nbsp;the&nbsp;pairwise&nbsp;distance&nbsp;matrix&nbsp;using&nbsp;a&nbsp;custom&nbsp;distance&nbsp;calculation&nbsp;method.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="DBSCAN-__init__"><strong>__init__</strong></a>(self, X, eps=0.5, min_samples=5, compile_numba=False)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
&nbsp;&nbsp;&nbsp;&nbsp;eps:&nbsp;The&nbsp;maximum&nbsp;distance&nbsp;between&nbsp;two&nbsp;samples&nbsp;for&nbsp;one&nbsp;to&nbsp;be&nbsp;considered&nbsp;as&nbsp;in&nbsp;the&nbsp;neighborhood&nbsp;of&nbsp;the&nbsp;other.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples:&nbsp;The&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;a&nbsp;neighborhood&nbsp;for&nbsp;a&nbsp;point&nbsp;to&nbsp;be&nbsp;considered&nbsp;as&nbsp;a&nbsp;core&nbsp;point.<br>
&nbsp;&nbsp;&nbsp;&nbsp;compile_numba:&nbsp;Whether&nbsp;to&nbsp;compile&nbsp;the&nbsp;distance&nbsp;calculations&nbsp;using&nbsp;Numba&nbsp;for&nbsp;performance.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;not&nbsp;compiled,&nbsp;the&nbsp;first&nbsp;call&nbsp;to&nbsp;the&nbsp;numba&nbsp;fitting&nbsp;function&nbsp;will&nbsp;take&nbsp;longer,&nbsp;but&nbsp;subsequent&nbsp;calls&nbsp;will&nbsp;be&nbsp;faster.</span></dd></dl>

<dl><dt><a name="DBSCAN-auto_eps"><strong>auto_eps</strong></a>(self, min=0.1, max=1.1, precision=0.01, return_scores=False, verbose=False)</dt><dd><span class="code">Find&nbsp;the&nbsp;optimal&nbsp;eps&nbsp;value&nbsp;for&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;based&nbsp;on&nbsp;silhouette&nbsp;score.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;min:&nbsp;The&nbsp;minimum&nbsp;eps&nbsp;value&nbsp;to&nbsp;start&nbsp;the&nbsp;search.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max:&nbsp;The&nbsp;maximum&nbsp;eps&nbsp;value&nbsp;to&nbsp;end&nbsp;the&nbsp;search.<br>
&nbsp;&nbsp;&nbsp;&nbsp;precision:&nbsp;The&nbsp;precision&nbsp;of&nbsp;the&nbsp;search.<br>
&nbsp;&nbsp;&nbsp;&nbsp;return_scores:&nbsp;Whether&nbsp;to&nbsp;return&nbsp;a&nbsp;dictionary&nbsp;of&nbsp;(eps,&nbsp;score)&nbsp;pairs.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;Whether&nbsp;to&nbsp;print&nbsp;the&nbsp;silhouette&nbsp;score&nbsp;for&nbsp;each&nbsp;eps&nbsp;value.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;eps:&nbsp;The&nbsp;optimal&nbsp;eps&nbsp;value.<br>
&nbsp;&nbsp;&nbsp;&nbsp;scores_dict&nbsp;(optional):&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;(eps,&nbsp;score)&nbsp;pairs&nbsp;if&nbsp;return_scores&nbsp;is&nbsp;True.</span></dd></dl>

<dl><dt><a name="DBSCAN-fit"><strong>fit</strong></a>(self, metric='euclidean', numba=False)</dt><dd><span class="code">Fit&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Algorithm&nbsp;Steps:<br>
1.&nbsp;Calculate&nbsp;the&nbsp;distance&nbsp;matrix&nbsp;between&nbsp;all&nbsp;points&nbsp;in&nbsp;the&nbsp;dataset.<br>
2.&nbsp;Identify&nbsp;core&nbsp;points&nbsp;based&nbsp;on&nbsp;the&nbsp;minimum&nbsp;number&nbsp;of&nbsp;neighbors&nbsp;within&nbsp;eps&nbsp;distance.<br>
3.&nbsp;Assign&nbsp;cluster&nbsp;labels&nbsp;using&nbsp;depth-first&nbsp;search&nbsp;(DFS)&nbsp;starting&nbsp;from&nbsp;core&nbsp;points.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;metric:&nbsp;The&nbsp;distance&nbsp;metric&nbsp;to&nbsp;use&nbsp;('euclidean',&nbsp;'manhattan',&nbsp;or&nbsp;'cosine').<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba:&nbsp;Whether&nbsp;to&nbsp;use&nbsp;numba&nbsp;for&nbsp;faster&nbsp;computation.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;each&nbsp;data&nbsp;point.</span></dd></dl>

<dl><dt><a name="DBSCAN-fit_predict"><strong>fit_predict</strong></a>(self, numba=False)</dt><dd><span class="code">Fit&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;and&nbsp;return&nbsp;the&nbsp;cluster&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;the&nbsp;data.</span></dd></dl>

<dl><dt><a name="DBSCAN-predict"><strong>predict</strong></a>(self, new_X)</dt><dd><span class="code">Predict&nbsp;the&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;new&nbsp;data&nbsp;points.<br>
&nbsp;<br>
Note:&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;does&nbsp;not&nbsp;naturally&nbsp;support&nbsp;predicting&nbsp;new&nbsp;data&nbsp;points.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;new_X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;to&nbsp;predict&nbsp;(numpy&nbsp;array).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels:&nbsp;The&nbsp;predicted&nbsp;cluster&nbsp;labels&nbsp;(-1&nbsp;for&nbsp;noise).</span></dd></dl>

<dl><dt><a name="DBSCAN-silhouette_score"><strong>silhouette_score</strong></a>(self)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;silhouette&nbsp;score&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;silhouette_score:&nbsp;The&nbsp;computed&nbsp;silhouette&nbsp;score.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="DataPrep">class <strong>DataPrep</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">A&nbsp;class&nbsp;for&nbsp;preparing&nbsp;data&nbsp;for&nbsp;machine&nbsp;learning&nbsp;models.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="DataPrep-df_to_ndarray"><strong>df_to_ndarray</strong></a>(df, y_col=0)</dt><dd><span class="code">Converts&nbsp;a&nbsp;DataFrame&nbsp;to&nbsp;a&nbsp;NumPy&nbsp;array.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;df:&nbsp;(pandas.DataFrame)&nbsp;-&nbsp;The&nbsp;DataFrame&nbsp;to&nbsp;be&nbsp;converted.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_col:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;label&nbsp;column&nbsp;(default&nbsp;is&nbsp;0).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;feature&nbsp;columns&nbsp;as&nbsp;a&nbsp;NumPy&nbsp;array.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;label&nbsp;column&nbsp;as&nbsp;a&nbsp;NumPy&nbsp;array.</span></dd></dl>

<dl><dt><a name="DataPrep-find_categorical_columns"><strong>find_categorical_columns</strong></a>(data)</dt><dd><span class="code">Finds&nbsp;the&nbsp;indices&nbsp;of&nbsp;non-numerical&nbsp;columns&nbsp;in&nbsp;a&nbsp;DataFrame&nbsp;or&nbsp;numpy&nbsp;array.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;data:&nbsp;(pandas.DataFrame&nbsp;or&nbsp;numpy.ndarray)&nbsp;-&nbsp;The&nbsp;data&nbsp;to&nbsp;be&nbsp;checked.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;categorical_cols:&nbsp;(list)&nbsp;-&nbsp;The&nbsp;list&nbsp;of&nbsp;indices&nbsp;of&nbsp;non-numerical&nbsp;columns.</span></dd></dl>

<dl><dt><a name="DataPrep-k_split"><strong>k_split</strong></a>(X, y, k=5)</dt><dd><span class="code">Splits&nbsp;the&nbsp;data&nbsp;into&nbsp;k&nbsp;folds&nbsp;for&nbsp;cross-validation.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;feature&nbsp;columns.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;label&nbsp;column.<br>
&nbsp;&nbsp;&nbsp;&nbsp;k:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;folds&nbsp;(default&nbsp;is&nbsp;5).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_folds:&nbsp;(list)&nbsp;-&nbsp;A&nbsp;list&nbsp;of&nbsp;k&nbsp;folds&nbsp;of&nbsp;feature&nbsp;columns.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_folds:&nbsp;(list)&nbsp;-&nbsp;A&nbsp;list&nbsp;of&nbsp;k&nbsp;folds&nbsp;of&nbsp;label&nbsp;columns.</span></dd></dl>

<dl><dt><a name="DataPrep-one_hot_encode"><strong>one_hot_encode</strong></a>(data, cols)</dt><dd><span class="code">One-hot&nbsp;encodes&nbsp;non-numerical&nbsp;columns&nbsp;in&nbsp;a&nbsp;DataFrame&nbsp;or&nbsp;numpy&nbsp;array.<br>
&nbsp;<br>
Drops&nbsp;the&nbsp;original&nbsp;columns&nbsp;after&nbsp;encoding.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;data:&nbsp;(pandas.DataFrame&nbsp;or&nbsp;numpy.ndarray)&nbsp;-&nbsp;The&nbsp;data&nbsp;to&nbsp;be&nbsp;encoded.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cols:&nbsp;(list)&nbsp;-&nbsp;The&nbsp;list&nbsp;of&nbsp;column&nbsp;indices&nbsp;to&nbsp;be&nbsp;encoded.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;data:&nbsp;(pandas.DataFrame&nbsp;or&nbsp;numpy.ndarray)&nbsp;-&nbsp;The&nbsp;data&nbsp;with&nbsp;one-hot&nbsp;encoded&nbsp;columns.</span></dd></dl>

<dl><dt><a name="DataPrep-prepare_data"><strong>prepare_data</strong></a>(csv_file, label_col_index, cols_to_encode=None, write_to_csv=True)</dt><dd><span class="code">Prepares&nbsp;the&nbsp;data&nbsp;by&nbsp;loading&nbsp;a&nbsp;CSV&nbsp;file,&nbsp;one-hot&nbsp;encoding&nbsp;non-numerical&nbsp;columns,&nbsp;and&nbsp;optionally&nbsp;writing&nbsp;the&nbsp;prepared&nbsp;data&nbsp;to&nbsp;a&nbsp;new&nbsp;CSV&nbsp;file.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;csv_file:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;path&nbsp;of&nbsp;the&nbsp;CSV&nbsp;file&nbsp;to&nbsp;load.<br>
&nbsp;&nbsp;&nbsp;&nbsp;label_col_index:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;label&nbsp;column.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cols_to_encode:&nbsp;(list),&nbsp;optional&nbsp;-&nbsp;The&nbsp;list&nbsp;of&nbsp;column&nbsp;indices&nbsp;to&nbsp;one-hot&nbsp;encode&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;write_to_csv:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;write&nbsp;the&nbsp;prepared&nbsp;data&nbsp;to&nbsp;a&nbsp;new&nbsp;CSV&nbsp;file&nbsp;(default&nbsp;is&nbsp;True).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;df:&nbsp;(pandas.DataFrame)&nbsp;-&nbsp;The&nbsp;prepared&nbsp;DataFrame.<br>
&nbsp;&nbsp;&nbsp;&nbsp;prepared_csv_file:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;path&nbsp;of&nbsp;the&nbsp;prepared&nbsp;CSV&nbsp;file.&nbsp;If&nbsp;write_to_csv&nbsp;is&nbsp;False,&nbsp;returns&nbsp;"N/A".</span></dd></dl>

<dl><dt><a name="DataPrep-write_data"><strong>write_data</strong></a>(df, csv_file, print_path=False)</dt><dd><span class="code">Writes&nbsp;the&nbsp;DataFrame&nbsp;to&nbsp;a&nbsp;CSV&nbsp;file.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;df:&nbsp;(pandas.DataFrame)&nbsp;-&nbsp;The&nbsp;DataFrame&nbsp;to&nbsp;be&nbsp;written.<br>
&nbsp;&nbsp;&nbsp;&nbsp;csv_file:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;path&nbsp;of&nbsp;the&nbsp;CSV&nbsp;file&nbsp;to&nbsp;write&nbsp;to.<br>
&nbsp;&nbsp;&nbsp;&nbsp;print_path:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;If&nbsp;True,&nbsp;prints&nbsp;the&nbsp;file&nbsp;path&nbsp;(default&nbsp;is&nbsp;False).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="DenseLayer">class <strong>DenseLayer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#DenseLayer">DenseLayer</a>(input_size,&nbsp;output_size,&nbsp;activation='relu')<br>
&nbsp;<br>
Initializes&nbsp;a&nbsp;fully&nbsp;connected&nbsp;layer&nbsp;<a href="builtins.html#object">object</a>,&nbsp;where&nbsp;each&nbsp;neuron&nbsp;is&nbsp;connected&nbsp;to&nbsp;all&nbsp;neurons&nbsp;in&nbsp;the&nbsp;previous&nbsp;layer.<br>
&nbsp;<br>
Each&nbsp;layer&nbsp;consists&nbsp;of&nbsp;weights,&nbsp;biases,&nbsp;and&nbsp;an&nbsp;activation&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size&nbsp;(int):&nbsp;The&nbsp;size&nbsp;of&nbsp;the&nbsp;input&nbsp;to&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size&nbsp;(int):&nbsp;The&nbsp;size&nbsp;of&nbsp;the&nbsp;output&nbsp;from&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation&nbsp;(str):&nbsp;The&nbsp;activation&nbsp;function&nbsp;to&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;layer.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights&nbsp;(np.ndarray):&nbsp;Weights&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;biases&nbsp;(np.ndarray):&nbsp;Biases&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation&nbsp;(str):&nbsp;<a href="#Activation">Activation</a>&nbsp;function&nbsp;name.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weight_gradients&nbsp;(np.ndarray):&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bias_gradients&nbsp;(np.ndarray):&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_cache&nbsp;(np.ndarray):&nbsp;Cached&nbsp;input&nbsp;for&nbsp;backpropagation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_cache&nbsp;(np.ndarray):&nbsp;Cached&nbsp;output&nbsp;for&nbsp;backpropagation.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#DenseLayer-zero_grad">zero_grad</a>():&nbsp;Resets&nbsp;the&nbsp;gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;to&nbsp;zero.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#DenseLayer-forward">forward</a>(X):&nbsp;Performs&nbsp;the&nbsp;forward&nbsp;pass&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#DenseLayer-backward">backward</a>(dA,&nbsp;reg_lambda):&nbsp;Performs&nbsp;the&nbsp;backward&nbsp;pass&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#DenseLayer-activate">activate</a>(Z):&nbsp;Applies&nbsp;the&nbsp;activation&nbsp;function.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#DenseLayer-activation_derivative">activation_derivative</a>(Z):&nbsp;Applies&nbsp;the&nbsp;derivative&nbsp;of&nbsp;the&nbsp;activation&nbsp;function.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="DenseLayer-__init__"><strong>__init__</strong></a>(self, input_size, output_size, activation='relu')</dt><dd><span class="code">Initializes&nbsp;the&nbsp;layer&nbsp;with&nbsp;weights,&nbsp;biases,&nbsp;and&nbsp;activation&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;input&nbsp;features&nbsp;to&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;output&nbsp;features&nbsp;from&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation:&nbsp;(str),&nbsp;optional&nbsp;-&nbsp;The&nbsp;activation&nbsp;function&nbsp;to&nbsp;use&nbsp;(default&nbsp;is&nbsp;"relu").<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;weight&nbsp;matrix&nbsp;initialized&nbsp;using&nbsp;He&nbsp;initialization&nbsp;for&nbsp;ReLU&nbsp;or&nbsp;Leaky&nbsp;ReLU,&nbsp;or&nbsp;standard&nbsp;initialization&nbsp;otherwise.<br>
&nbsp;&nbsp;&nbsp;&nbsp;biases:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;bias&nbsp;vector&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;input&nbsp;features&nbsp;to&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;output&nbsp;features&nbsp;from&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;activation&nbsp;function&nbsp;to&nbsp;use.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weight_gradients:&nbsp;(np.ndarray&nbsp;or&nbsp;None)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;weights,&nbsp;initialized&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bias_gradients:&nbsp;(np.ndarray&nbsp;or&nbsp;None)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;biases,&nbsp;initialized&nbsp;to&nbsp;None.</span></dd></dl>

<dl><dt><a name="DenseLayer-activate"><strong>activate</strong></a>(self, Z)</dt><dd><span class="code">Apply&nbsp;activation&nbsp;function.</span></dd></dl>

<dl><dt><a name="DenseLayer-activation_derivative"><strong>activation_derivative</strong></a>(self, Z)</dt><dd><span class="code">Apply&nbsp;activation&nbsp;derivative.</span></dd></dl>

<dl><dt><a name="DenseLayer-backward"><strong>backward</strong></a>(self, dA, reg_lambda)</dt><dd><span class="code">Backward&nbsp;pass&nbsp;of&nbsp;the&nbsp;layer.</span></dd></dl>

<dl><dt><a name="DenseLayer-forward"><strong>forward</strong></a>(self, X)</dt><dd><span class="code">Forward&nbsp;pass&nbsp;of&nbsp;the&nbsp;layer.</span></dd></dl>

<dl><dt><a name="DenseLayer-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><span class="code">Reset&nbsp;the&nbsp;gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;to&nbsp;zero.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="FlattenLayer">class <strong>FlattenLayer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">A&nbsp;layer&nbsp;that&nbsp;flattens&nbsp;multi-dimensional&nbsp;input&nbsp;into&nbsp;a&nbsp;2D&nbsp;array&nbsp;(batch_size,&nbsp;flattened_size).<br>
&nbsp;<br>
Useful&nbsp;for&nbsp;transitioning&nbsp;from&nbsp;convolutional&nbsp;layers&nbsp;to&nbsp;dense&nbsp;layers.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_shape:&nbsp;(tuple)&nbsp;-&nbsp;Shape&nbsp;of&nbsp;the&nbsp;input&nbsp;data&nbsp;(excluding&nbsp;batch&nbsp;size).<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int)&nbsp;-&nbsp;Size&nbsp;of&nbsp;the&nbsp;flattened&nbsp;output&nbsp;vector.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_cache:&nbsp;(np.ndarray)&nbsp;-&nbsp;Cached&nbsp;input&nbsp;for&nbsp;backpropagation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size:&nbsp;(int)&nbsp;-&nbsp;Size&nbsp;of&nbsp;the&nbsp;input&nbsp;(same&nbsp;as&nbsp;input_shape).<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int)&nbsp;-&nbsp;Size&nbsp;of&nbsp;the&nbsp;output&nbsp;(same&nbsp;as&nbsp;output_size).<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="FlattenLayer-__init__"><strong>__init__</strong></a>(self)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;layer&nbsp;with&nbsp;default&nbsp;attributes.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_shape:&nbsp;(tuple&nbsp;or&nbsp;None)&nbsp;-&nbsp;Shape&nbsp;of&nbsp;the&nbsp;input&nbsp;data,&nbsp;to&nbsp;be&nbsp;set&nbsp;dynamically&nbsp;during&nbsp;the&nbsp;forward&nbsp;pass.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int&nbsp;or&nbsp;None)&nbsp;-&nbsp;Size&nbsp;of&nbsp;the&nbsp;output&nbsp;data,&nbsp;to&nbsp;be&nbsp;set&nbsp;dynamically&nbsp;during&nbsp;the&nbsp;forward&nbsp;pass.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_cache:&nbsp;(any&nbsp;or&nbsp;None)&nbsp;-&nbsp;Cache&nbsp;to&nbsp;store&nbsp;input&nbsp;data&nbsp;for&nbsp;use&nbsp;during&nbsp;backpropagation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size:&nbsp;(int&nbsp;or&nbsp;None)&nbsp;-&nbsp;Flattened&nbsp;size&nbsp;of&nbsp;the&nbsp;input,&nbsp;calculated&nbsp;as&nbsp;channels&nbsp;*&nbsp;height&nbsp;*&nbsp;width.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int&nbsp;or&nbsp;None)&nbsp;-&nbsp;Flattened&nbsp;size&nbsp;of&nbsp;the&nbsp;output,&nbsp;same&nbsp;as&nbsp;input_size.</span></dd></dl>

<dl><dt><a name="FlattenLayer-backward"><strong>backward</strong></a>(self, dA, reg_lambda=0)</dt><dd><span class="code">Reshapes&nbsp;the&nbsp;gradient&nbsp;back&nbsp;to&nbsp;the&nbsp;original&nbsp;input&nbsp;shape.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dA&nbsp;(np.ndarray):&nbsp;Gradient&nbsp;of&nbsp;the&nbsp;loss&nbsp;with&nbsp;respect&nbsp;to&nbsp;the&nbsp;layer's&nbsp;output,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shape&nbsp;(batch_size,&nbsp;flattened_size)<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float):&nbsp;Regularization&nbsp;parameter&nbsp;(unused&nbsp;in&nbsp;<a href="#FlattenLayer">FlattenLayer</a>).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Gradient&nbsp;with&nbsp;respect&nbsp;to&nbsp;the&nbsp;input,&nbsp;reshaped&nbsp;to&nbsp;original&nbsp;input&nbsp;shape.</span></dd></dl>

<dl><dt><a name="FlattenLayer-forward"><strong>forward</strong></a>(self, X)</dt><dd><span class="code">Flattens&nbsp;the&nbsp;input&nbsp;tensor.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(batch_size,&nbsp;channels,&nbsp;height,&nbsp;width)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or&nbsp;any&nbsp;multi-dimensional&nbsp;shape&nbsp;after&nbsp;batch&nbsp;dimension.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Flattened&nbsp;output&nbsp;of&nbsp;shape&nbsp;(batch_size,&nbsp;flattened_size)</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="GeneralizedSVC">class <strong>GeneralizedSVC</strong></a>(<a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#GeneralizedSVC">GeneralizedSVC</a>(C=1.0,&nbsp;tol=0.0001,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;kernel='linear',&nbsp;degree=3,&nbsp;gamma='scale',&nbsp;coef0=0.0)<br>
&nbsp;<br>
<a href="#GeneralizedSVC">GeneralizedSVC</a>:&nbsp;A&nbsp;Support&nbsp;Vector&nbsp;Classifier&nbsp;(SVC)&nbsp;model&nbsp;with&nbsp;support&nbsp;for&nbsp;multiple&nbsp;kernels.<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;an&nbsp;SVC&nbsp;model&nbsp;using&nbsp;gradient&nbsp;descent&nbsp;for&nbsp;optimization.&nbsp;It&nbsp;supports<br>
linear&nbsp;and&nbsp;non-linear&nbsp;kernels,&nbsp;including&nbsp;polynomial&nbsp;and&nbsp;RBF&nbsp;kernels.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C&nbsp;(float):&nbsp;Regularization&nbsp;parameter.&nbsp;Default&nbsp;is&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol&nbsp;(float):&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria.&nbsp;Default&nbsp;is&nbsp;1e-4.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter&nbsp;(int):&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel&nbsp;(str):&nbsp;Kernel&nbsp;type&nbsp;('linear',&nbsp;'poly',&nbsp;'rbf').&nbsp;Default&nbsp;is&nbsp;'linear'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;degree&nbsp;(int):&nbsp;Degree&nbsp;of&nbsp;the&nbsp;polynomial&nbsp;kernel&nbsp;function&nbsp;('poly').&nbsp;Ignored&nbsp;by&nbsp;other&nbsp;kernels.&nbsp;Default&nbsp;is&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;gamma&nbsp;(str&nbsp;or&nbsp;float):&nbsp;Kernel&nbsp;coefficient&nbsp;for&nbsp;'rbf'&nbsp;and&nbsp;'poly'.&nbsp;Default&nbsp;is&nbsp;'scale'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef0&nbsp;(float):&nbsp;Independent&nbsp;term&nbsp;in&nbsp;kernel&nbsp;function&nbsp;('poly').&nbsp;Default&nbsp;is&nbsp;0.0.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GeneralizedSVC-__init__">__init__</a>(self,&nbsp;C=1.0,&nbsp;tol=1e-4,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;kernel="linear",&nbsp;degree=3,&nbsp;gamma="scale",&nbsp;coef0=0.0):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initialize&nbsp;the&nbsp;<a href="#GeneralizedSVC">GeneralizedSVC</a>&nbsp;model&nbsp;with&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_fit(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fit&nbsp;the&nbsp;<a href="#GeneralizedSVC">GeneralizedSVC</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data&nbsp;using&nbsp;gradient&nbsp;descent.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_predict_binary(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predict&nbsp;binary&nbsp;class&nbsp;labels&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_predict_multiclass(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predict&nbsp;multi-class&nbsp;labels&nbsp;using&nbsp;one-vs-rest&nbsp;strategy.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GeneralizedSVC-decision_function">decision_function</a>(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute&nbsp;raw&nbsp;decision&nbsp;function&nbsp;values&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_score_binary(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute&nbsp;the&nbsp;accuracy&nbsp;score&nbsp;for&nbsp;binary&nbsp;classification.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_score_multiclass(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute&nbsp;the&nbsp;accuracy&nbsp;score&nbsp;for&nbsp;multi-class&nbsp;classification.<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValueError:&nbsp;If&nbsp;numerical&nbsp;instability&nbsp;is&nbsp;detected&nbsp;during&nbsp;training.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.svm.generalizedSVM.html#GeneralizedSVC">GeneralizedSVC</a></dd>
<dd><a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="GeneralizedSVC-__init__"><strong>__init__</strong></a>(self, C=1.0, tol=0.0001, max_iter=1000, learning_rate=0.01, kernel='linear', degree=3, gamma='scale', coef0=0.0)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#GeneralizedSVC">GeneralizedSVC</a>&nbsp;model&nbsp;with&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C:&nbsp;(float)&nbsp;-&nbsp;Regularization&nbsp;parameter.&nbsp;Default&nbsp;is&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float)&nbsp;-&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria.&nbsp;Default&nbsp;is&nbsp;1e-4.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float)&nbsp;-&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel:&nbsp;(str)&nbsp;-&nbsp;Kernel&nbsp;type&nbsp;('linear',&nbsp;'poly',&nbsp;'rbf').&nbsp;Default&nbsp;is&nbsp;'linear'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;degree:&nbsp;(int)&nbsp;-&nbsp;Degree&nbsp;of&nbsp;the&nbsp;polynomial&nbsp;kernel&nbsp;function&nbsp;('poly').&nbsp;Ignored&nbsp;by&nbsp;other&nbsp;kernels.&nbsp;Default&nbsp;is&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;gamma:&nbsp;(str&nbsp;or&nbsp;float)&nbsp;-&nbsp;Kernel&nbsp;coefficient&nbsp;for&nbsp;'rbf'&nbsp;and&nbsp;'poly'.&nbsp;Default&nbsp;is&nbsp;'scale'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef0:&nbsp;(float)&nbsp;-&nbsp;Independent&nbsp;term&nbsp;in&nbsp;kernel&nbsp;function&nbsp;('poly').&nbsp;Default&nbsp;is&nbsp;0.0.</span></dd></dl>

<dl><dt><a name="GeneralizedSVC-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;raw&nbsp;decision&nbsp;function&nbsp;values&nbsp;for&nbsp;input&nbsp;samples.</span></dd></dl>

<hr>
Methods inherited from <a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>:<br>
<dl><dt><a name="GeneralizedSVC-__sklearn_is_fitted__"><strong>__sklearn_is_fitted__</strong></a>(self)</dt><dd><span class="code">Checks&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted&nbsp;(for&nbsp;sklearn&nbsp;compatibility).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fitted:&nbsp;(bool)&nbsp;-&nbsp;True&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted,&nbsp;otherwise&nbsp;False.</span></dd></dl>

<dl><dt><a name="GeneralizedSVC-fit"><strong>fit</strong></a>(self, X, y=None)</dt><dd><span class="code">Fits&nbsp;the&nbsp;SVM&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Training&nbsp;vectors.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Target&nbsp;values.&nbsp;Default&nbsp;is&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;fitted&nbsp;instance.</span></dd></dl>

<dl><dt><a name="GeneralizedSVC-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><span class="code">Retrieves&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;deep:&nbsp;(bool)&nbsp;-&nbsp;If&nbsp;True,&nbsp;returns&nbsp;parameters&nbsp;of&nbsp;subobjects&nbsp;as&nbsp;well.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;params:&nbsp;(dict)&nbsp;-&nbsp;Dictionary&nbsp;of&nbsp;hyperparameter&nbsp;names&nbsp;and&nbsp;values.</span></dd></dl>

<dl><dt><a name="GeneralizedSVC-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Input&nbsp;samples.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;predicted_labels:&nbsp;(ndarray&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Predicted&nbsp;class&nbsp;labels.</span></dd></dl>

<dl><dt><a name="GeneralizedSVC-score"><strong>score</strong></a>(self, X, y)</dt><dd><span class="code">Computes&nbsp;the&nbsp;mean&nbsp;accuracy&nbsp;of&nbsp;the&nbsp;model&nbsp;on&nbsp;the&nbsp;given&nbsp;test&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Test&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;True&nbsp;class&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;score:&nbsp;(float)&nbsp;-&nbsp;Mean&nbsp;accuracy&nbsp;of&nbsp;predictions.</span></dd></dl>

<dl><dt><a name="GeneralizedSVC-set_params"><strong>set_params</strong></a>(self, **parameters)</dt><dd><span class="code">Sets&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;**parameters:&nbsp;(dict)&nbsp;-&nbsp;Hyperparameter&nbsp;names&nbsp;and&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;updated&nbsp;estimator&nbsp;instance.</span></dd></dl>

<hr>
Data descriptors inherited from <a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="GeneralizedSVR">class <strong>GeneralizedSVR</strong></a>(<a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#GeneralizedSVR">GeneralizedSVR</a>(C=1.0,&nbsp;tol=0.0001,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;epsilon=0.1,&nbsp;kernel='linear',&nbsp;degree=3,&nbsp;gamma='scale',&nbsp;coef0=0.0)<br>
&nbsp;<br>
<a href="#GeneralizedSVR">GeneralizedSVR</a>:&nbsp;A&nbsp;Support&nbsp;Vector&nbsp;Regression&nbsp;(SVR)&nbsp;model&nbsp;with&nbsp;support&nbsp;for&nbsp;multiple&nbsp;kernels.<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;an&nbsp;SVR&nbsp;model&nbsp;using&nbsp;gradient&nbsp;descent&nbsp;for&nbsp;optimization.&nbsp;It&nbsp;supports<br>
linear&nbsp;and&nbsp;non-linear&nbsp;kernels,&nbsp;including&nbsp;polynomial&nbsp;and&nbsp;RBF&nbsp;kernels.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C&nbsp;(float):&nbsp;Regularization&nbsp;parameter.&nbsp;Default&nbsp;is&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol&nbsp;(float):&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria.&nbsp;Default&nbsp;is&nbsp;1e-4.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter&nbsp;(int):&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float):&nbsp;Epsilon&nbsp;parameter&nbsp;for&nbsp;epsilon-insensitive&nbsp;loss.&nbsp;Default&nbsp;is&nbsp;0.1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel&nbsp;(str):&nbsp;Kernel&nbsp;type&nbsp;('linear',&nbsp;'poly',&nbsp;'rbf').&nbsp;Default&nbsp;is&nbsp;'linear'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;degree&nbsp;(int):&nbsp;Degree&nbsp;of&nbsp;the&nbsp;polynomial&nbsp;kernel&nbsp;function&nbsp;('poly').&nbsp;Ignored&nbsp;by&nbsp;other&nbsp;kernels.&nbsp;Default&nbsp;is&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;gamma&nbsp;(str&nbsp;or&nbsp;float):&nbsp;Kernel&nbsp;coefficient&nbsp;for&nbsp;'rbf'&nbsp;and&nbsp;'poly'.&nbsp;Default&nbsp;is&nbsp;'scale'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef0&nbsp;(float):&nbsp;Independent&nbsp;term&nbsp;in&nbsp;kernel&nbsp;function&nbsp;('poly').&nbsp;Default&nbsp;is&nbsp;0.0.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GeneralizedSVR-__init__">__init__</a>(self,&nbsp;C=1.0,&nbsp;tol=1e-4,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;epsilon=0.1,&nbsp;kernel="linear",&nbsp;degree=3,&nbsp;gamma="scale",&nbsp;coef0=0.0):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initialize&nbsp;the&nbsp;<a href="#GeneralizedSVR">GeneralizedSVR</a>&nbsp;model&nbsp;with&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_fit(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fit&nbsp;the&nbsp;<a href="#GeneralizedSVR">GeneralizedSVR</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data&nbsp;using&nbsp;gradient&nbsp;descent.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GeneralizedSVR-predict">predict</a>(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predict&nbsp;continuous&nbsp;target&nbsp;values&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GeneralizedSVR-decision_function">decision_function</a>(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute&nbsp;raw&nbsp;decision&nbsp;function&nbsp;values&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GeneralizedSVR-score">score</a>(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute&nbsp;the&nbsp;coefficient&nbsp;of&nbsp;determination&nbsp;(R&nbsp;score)&nbsp;for&nbsp;the&nbsp;model's&nbsp;predictions.<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValueError:&nbsp;If&nbsp;numerical&nbsp;instability&nbsp;is&nbsp;detected&nbsp;during&nbsp;training.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.svm.generalizedSVM.html#GeneralizedSVR">GeneralizedSVR</a></dd>
<dd><a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="GeneralizedSVR-__init__"><strong>__init__</strong></a>(self, C=1.0, tol=0.0001, max_iter=1000, learning_rate=0.01, epsilon=0.1, kernel='linear', degree=3, gamma='scale', coef0=0.0)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#GeneralizedSVR">GeneralizedSVR</a>&nbsp;model&nbsp;with&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C:&nbsp;(float)&nbsp;-&nbsp;Regularization&nbsp;parameter.&nbsp;Default&nbsp;is&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float)&nbsp;-&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria.&nbsp;Default&nbsp;is&nbsp;1e-4.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float)&nbsp;-&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon:&nbsp;(float)&nbsp;-&nbsp;Epsilon&nbsp;parameter&nbsp;for&nbsp;epsilon-insensitive&nbsp;loss.&nbsp;Default&nbsp;is&nbsp;0.1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel:&nbsp;(str)&nbsp;-&nbsp;Kernel&nbsp;type&nbsp;('linear',&nbsp;'poly',&nbsp;'rbf').&nbsp;Default&nbsp;is&nbsp;'linear'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;degree:&nbsp;(int)&nbsp;-&nbsp;Degree&nbsp;of&nbsp;the&nbsp;polynomial&nbsp;kernel&nbsp;function&nbsp;('poly').&nbsp;Ignored&nbsp;by&nbsp;other&nbsp;kernels.&nbsp;Default&nbsp;is&nbsp;3.<br>
&nbsp;&nbsp;&nbsp;&nbsp;gamma:&nbsp;(str&nbsp;or&nbsp;float)&nbsp;-&nbsp;Kernel&nbsp;coefficient&nbsp;for&nbsp;'rbf'&nbsp;and&nbsp;'poly'.&nbsp;Default&nbsp;is&nbsp;'scale'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef0:&nbsp;(float)&nbsp;-&nbsp;Independent&nbsp;term&nbsp;in&nbsp;kernel&nbsp;function&nbsp;('poly').&nbsp;Default&nbsp;is&nbsp;0.0.</span></dd></dl>

<dl><dt><a name="GeneralizedSVR-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;raw&nbsp;decision&nbsp;function&nbsp;values&nbsp;for&nbsp;input&nbsp;samples.</span></dd></dl>

<dl><dt><a name="GeneralizedSVR-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;continuous&nbsp;target&nbsp;values&nbsp;for&nbsp;input&nbsp;samples.</span></dd></dl>

<dl><dt><a name="GeneralizedSVR-score"><strong>score</strong></a>(self, X, y)</dt><dd><span class="code">Compute&nbsp;the&nbsp;coefficient&nbsp;of&nbsp;determination&nbsp;(R&nbsp;score)&nbsp;for&nbsp;the&nbsp;model's&nbsp;predictions.</span></dd></dl>

<hr>
Methods inherited from <a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>:<br>
<dl><dt><a name="GeneralizedSVR-__sklearn_is_fitted__"><strong>__sklearn_is_fitted__</strong></a>(self)</dt><dd><span class="code">Checks&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted&nbsp;(for&nbsp;sklearn&nbsp;compatibility).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fitted:&nbsp;(bool)&nbsp;-&nbsp;True&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted,&nbsp;otherwise&nbsp;False.</span></dd></dl>

<dl><dt><a name="GeneralizedSVR-fit"><strong>fit</strong></a>(self, X, y=None)</dt><dd><span class="code">Fits&nbsp;the&nbsp;SVM&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Training&nbsp;vectors.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Target&nbsp;values.&nbsp;Default&nbsp;is&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;fitted&nbsp;instance.</span></dd></dl>

<dl><dt><a name="GeneralizedSVR-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><span class="code">Retrieves&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;deep:&nbsp;(bool)&nbsp;-&nbsp;If&nbsp;True,&nbsp;returns&nbsp;parameters&nbsp;of&nbsp;subobjects&nbsp;as&nbsp;well.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;params:&nbsp;(dict)&nbsp;-&nbsp;Dictionary&nbsp;of&nbsp;hyperparameter&nbsp;names&nbsp;and&nbsp;values.</span></dd></dl>

<dl><dt><a name="GeneralizedSVR-set_params"><strong>set_params</strong></a>(self, **parameters)</dt><dd><span class="code">Sets&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;**parameters:&nbsp;(dict)&nbsp;-&nbsp;Hyperparameter&nbsp;names&nbsp;and&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;updated&nbsp;estimator&nbsp;instance.</span></dd></dl>

<hr>
Data descriptors inherited from <a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="GradientBoostedClassifier">class <strong>GradientBoostedClassifier</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#GradientBoostedClassifier">GradientBoostedClassifier</a>(X=None,&nbsp;y=None,&nbsp;n_estimators:&nbsp;int&nbsp;=&nbsp;100,&nbsp;learning_rate:&nbsp;float&nbsp;=&nbsp;0.1,&nbsp;max_depth:&nbsp;int&nbsp;=&nbsp;3,&nbsp;min_samples_split:&nbsp;int&nbsp;=&nbsp;2,&nbsp;random_seed:&nbsp;int&nbsp;=&nbsp;None)<br>
&nbsp;<br>
A&nbsp;Gradient&nbsp;Boosted&nbsp;Decision&nbsp;Tree&nbsp;Classifier.<br>
&nbsp;<br>
This&nbsp;model&nbsp;builds&nbsp;an&nbsp;ensemble&nbsp;of&nbsp;regression&nbsp;trees&nbsp;sequentially.&nbsp;Each&nbsp;tree<br>
is&nbsp;trained&nbsp;to&nbsp;predict&nbsp;the&nbsp;pseudo-residuals&nbsp;(gradients&nbsp;of&nbsp;the&nbsp;loss&nbsp;function)<br>
of&nbsp;the&nbsp;previous&nbsp;model's&nbsp;predictions.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(np.ndarray):&nbsp;Training&nbsp;input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(np.ndarray):&nbsp;Training&nbsp;target&nbsp;class&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;boosting&nbsp;stages&nbsp;(trees)&nbsp;to&nbsp;perform.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Step&nbsp;size&nbsp;shrinkage&nbsp;to&nbsp;prevent&nbsp;overfitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;individual&nbsp;regression&nbsp;tree&nbsp;estimators.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;Minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node&nbsp;in&nbsp;a&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int&nbsp;or&nbsp;None):&nbsp;Controls&nbsp;the&nbsp;randomness&nbsp;for&nbsp;reproducibility&nbsp;(currently&nbsp;affects&nbsp;feature&nbsp;selection&nbsp;within&nbsp;trees&nbsp;if&nbsp;applicable).<br>
&nbsp;&nbsp;&nbsp;&nbsp;trees_&nbsp;(list):&nbsp;List&nbsp;storing&nbsp;the&nbsp;fitted&nbsp;regression&nbsp;tree&nbsp;instances&nbsp;for&nbsp;each&nbsp;boosting&nbsp;stage&nbsp;(and&nbsp;for&nbsp;each&nbsp;class&nbsp;in&nbsp;multiclass).<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes_&nbsp;(np.ndarray):&nbsp;The&nbsp;unique&nbsp;class&nbsp;labels&nbsp;found&nbsp;in&nbsp;the&nbsp;target&nbsp;variable&nbsp;`y`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_classes_&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;unique&nbsp;classes.<br>
&nbsp;&nbsp;&nbsp;&nbsp;init_estimator_&nbsp;(float&nbsp;or&nbsp;np.ndarray):&nbsp;The&nbsp;initial&nbsp;prediction&nbsp;model&nbsp;(predicts&nbsp;log-odds).<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss_&nbsp;(str):&nbsp;The&nbsp;loss&nbsp;function&nbsp;used&nbsp;('log_loss'&nbsp;for&nbsp;binary,&nbsp;'multinomial'&nbsp;for&nbsp;multi-class).<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="GradientBoostedClassifier-__init__"><strong>__init__</strong></a>(self, X=None, y=None, n_estimators: int = 100, learning_rate: float = 0.1, max_depth: int = 3, min_samples_split: int = 2, random_seed: int = None)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;Gradient&nbsp;Boosted&nbsp;Classifier.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Training&nbsp;input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(array-like):&nbsp;Training&nbsp;target&nbsp;class&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;boosting&nbsp;stages&nbsp;(trees).<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Step&nbsp;size&nbsp;shrinkage&nbsp;to&nbsp;prevent&nbsp;overfitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;individual&nbsp;regression&nbsp;tree&nbsp;estimator.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;Minimum&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node&nbsp;in&nbsp;a&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int,&nbsp;optional):&nbsp;Seed&nbsp;for&nbsp;reproducibility.&nbsp;Defaults&nbsp;to&nbsp;None.</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-calculate_metrics"><strong>calculate_metrics</strong></a>(self, y_true, y_pred, y_prob=None)</dt><dd><span class="code">Calculate&nbsp;common&nbsp;classification&nbsp;metrics.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;class&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like):&nbsp;Predicted&nbsp;class&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_prob&nbsp;(array-like,&nbsp;optional):&nbsp;Predicted&nbsp;probabilities&nbsp;for&nbsp;Log&nbsp;Loss&nbsp;calculation.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics&nbsp;(Accuracy,&nbsp;Precision,&nbsp;Recall,&nbsp;F1&nbsp;Score,&nbsp;Log&nbsp;Loss&nbsp;if&nbsp;applicable).</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;the&nbsp;raw&nbsp;decision&nbsp;scores&nbsp;(log-odds)&nbsp;for&nbsp;samples&nbsp;in&nbsp;X.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;The&nbsp;raw&nbsp;decision&nbsp;scores.&nbsp;Shape&nbsp;(n_samples,)&nbsp;for&nbsp;binary<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or&nbsp;(n_samples,&nbsp;n_classes)&nbsp;for&nbsp;multi-class.</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-fit"><strong>fit</strong></a>(self, X=None, y=None, sample_weight=None, verbose=0)</dt><dd><span class="code">Fits&nbsp;the&nbsp;gradient&nbsp;boosted&nbsp;classifier&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Training&nbsp;input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(array-like):&nbsp;Training&nbsp;target&nbsp;class&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight&nbsp;(array-like,&nbsp;optional):&nbsp;Sample&nbsp;weights&nbsp;for&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(int):&nbsp;Controls&nbsp;the&nbsp;verbosity&nbsp;of&nbsp;the&nbsp;fitting&nbsp;process.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;for&nbsp;no&nbsp;output,&nbsp;1&nbsp;for&nbsp;basic&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;The&nbsp;fitted&nbsp;<a href="#GradientBoostedClassifier">GradientBoostedClassifier</a>&nbsp;instance.</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-get_params"><strong>get_params</strong></a>(self)</dt><dd><span class="code">Get&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;<a href="#GradientBoostedClassifier">GradientBoostedClassifier</a>.</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-get_stats"><strong>get_stats</strong></a>(self, y_true, X=None, y_pred=None, verbose=False)</dt><dd><span class="code">Calculate&nbsp;and&nbsp;optionally&nbsp;print&nbsp;evaluation&nbsp;metrics.&nbsp;Requires&nbsp;either&nbsp;X&nbsp;or&nbsp;y_pred.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like,&nbsp;optional):&nbsp;Input&nbsp;features&nbsp;to&nbsp;generate&nbsp;predictions&nbsp;if&nbsp;y_pred&nbsp;is&nbsp;not&nbsp;provided.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like,&nbsp;optional):&nbsp;Pre-computed&nbsp;predicted&nbsp;class&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;the&nbsp;metrics.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics.</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;input&nbsp;features&nbsp;X.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Predicted&nbsp;class&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<dl><dt><a name="GradientBoostedClassifier-predict_proba"><strong>predict_proba</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;class&nbsp;probabilities&nbsp;for&nbsp;samples&nbsp;in&nbsp;X.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Predicted&nbsp;class&nbsp;probabilities.&nbsp;Shape&nbsp;(n_samples,&nbsp;n_classes).<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;binary,&nbsp;columns&nbsp;are&nbsp;[P(class&nbsp;0),&nbsp;P(class&nbsp;1)].</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="GradientBoostedRegressor">class <strong>GradientBoostedRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#GradientBoostedRegressor">GradientBoostedRegressor</a>(X=None,&nbsp;y=None,&nbsp;num_trees:&nbsp;int&nbsp;=&nbsp;100,&nbsp;max_depth:&nbsp;int&nbsp;=&nbsp;3,&nbsp;learning_rate:&nbsp;float&nbsp;=&nbsp;0.1,&nbsp;min_samples_split:&nbsp;int&nbsp;=&nbsp;2,&nbsp;random_seed:&nbsp;int&nbsp;=&nbsp;None)<br>
&nbsp;<br>
A&nbsp;class&nbsp;to&nbsp;represent&nbsp;a&nbsp;Gradient&nbsp;Boosted&nbsp;Decision&nbsp;Tree&nbsp;Regressor.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int):&nbsp;The&nbsp;random&nbsp;seed&nbsp;for&nbsp;the&nbsp;random&nbsp;number&nbsp;generator.<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_trees&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;ensemble.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;decision&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;gradient&nbsp;boosted&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int):&nbsp;The&nbsp;random&nbsp;seed&nbsp;for&nbsp;the&nbsp;random&nbsp;number&nbsp;generator.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-fit">fit</a>(X=None,&nbsp;y=None,&nbsp;verbose=0):&nbsp;Fits&nbsp;the&nbsp;gradient&nbsp;boosted&nbsp;decision&nbsp;tree&nbsp;regressor&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-predict">predict</a>(X):&nbsp;Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-calculate_metrics">calculate_metrics</a>(y_true,&nbsp;y_pred):&nbsp;Calculates&nbsp;the&nbsp;evaluation&nbsp;metrics.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-get_stats">get_stats</a>(y_true,&nbsp;y_pred,&nbsp;verbose=False):&nbsp;Returns&nbsp;the&nbsp;evaluation&nbsp;metrics.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="GradientBoostedRegressor-__init__"><strong>__init__</strong></a>(self, X=None, y=None, num_trees: int = 100, max_depth: int = 3, learning_rate: float = 0.1, min_samples_split: int = 2, random_seed: int = None)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;Gradient&nbsp;Boosted&nbsp;Decision&nbsp;Tree&nbsp;Regressor.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Input&nbsp;feature&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Target&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_trees&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;boosting&nbsp;stages&nbsp;(trees).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;individual&nbsp;tree&nbsp;regressor.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Step&nbsp;size&nbsp;shrinkage&nbsp;to&nbsp;prevent&nbsp;overfitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;Minimum&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int):&nbsp;Seed&nbsp;for&nbsp;reproducibility&nbsp;(currently&nbsp;affects&nbsp;feature&nbsp;selection&nbsp;within&nbsp;trees).</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-calculate_metrics"><strong>calculate_metrics</strong></a>(self, y_true, y_pred)</dt><dd><span class="code">Calculate&nbsp;common&nbsp;regression&nbsp;metrics.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like):&nbsp;Predicted&nbsp;target&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics&nbsp;(MSE,&nbsp;R^2,&nbsp;MAE,&nbsp;RMSE,&nbsp;MAPE).</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-fit"><strong>fit</strong></a>(self, X=None, y=None, sample_weight=None, verbose=0)</dt><dd><span class="code">Fits&nbsp;the&nbsp;gradient&nbsp;boosted&nbsp;decision&nbsp;tree&nbsp;regressor&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
This&nbsp;method&nbsp;trains&nbsp;the&nbsp;ensemble&nbsp;of&nbsp;decision&nbsp;trees&nbsp;by&nbsp;iteratively&nbsp;fitting&nbsp;each&nbsp;tree&nbsp;to&nbsp;the&nbsp;residuals<br>
of&nbsp;the&nbsp;previous&nbsp;iteration.&nbsp;The&nbsp;residuals&nbsp;are&nbsp;updated&nbsp;after&nbsp;each&nbsp;iteration&nbsp;by&nbsp;subtracting&nbsp;the&nbsp;predictions<br>
made&nbsp;by&nbsp;the&nbsp;current&nbsp;tree&nbsp;from&nbsp;the&nbsp;:target&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Training&nbsp;input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(array-like):&nbsp;Training&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight&nbsp;(array-like):&nbsp;Sample&nbsp;weights&nbsp;for&nbsp;each&nbsp;instance&nbsp;(not&nbsp;used&nbsp;in&nbsp;this&nbsp;implementation).<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(int):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;progress&nbsp;messages&nbsp;(e.g.,&nbsp;residuals).&nbsp;0&nbsp;for&nbsp;no&nbsp;output,&nbsp;1&nbsp;for&nbsp;output,&nbsp;&gt;1&nbsp;for&nbsp;detailed&nbsp;output<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;The&nbsp;fitted&nbsp;<a href="#GradientBoostedRegressor">GradientBoostedRegressor</a>&nbsp;instance.</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-get_params"><strong>get_params</strong></a>(self)</dt><dd><span class="code">Get&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;<a href="#GradientBoostedRegressor">GradientBoostedRegressor</a>.</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-get_stats"><strong>get_stats</strong></a>(self, y_true, y_pred, verbose=False)</dt><dd><span class="code">Calculate&nbsp;and&nbsp;optionally&nbsp;print&nbsp;evaluation&nbsp;metrics.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like):&nbsp;Predicted&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;progress&nbsp;messages&nbsp;(e.g.,&nbsp;residuals).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics&nbsp;(MSE,&nbsp;R^2,&nbsp;MAE,&nbsp;RMSE,&nbsp;MAPE).</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;target&nbsp;values&nbsp;for&nbsp;input&nbsp;features&nbsp;X&nbsp;using&nbsp;the&nbsp;fitted&nbsp;GBR&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Predicted&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="GridSearchCV">class <strong>GridSearchCV</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#GridSearchCV">GridSearchCV</a>(model,&nbsp;param_grid,&nbsp;cv=5,&nbsp;metric='mse',&nbsp;direction='minimize')<br>
&nbsp;<br>
Implements&nbsp;a&nbsp;grid&nbsp;search&nbsp;cross-validation&nbsp;for&nbsp;hyperparameter&nbsp;tuning.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="GridSearchCV-__init__"><strong>__init__</strong></a>(self, model, param_grid, cv=5, metric='mse', direction='minimize')</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#GridSearchCV">GridSearchCV</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;The&nbsp;model&nbsp;Object&nbsp;to&nbsp;be&nbsp;tuned.<br>
&nbsp;&nbsp;&nbsp;&nbsp;param_grid:&nbsp;(list)&nbsp;-&nbsp;A&nbsp;list&nbsp;of&nbsp;dictionaries&nbsp;containing&nbsp;hyperparameters&nbsp;to&nbsp;be&nbsp;tuned.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cv:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;folds&nbsp;for&nbsp;cross-validation.&nbsp;Default&nbsp;is&nbsp;5.<br>
&nbsp;&nbsp;&nbsp;&nbsp;metric:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;metric&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;evaluation.&nbsp;Default&nbsp;is&nbsp;'mse'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Regression&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'mse',&nbsp;'r2',&nbsp;'mae',&nbsp;'rmse',&nbsp;'mape',&nbsp;'mpe'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Classification&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'accuracy',&nbsp;'precision',&nbsp;'recall',&nbsp;'f1',&nbsp;'log_loss'<br>
&nbsp;&nbsp;&nbsp;&nbsp;direction:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;direction&nbsp;to&nbsp;optimize&nbsp;the&nbsp;metric.&nbsp;Default&nbsp;is&nbsp;'minimize'.</span></dd></dl>

<dl><dt><a name="GridSearchCV-fit"><strong>fit</strong></a>(self, X, y, verbose=False)</dt><dd><span class="code">Fits&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;for&nbsp;all&nbsp;hyperparameter&nbsp;combinations.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;feature&nbsp;columns.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;label&nbsp;column.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;(bool)&nbsp;-&nbsp;A&nbsp;flag&nbsp;to&nbsp;display&nbsp;the&nbsp;training&nbsp;progress.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;The&nbsp;best&nbsp;model&nbsp;with&nbsp;the&nbsp;optimal&nbsp;hyperparameters.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="HuberLoss">class <strong>HuberLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;Huber&nbsp;loss&nbsp;implementation&nbsp;using&nbsp;numpy.<br>
&nbsp;<br>
Formula:&nbsp;mean(0.5&nbsp;*&nbsp;(y_true&nbsp;-&nbsp;y_pred)**2)&nbsp;if&nbsp;abs(y_true&nbsp;-&nbsp;y_pred)&nbsp;&lt;=&nbsp;delta&nbsp;else&nbsp;mean(delta&nbsp;*&nbsp;(abs(y_true&nbsp;-&nbsp;y_pred)&nbsp;-&nbsp;delta&nbsp;/&nbsp;2))<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#HuberLoss-__call__">__call__</a>(self,&nbsp;y_true,&nbsp;y_pred,&nbsp;delta=1.0):&nbsp;Calculate&nbsp;the&nbsp;Huber&nbsp;loss.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="HuberLoss-__call__"><strong>__call__</strong></a>(self, y_true, y_pred, delta=1.0)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;Huber&nbsp;loss.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(np.ndarray):&nbsp;The&nbsp;true&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(np.ndarray):&nbsp;The&nbsp;predicted&nbsp;values&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;delta&nbsp;(float):&nbsp;The&nbsp;threshold&nbsp;for&nbsp;the&nbsp;Huber&nbsp;loss.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;Huber&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="IsolationForest">class <strong>IsolationForest</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#IsolationForest">IsolationForest</a>(n_trees=100,&nbsp;max_samples=None,&nbsp;max_depth=10,&nbsp;n_jobs=1,&nbsp;force_true_length=False)<br>
&nbsp;<br>
<a href="#IsolationForest">IsolationForest</a>&nbsp;is&nbsp;an&nbsp;implementation&nbsp;of&nbsp;the&nbsp;Isolation&nbsp;Forest&nbsp;algorithm&nbsp;for&nbsp;anomaly&nbsp;detection.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_trees&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;isolation&nbsp;trees&nbsp;to&nbsp;build.&nbsp;Default&nbsp;is&nbsp;100.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_samples&nbsp;(int&nbsp;or&nbsp;None):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;samples&nbsp;to&nbsp;draw&nbsp;for&nbsp;each&nbsp;tree.&nbsp;If&nbsp;None,&nbsp;defaults&nbsp;to&nbsp;the&nbsp;minimum&nbsp;of&nbsp;256&nbsp;or&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the&nbsp;dataset.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;isolation&nbsp;tree.&nbsp;Default&nbsp;is&nbsp;10.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;parallel&nbsp;jobs&nbsp;to&nbsp;run.&nbsp;Set&nbsp;to&nbsp;-1&nbsp;to&nbsp;use&nbsp;all&nbsp;available&nbsp;cores.&nbsp;Default&nbsp;is&nbsp;1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;force&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;calculation.&nbsp;Default&nbsp;is&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;trees&nbsp;(list):&nbsp;A&nbsp;list&nbsp;to&nbsp;store&nbsp;the&nbsp;trained&nbsp;isolation&nbsp;trees.<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes_&nbsp;(numpy.ndarray):&nbsp;An&nbsp;array&nbsp;representing&nbsp;the&nbsp;classes&nbsp;(0&nbsp;for&nbsp;normal,&nbsp;1&nbsp;for&nbsp;anomaly).<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationForest-__init__">__init__</a>(n_trees=100,&nbsp;max_samples=None,&nbsp;max_depth=10,&nbsp;n_jobs=1,&nbsp;force_true_length=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;<a href="#IsolationForest">IsolationForest</a>&nbsp;with&nbsp;the&nbsp;specified&nbsp;parameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationForest-fit">fit</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;the&nbsp;isolation&nbsp;forest&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_fit_tree(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;a&nbsp;single&nbsp;isolation&nbsp;tree&nbsp;to&nbsp;a&nbsp;subset&nbsp;of&nbsp;the&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationTree">IsolationTree</a>:&nbsp;A&nbsp;trained&nbsp;isolation&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationForest-anomaly_score">anomaly_score</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;the&nbsp;anomaly&nbsp;scores&nbsp;for&nbsp;given&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numpy.ndarray:&nbsp;An&nbsp;array&nbsp;of&nbsp;anomaly&nbsp;scores.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationForest-predict">predict</a>(X,&nbsp;threshold=0.5):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predicts&nbsp;whether&nbsp;samples&nbsp;are&nbsp;anomalies.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;threshold&nbsp;(float):&nbsp;The&nbsp;threshold&nbsp;for&nbsp;classifying&nbsp;anomalies&nbsp;(default:&nbsp;0.5).<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numpy.ndarray:&nbsp;An&nbsp;array&nbsp;of&nbsp;predictions&nbsp;(1&nbsp;if&nbsp;the&nbsp;sample&nbsp;is&nbsp;an&nbsp;anomaly,&nbsp;0&nbsp;otherwise).<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationForest-__sklearn_is_fitted__">__sklearn_is_fitted__</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Checks&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool:&nbsp;True&nbsp;if&nbsp;the&nbsp;model&nbsp;is&nbsp;fitted,&nbsp;False&nbsp;otherwise.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="IsolationForest-__init__"><strong>__init__</strong></a>(self, n_trees=100, max_samples=None, max_depth=10, n_jobs=1, force_true_length=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#IsolationForest">IsolationForest</a>&nbsp;with&nbsp;the&nbsp;specified&nbsp;parameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_trees:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;isolation&nbsp;trees&nbsp;to&nbsp;build&nbsp;(default:&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_samples:&nbsp;(int&nbsp;or&nbsp;None),&nbsp;optional&nbsp;-&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;samples&nbsp;to&nbsp;draw&nbsp;for&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;None,&nbsp;defaults&nbsp;to&nbsp;the&nbsp;minimum&nbsp;of&nbsp;256&nbsp;or&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the&nbsp;dataset&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;isolation&nbsp;tree&nbsp;(default:&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;parallel&nbsp;jobs&nbsp;to&nbsp;run.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set&nbsp;to&nbsp;-1&nbsp;to&nbsp;use&nbsp;all&nbsp;available&nbsp;cores&nbsp;(default:&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;force&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;calculation&nbsp;(default:&nbsp;False).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_trees:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;isolation&nbsp;trees.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_samples:&nbsp;(int&nbsp;or&nbsp;None)&nbsp;-&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;samples&nbsp;for&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;trees.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length:&nbsp;(bool)&nbsp;-&nbsp;Indicates&nbsp;whether&nbsp;to&nbsp;use&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;for&nbsp;scoring.<br>
&nbsp;&nbsp;&nbsp;&nbsp;trees:&nbsp;(list)&nbsp;-&nbsp;A&nbsp;list&nbsp;to&nbsp;store&nbsp;the&nbsp;trained&nbsp;isolation&nbsp;trees.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;parallel&nbsp;jobs&nbsp;to&nbsp;run.<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes_:&nbsp;(np.ndarray)&nbsp;-&nbsp;An&nbsp;array&nbsp;representing&nbsp;the&nbsp;classes&nbsp;(0&nbsp;for&nbsp;normal,&nbsp;1&nbsp;for&nbsp;anomaly).</span></dd></dl>

<dl><dt><a name="IsolationForest-__sklearn_is_fitted__"><strong>__sklearn_is_fitted__</strong></a>(self)</dt><dd><span class="code">Checks&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted.</span></dd></dl>

<dl><dt><a name="IsolationForest-anomaly_score"><strong>anomaly_score</strong></a>(self, X)</dt><dd><span class="code">Computes&nbsp;the&nbsp;anomaly&nbsp;scores&nbsp;for&nbsp;given&nbsp;samples.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;samples.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;array:&nbsp;An&nbsp;array&nbsp;of&nbsp;anomaly&nbsp;scores.</span></dd></dl>

<dl><dt><a name="IsolationForest-fit"><strong>fit</strong></a>(self, X, y=None)</dt><dd><span class="code">Fits&nbsp;the&nbsp;isolation&nbsp;forest&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels&nbsp;(not&nbsp;used&nbsp;in&nbsp;this&nbsp;implementation).</span></dd></dl>

<dl><dt><a name="IsolationForest-predict"><strong>predict</strong></a>(self, X, threshold=0.5)</dt><dd><span class="code">Predicts&nbsp;whether&nbsp;samples&nbsp;are&nbsp;anomalies.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;threshold:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;threshold&nbsp;for&nbsp;classifying&nbsp;anomalies&nbsp;(default:&nbsp;0.5).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;array:&nbsp;An&nbsp;array&nbsp;of&nbsp;predictions&nbsp;(1&nbsp;if&nbsp;the&nbsp;sample&nbsp;is&nbsp;an&nbsp;anomaly,&nbsp;0&nbsp;otherwise).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="IsolationTree">class <strong>IsolationTree</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#IsolationTree">IsolationTree</a>(max_depth=10,&nbsp;force_true_length=False)<br>
&nbsp;<br>
<a href="#IsolationTree">IsolationTree</a>&nbsp;is&nbsp;a&nbsp;class&nbsp;that&nbsp;implements&nbsp;an&nbsp;isolation&nbsp;tree,&nbsp;which&nbsp;is&nbsp;a&nbsp;fundamental&nbsp;building&nbsp;block&nbsp;of&nbsp;the&nbsp;Isolation&nbsp;Forest&nbsp;algorithm.<br>
&nbsp;<br>
The&nbsp;Isolation&nbsp;Forest&nbsp;is&nbsp;an&nbsp;unsupervised&nbsp;learning&nbsp;method&nbsp;used&nbsp;for&nbsp;anomaly&nbsp;detection.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree.&nbsp;Default&nbsp;is&nbsp;10.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree&nbsp;(dict):&nbsp;The&nbsp;learned&nbsp;isolation&nbsp;tree&nbsp;structure.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length&nbsp;(bool):&nbsp;If&nbsp;True,&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;is&nbsp;used&nbsp;for&nbsp;scoring<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;the&nbsp;average&nbsp;path&nbsp;length.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationTree-__init__">__init__</a>(max_depth=10,&nbsp;force_true_length=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;<a href="#IsolationTree">IsolationTree</a>&nbsp;with&nbsp;the&nbsp;specified&nbsp;maximum&nbsp;depth&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scoring&nbsp;method.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationTree-fit">fit</a>(X,&nbsp;depth=0):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;the&nbsp;isolation&nbsp;tree&nbsp;to&nbsp;the&nbsp;input&nbsp;data&nbsp;by&nbsp;recursively&nbsp;partitioning<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;data&nbsp;based&nbsp;on&nbsp;randomly&nbsp;selected&nbsp;features&nbsp;and&nbsp;split&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#IsolationTree-path_length">path_length</a>(X,&nbsp;tree=None,&nbsp;depth=0):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;the&nbsp;path&nbsp;length&nbsp;for&nbsp;a&nbsp;given&nbsp;sample&nbsp;by&nbsp;traversing&nbsp;the&nbsp;tree<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;structure.&nbsp;The&nbsp;path&nbsp;length&nbsp;is&nbsp;used&nbsp;to&nbsp;determine&nbsp;how&nbsp;isolated&nbsp;a&nbsp;sample&nbsp;is.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="IsolationTree-__init__"><strong>__init__</strong></a>(self, max_depth=10, force_true_length=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;Isolation&nbsp;Forest&nbsp;with&nbsp;specified&nbsp;parameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree&nbsp;(default&nbsp;is&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;If&nbsp;True,&nbsp;use&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;for&nbsp;scoring&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree:&nbsp;(<a href="builtins.html#object">object</a>&nbsp;or&nbsp;None)&nbsp;-&nbsp;The&nbsp;tree&nbsp;structure&nbsp;used&nbsp;in&nbsp;the&nbsp;Isolation&nbsp;Forest&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_true_length:&nbsp;(bool)&nbsp;-&nbsp;Indicates&nbsp;whether&nbsp;to&nbsp;use&nbsp;the&nbsp;true&nbsp;path&nbsp;length&nbsp;for&nbsp;scoring.</span></dd></dl>

<dl><dt><a name="IsolationTree-fit"><strong>fit</strong></a>(self, X, depth=0)</dt><dd><span class="code">Fits&nbsp;the&nbsp;isolation&nbsp;tree&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;current&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree&nbsp;(default:&nbsp;0).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;The&nbsp;learned&nbsp;isolation&nbsp;tree.</span></dd></dl>

<dl><dt><a name="IsolationTree-path_length"><strong>path_length</strong></a>(self, X, tree=None, depth=0)</dt><dd><span class="code">Computes&nbsp;the&nbsp;path&nbsp;length&nbsp;for&nbsp;a&nbsp;given&nbsp;sample.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;sample.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;current&nbsp;node&nbsp;of&nbsp;the&nbsp;tree&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;current&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree&nbsp;(default:&nbsp;0).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;int:&nbsp;The&nbsp;path&nbsp;length.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="IsolationUtils">class <strong>IsolationUtils</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Utility&nbsp;functions&nbsp;for&nbsp;the&nbsp;Isolation&nbsp;Forest&nbsp;algorithm.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Static methods defined here:<br>
<dl><dt><a name="IsolationUtils-compute_avg_path_length"><strong>compute_avg_path_length</strong></a>(size)</dt><dd><span class="code">Computes&nbsp;the&nbsp;average&nbsp;path&nbsp;length&nbsp;of&nbsp;unsuccessful&nbsp;searches&nbsp;in&nbsp;a&nbsp;binary&nbsp;search&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;size:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;size&nbsp;of&nbsp;the&nbsp;tree.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;average_path_length:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;average&nbsp;path&nbsp;length.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITAdadeltaOptimizer">class <strong>JITAdadeltaOptimizer</strong></a>(JITAdadeltaOptimizer)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#JITAdadeltaOptimizer">JITAdadeltaOptimizer</a>(*args,&nbsp;**kwargs)<br>
&nbsp;<br>
Adadelta&nbsp;optimizer&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
Formula:<br>
&nbsp;&nbsp;&nbsp;&nbsp;E[g^2]_t&nbsp;=&nbsp;rho&nbsp;*&nbsp;E[g^2]_{t-1}&nbsp;+&nbsp;(1&nbsp;-&nbsp;rho)&nbsp;*&nbsp;g^2<br>
&nbsp;&nbsp;&nbsp;&nbsp;Delta_x&nbsp;=&nbsp;-&nbsp;(sqrt(E[delta_x^2]_{t-1}&nbsp;+&nbsp;epsilon)&nbsp;/&nbsp;sqrt(E[g^2]_t&nbsp;+&nbsp;epsilon))&nbsp;*&nbsp;g<br>
&nbsp;&nbsp;&nbsp;&nbsp;E[delta_x^2]_t&nbsp;=&nbsp;rho&nbsp;*&nbsp;E[delta_x^2]_{t-1}&nbsp;+&nbsp;(1&nbsp;-&nbsp;rho)&nbsp;*&nbsp;Delta_x^2<br>
Derived&nbsp;from:&nbsp;<a href="https://arxiv.org/abs/1212.5701">https://arxiv.org/abs/1212.5701</a><br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;rho&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;decay&nbsp;rate.&nbsp;Defaults&nbsp;to&nbsp;0.95.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float,&nbsp;optional):&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero.&nbsp;Defaults&nbsp;to&nbsp;1e-6.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter.&nbsp;Defaults&nbsp;to&nbsp;0.0.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.neural_networks.optimizers_jit.html#JITAdadeltaOptimizer">JITAdadeltaOptimizer</a></dd>
<dd>JITAdadeltaOptimizer</dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>class_type</strong> = jitclass.JITAdadeltaOptimizer#27bc57f6bd0&lt;learni...float64, 3d, C),E_delta_x2:array(float64, 3d, C)&gt;</dl>

<hr>
Methods inherited from JITAdadeltaOptimizer:<br>
<dl><dt><a name="JITAdadeltaOptimizer-__init__"><strong>__init__</strong></a>(self, learning_rate=1.0, rho=0.95, epsilon=1e-06, reg_lambda=0.0)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;optimizer&nbsp;with&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer&nbsp;(default&nbsp;is&nbsp;1.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;rho:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;running&nbsp;averages&nbsp;(default&nbsp;is&nbsp;0.95).<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero&nbsp;(default&nbsp;is&nbsp;1e-6).<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;regularization&nbsp;parameter&nbsp;(default&nbsp;is&nbsp;0.0).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;E_g2:&nbsp;(np.ndarray)&nbsp;-&nbsp;Running&nbsp;average&nbsp;of&nbsp;squared&nbsp;gradients.<br>
&nbsp;&nbsp;&nbsp;&nbsp;E_delta_x2:&nbsp;(np.ndarray)&nbsp;-&nbsp;Running&nbsp;average&nbsp;of&nbsp;squared&nbsp;parameter&nbsp;updates.</span></dd></dl>

<dl><dt><a name="JITAdadeltaOptimizer-initialize"><strong>initialize</strong></a>(self, layers)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;running&nbsp;averages&nbsp;for&nbsp;each&nbsp;layer's&nbsp;weights.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="JITAdadeltaOptimizer-update"><strong>update</strong></a>(self, layer, dW, db, index)</dt><dd><span class="code">Updates&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;a&nbsp;layer&nbsp;using&nbsp;the&nbsp;Adadelta&nbsp;optimization&nbsp;algorithm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer:&nbsp;(Layer)&nbsp;-&nbsp;The&nbsp;layer&nbsp;to&nbsp;update.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dW:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;db:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;index:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="JITAdadeltaOptimizer-update_layers"><strong>update_layers</strong></a>(self, layers, dWs, dbs)</dt><dd><span class="code">Updates&nbsp;all&nbsp;layers'&nbsp;weights&nbsp;and&nbsp;biases&nbsp;using&nbsp;the&nbsp;Adadelta&nbsp;optimization&nbsp;algorithm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dWs:&nbsp;(list&nbsp;of&nbsp;np.ndarray)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;for&nbsp;each&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dbs:&nbsp;(list&nbsp;of&nbsp;np.ndarray)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;biases&nbsp;for&nbsp;each&nbsp;layer.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<hr>
Data descriptors inherited from JITAdadeltaOptimizer:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITAdamOptimizer">class <strong>JITAdamOptimizer</strong></a>(JITAdamOptimizer)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#JITAdamOptimizer">JITAdamOptimizer</a>(*args,&nbsp;**kwargs)<br>
&nbsp;<br>
Adam&nbsp;optimizer&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
Formula:&nbsp;w&nbsp;=&nbsp;w&nbsp;-&nbsp;alpha&nbsp;*&nbsp;m_hat&nbsp;/&nbsp;(sqrt(v_hat)&nbsp;+&nbsp;epsilon)&nbsp;-&nbsp;lambda&nbsp;*&nbsp;w<br>
Derived&nbsp;from:&nbsp;<a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a><br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;0.001.<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta1&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;first&nbsp;moment&nbsp;estimates.&nbsp;Defaults&nbsp;to&nbsp;0.9.<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta2&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;second&nbsp;moment&nbsp;estimates.&nbsp;Defaults&nbsp;to&nbsp;0.999.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float,&nbsp;optional):&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero.&nbsp;Defaults&nbsp;to&nbsp;1e-8.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter.&nbsp;Defaults&nbsp;to&nbsp;0.01.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.neural_networks.optimizers_jit.html#JITAdamOptimizer">JITAdamOptimizer</a></dd>
<dd>JITAdamOptimizer</dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>class_type</strong> = jitclass.JITAdamOptimizer#27bc57de7d0&lt;learning_r...t64, 2d, A),db:array(float64, 2d, A),index:int32&gt;</dl>

<hr>
Methods inherited from JITAdamOptimizer:<br>
<dl><dt><a name="JITAdamOptimizer-__init__"><strong>__init__</strong></a>(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, reg_lambda=0.01)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;optimizer&nbsp;with&nbsp;the&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer&nbsp;(default&nbsp;is&nbsp;0.001).<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta1:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;first&nbsp;moment&nbsp;estimates&nbsp;(default&nbsp;is&nbsp;0.9).<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta2:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;second&nbsp;moment&nbsp;estimates&nbsp;(default&nbsp;is&nbsp;0.999).<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero&nbsp;(default&nbsp;is&nbsp;1e-8).<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Regularization&nbsp;parameter;&nbsp;larger&nbsp;values&nbsp;imply&nbsp;stronger&nbsp;regularization&nbsp;(default&nbsp;is&nbsp;0.01).</span></dd></dl>

<dl><dt><a name="JITAdamOptimizer-initialize"><strong>initialize</strong></a>(self, layers)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;first&nbsp;and&nbsp;second&nbsp;moment&nbsp;estimates&nbsp;for&nbsp;each&nbsp;layer's&nbsp;weights.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="JITAdamOptimizer-update"><strong>update</strong></a>(self, layer, dW, db, index)</dt><dd><span class="code">Updates&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;a&nbsp;layer&nbsp;using&nbsp;the&nbsp;Adam&nbsp;optimization&nbsp;algorithm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer:&nbsp;(Layer)&nbsp;-&nbsp;The&nbsp;layer&nbsp;to&nbsp;update.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dW:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;db:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;index:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="JITAdamOptimizer-update_layers"><strong>update_layers</strong></a>(self, layers, dWs, dbs)</dt><dd><span class="code">Updates&nbsp;all&nbsp;layers'&nbsp;weights&nbsp;and&nbsp;biases&nbsp;using&nbsp;the&nbsp;Adam&nbsp;optimization&nbsp;algorithm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dWs:&nbsp;(list&nbsp;of&nbsp;np.ndarray)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;for&nbsp;each&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dbs:&nbsp;(list&nbsp;of&nbsp;np.ndarray)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;biases&nbsp;for&nbsp;each&nbsp;layer.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<hr>
Data descriptors inherited from JITAdamOptimizer:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITBCEWithLogitsLoss">class <strong>JITBCEWithLogitsLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss&nbsp;with&nbsp;logits&nbsp;implementation&nbsp;using&nbsp;numba.<br>
&nbsp;<br>
Formula:&nbsp;-mean(y&nbsp;*&nbsp;log(p)&nbsp;+&nbsp;(1&nbsp;-&nbsp;y)&nbsp;*&nbsp;log(1&nbsp;-&nbsp;p))<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#JITBCEWithLogitsLoss-calculate_loss">calculate_loss</a>(self,&nbsp;logits,&nbsp;targets):&nbsp;Calculate&nbsp;the&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="JITBCEWithLogitsLoss-__init__"><strong>__init__</strong></a>(self)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;class&nbsp;with&nbsp;default&nbsp;values&nbsp;for&nbsp;logits&nbsp;and&nbsp;targets.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;logits&nbsp;(numpy.ndarray):&nbsp;A&nbsp;2D&nbsp;array&nbsp;initialized&nbsp;to&nbsp;zeros&nbsp;with&nbsp;shape&nbsp;(1,&nbsp;1),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;representing&nbsp;the&nbsp;predicted&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;targets&nbsp;(numpy.ndarray):&nbsp;A&nbsp;2D&nbsp;array&nbsp;initialized&nbsp;to&nbsp;zeros&nbsp;with&nbsp;shape&nbsp;(1,&nbsp;1),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;representing&nbsp;the&nbsp;true&nbsp;target&nbsp;values.</span></dd></dl>

<dl><dt><a name="JITBCEWithLogitsLoss-calculate_loss"><strong>calculate_loss</strong></a>(self, logits, targets)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;logits&nbsp;(np.ndarray):&nbsp;The&nbsp;logits&nbsp;(predicted&nbsp;values)&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;targets&nbsp;(np.ndarray):&nbsp;The&nbsp;target&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITConvLayer">class <strong>JITConvLayer</strong></a>(JITConvLayer)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#JITConvLayer">JITConvLayer</a>(*args,&nbsp;**kwargs)<br>
&nbsp;<br>
A&nbsp;convolutional&nbsp;layer&nbsp;implementation&nbsp;for&nbsp;neural&nbsp;networks&nbsp;using&nbsp;Numba&nbsp;JIT&nbsp;compilation.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.neural_networks.layers_jit.html#JITConvLayer">JITConvLayer</a></dd>
<dd>JITConvLayer</dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>class_type</strong> = jitclass.JITConvLayer#27bc4d7db50&lt;in_channels:in...2,w_out:int32,input_size:int32,output_size:int32&gt;</dl>

<hr>
Methods inherited from JITConvLayer:<br>
<dl><dt><a name="JITConvLayer-__init__"><strong>__init__</strong></a>(self, in_channels, out_channels, kernel_size, stride=1, padding=0, activation='relu')</dt><dd><span class="code">Initializes&nbsp;the&nbsp;convolutional&nbsp;layer&nbsp;with&nbsp;weights,&nbsp;biases,&nbsp;and&nbsp;activation&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;in_channels:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;input&nbsp;channels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;out_channels:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;output&nbsp;channels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel_size:&nbsp;(int)&nbsp;-&nbsp;Size&nbsp;of&nbsp;the&nbsp;convolutional&nbsp;kernel&nbsp;(assumes&nbsp;square&nbsp;kernels).<br>
&nbsp;&nbsp;&nbsp;&nbsp;stride:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Stride&nbsp;of&nbsp;the&nbsp;convolution&nbsp;(default&nbsp;is&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;padding:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Padding&nbsp;added&nbsp;to&nbsp;the&nbsp;input&nbsp;(default&nbsp;is&nbsp;0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation:&nbsp;(str),&nbsp;optional&nbsp;-&nbsp;<a href="#Activation">Activation</a>&nbsp;function&nbsp;to&nbsp;use&nbsp;(default&nbsp;is&nbsp;"relu").<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights:&nbsp;(np.ndarray)&nbsp;-&nbsp;Convolutional&nbsp;weight&nbsp;matrix&nbsp;initialized&nbsp;using&nbsp;He&nbsp;initialization.<br>
&nbsp;&nbsp;&nbsp;&nbsp;biases:&nbsp;(np.ndarray)&nbsp;-&nbsp;Bias&nbsp;vector&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation:&nbsp;(str)&nbsp;-&nbsp;<a href="#Activation">Activation</a>&nbsp;function&nbsp;for&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weight_gradients:&nbsp;(np.ndarray)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;weights,&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bias_gradients:&nbsp;(np.ndarray)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;biases,&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_cache:&nbsp;(np.ndarray)&nbsp;-&nbsp;Cached&nbsp;input&nbsp;values&nbsp;for&nbsp;backpropagation,&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_cols:&nbsp;(np.ndarray)&nbsp;-&nbsp;Cached&nbsp;column-transformed&nbsp;input&nbsp;for&nbsp;backpropagation,&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_padded:&nbsp;(np.ndarray)&nbsp;-&nbsp;Cached&nbsp;padded&nbsp;input&nbsp;for&nbsp;backpropagation,&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;h_out:&nbsp;(int)&nbsp;-&nbsp;Height&nbsp;of&nbsp;the&nbsp;output&nbsp;feature&nbsp;map,&nbsp;initialized&nbsp;to&nbsp;0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;w_out:&nbsp;(int)&nbsp;-&nbsp;Width&nbsp;of&nbsp;the&nbsp;output&nbsp;feature&nbsp;map,&nbsp;initialized&nbsp;to&nbsp;0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;input&nbsp;channels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;output&nbsp;channels.</span></dd></dl>

<dl><dt><a name="JITConvLayer-activate"><strong>activate</strong></a>(self, Z)</dt><dd><span class="code">Apply&nbsp;activation&nbsp;function.</span></dd></dl>

<dl><dt><a name="JITConvLayer-activation_derivative"><strong>activation_derivative</strong></a>(self, Z)</dt><dd><span class="code">Apply&nbsp;activation&nbsp;derivative.</span></dd></dl>

<dl><dt><a name="JITConvLayer-backward"><strong>backward</strong></a>(self, d_out, reg_lambda=0)</dt><dd><span class="code">Backward&nbsp;pass&nbsp;for&nbsp;convolutional&nbsp;layer.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;d_out&nbsp;(np.ndarray):&nbsp;Gradient&nbsp;of&nbsp;the&nbsp;loss&nbsp;with&nbsp;respect&nbsp;to&nbsp;the&nbsp;layer&nbsp;output<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;Regularization&nbsp;parameter<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dX:&nbsp;Gradient&nbsp;with&nbsp;respect&nbsp;to&nbsp;the&nbsp;input&nbsp;X</span></dd></dl>

<dl><dt><a name="JITConvLayer-forward"><strong>forward</strong></a>(self, X)</dt><dd><span class="code">Forward&nbsp;pass&nbsp;for&nbsp;convolutional&nbsp;layer.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;numpy&nbsp;array&nbsp;with&nbsp;shape&nbsp;(batch_size,&nbsp;in_channels,&nbsp;height,&nbsp;width)<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Output&nbsp;feature&nbsp;maps&nbsp;after&nbsp;convolution&nbsp;and&nbsp;activation.</span></dd></dl>

<dl><dt><a name="JITConvLayer-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><span class="code">Reset&nbsp;the&nbsp;gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;to&nbsp;zero.</span></dd></dl>

<hr>
Data descriptors inherited from JITConvLayer:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITCrossEntropyLoss">class <strong>JITCrossEntropyLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;cross&nbsp;entropy&nbsp;loss&nbsp;implementation&nbsp;using&nbsp;numba&nbsp;for&nbsp;multi-class&nbsp;classification.<br>
&nbsp;<br>
Formula:&nbsp;-sum(y&nbsp;*&nbsp;log(p)&nbsp;+&nbsp;(1&nbsp;-&nbsp;y)&nbsp;*&nbsp;log(1&nbsp;-&nbsp;p))&nbsp;/&nbsp;m<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#JITCrossEntropyLoss-calculate_loss">calculate_loss</a>(self,&nbsp;logits,&nbsp;targets):&nbsp;Calculate&nbsp;the&nbsp;cross&nbsp;entropy&nbsp;loss.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="JITCrossEntropyLoss-__init__"><strong>__init__</strong></a>(self)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;instance&nbsp;variables&nbsp;for&nbsp;the&nbsp;class.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;logits:&nbsp;(np.ndarray)&nbsp;-&nbsp;A&nbsp;2D&nbsp;array&nbsp;initialized&nbsp;to&nbsp;zeros&nbsp;with&nbsp;shape&nbsp;(1,&nbsp;1),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;representing&nbsp;the&nbsp;predicted&nbsp;values&nbsp;or&nbsp;outputs&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;targets:&nbsp;(np.ndarray)&nbsp;-&nbsp;A&nbsp;2D&nbsp;array&nbsp;initialized&nbsp;to&nbsp;zeros&nbsp;with&nbsp;shape&nbsp;(1,&nbsp;1),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;representing&nbsp;the&nbsp;ground&nbsp;truth&nbsp;or&nbsp;target&nbsp;values.</span></dd></dl>

<dl><dt><a name="JITCrossEntropyLoss-calculate_loss"><strong>calculate_loss</strong></a>(self, logits, targets)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;cross&nbsp;entropy&nbsp;loss.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;logits&nbsp;(np.ndarray):&nbsp;The&nbsp;logits&nbsp;(predicted&nbsp;values)&nbsp;of&nbsp;shape&nbsp;(num_samples,&nbsp;num_classes).<br>
&nbsp;&nbsp;&nbsp;&nbsp;targets&nbsp;(np.ndarray):&nbsp;The&nbsp;target&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;cross&nbsp;entropy&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITDenseLayer">class <strong>JITDenseLayer</strong></a>(JITDenseLayer)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#JITDenseLayer">JITDenseLayer</a>(*args,&nbsp;**kwargs)<br>
&nbsp;<br>
Initializes&nbsp;a&nbsp;fully&nbsp;connected&nbsp;layer&nbsp;<a href="builtins.html#object">object</a>,&nbsp;where&nbsp;each&nbsp;neuron&nbsp;is&nbsp;connected&nbsp;to&nbsp;all&nbsp;neurons&nbsp;in&nbsp;the&nbsp;previous&nbsp;layer.<br>
&nbsp;<br>
Each&nbsp;layer&nbsp;consists&nbsp;of&nbsp;weights,&nbsp;biases,&nbsp;and&nbsp;an&nbsp;activation&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size&nbsp;(int):&nbsp;The&nbsp;size&nbsp;of&nbsp;the&nbsp;input&nbsp;to&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size&nbsp;(int):&nbsp;The&nbsp;size&nbsp;of&nbsp;the&nbsp;output&nbsp;from&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation&nbsp;(str):&nbsp;The&nbsp;activation&nbsp;function&nbsp;to&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;layer.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights&nbsp;(np.ndarray):&nbsp;Weights&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;biases&nbsp;(np.ndarray):&nbsp;Biases&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation&nbsp;(str):&nbsp;<a href="#Activation">Activation</a>&nbsp;function&nbsp;name.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weight_gradients&nbsp;(np.ndarray):&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bias_gradients&nbsp;(np.ndarray):&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_cache&nbsp;(np.ndarray):&nbsp;Cached&nbsp;input&nbsp;for&nbsp;backpropagation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_cache&nbsp;(np.ndarray):&nbsp;Cached&nbsp;output&nbsp;for&nbsp;backpropagation.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#JITDenseLayer-zero_grad">zero_grad</a>():&nbsp;Resets&nbsp;the&nbsp;gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;to&nbsp;zero.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#JITDenseLayer-forward">forward</a>(X):&nbsp;Performs&nbsp;the&nbsp;forward&nbsp;pass&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#JITDenseLayer-backward">backward</a>(dA,&nbsp;reg_lambda):&nbsp;Performs&nbsp;the&nbsp;backward&nbsp;pass&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#JITDenseLayer-activate">activate</a>(Z):&nbsp;Applies&nbsp;the&nbsp;activation&nbsp;function.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#JITDenseLayer-activation_derivative">activation_derivative</a>(Z):&nbsp;Applies&nbsp;the&nbsp;derivative&nbsp;of&nbsp;the&nbsp;activation&nbsp;function.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.neural_networks.layers_jit.html#JITDenseLayer">JITDenseLayer</a></dd>
<dd>JITDenseLayer</dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>class_type</strong> = jitclass.JITDenseLayer#27bc4d69050&lt;weights:array...oat64, 2d, C),input_size:int32,output_size:int32&gt;</dl>

<hr>
Methods inherited from JITDenseLayer:<br>
<dl><dt><a name="JITDenseLayer-__init__"><strong>__init__</strong></a>(self, input_size, output_size, activation='relu')</dt><dd><span class="code">Initializes&nbsp;the&nbsp;layer&nbsp;with&nbsp;weights,&nbsp;biases,&nbsp;and&nbsp;activation&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;input&nbsp;features&nbsp;to&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;output&nbsp;features&nbsp;from&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation:&nbsp;(str),&nbsp;optional&nbsp;-&nbsp;The&nbsp;activation&nbsp;function&nbsp;to&nbsp;use&nbsp;(default&nbsp;is&nbsp;"relu").<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;weight&nbsp;matrix&nbsp;initialized&nbsp;using&nbsp;He&nbsp;initialization&nbsp;for&nbsp;ReLU&nbsp;or&nbsp;Leaky&nbsp;ReLU,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or&nbsp;Xavier&nbsp;initialization&nbsp;for&nbsp;other&nbsp;activations.<br>
&nbsp;&nbsp;&nbsp;&nbsp;biases:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;bias&nbsp;vector&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;activation&nbsp;function&nbsp;for&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weight_gradients:&nbsp;(np.ndarray)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;weights,&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bias_gradients:&nbsp;(np.ndarray)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;biases,&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_cache:&nbsp;(np.ndarray)&nbsp;-&nbsp;Cached&nbsp;input&nbsp;values&nbsp;for&nbsp;backpropagation,&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_cache:&nbsp;(np.ndarray)&nbsp;-&nbsp;Cached&nbsp;output&nbsp;values&nbsp;for&nbsp;backpropagation,&nbsp;initialized&nbsp;to&nbsp;zeros.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;input&nbsp;features&nbsp;to&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;output&nbsp;features&nbsp;from&nbsp;the&nbsp;layer.</span></dd></dl>

<dl><dt><a name="JITDenseLayer-activate"><strong>activate</strong></a>(self, Z)</dt><dd><span class="code">Apply&nbsp;activation&nbsp;function.</span></dd></dl>

<dl><dt><a name="JITDenseLayer-activation_derivative"><strong>activation_derivative</strong></a>(self, Z)</dt><dd><span class="code">Apply&nbsp;activation&nbsp;derivative.</span></dd></dl>

<dl><dt><a name="JITDenseLayer-backward"><strong>backward</strong></a>(self, dA, reg_lambda)</dt><dd><span class="code">Perform&nbsp;the&nbsp;backward&nbsp;pass&nbsp;of&nbsp;the&nbsp;layer.</span></dd></dl>

<dl><dt><a name="JITDenseLayer-forward"><strong>forward</strong></a>(self, X)</dt><dd><span class="code">Perform&nbsp;the&nbsp;forward&nbsp;pass&nbsp;of&nbsp;the&nbsp;layer.</span></dd></dl>

<dl><dt><a name="JITDenseLayer-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><span class="code">Reset&nbsp;the&nbsp;gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;to&nbsp;zero.</span></dd></dl>

<hr>
Data descriptors inherited from JITDenseLayer:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITFlattenLayer">class <strong>JITFlattenLayer</strong></a>(JITFlattenLayer)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#JITFlattenLayer">JITFlattenLayer</a>(*args,&nbsp;**kwargs)<br>
&nbsp;<br>
A&nbsp;layer&nbsp;that&nbsp;flattens&nbsp;multi-dimensional&nbsp;input&nbsp;into&nbsp;a&nbsp;2D&nbsp;array&nbsp;(batch_size,&nbsp;flattened_size).<br>
&nbsp;<br>
Useful&nbsp;for&nbsp;transitioning&nbsp;from&nbsp;convolutional&nbsp;layers&nbsp;to&nbsp;dense&nbsp;layers.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.neural_networks.layers_jit.html#JITFlattenLayer">JITFlattenLayer</a></dd>
<dd>JITFlattenLayer</dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>class_type</strong> = jitclass.JITFlattenLayer#27bc4d6b010&lt;input_shape...put_cache:array(float64, 4d, A),input_size:int32&gt;</dl>

<hr>
Methods inherited from JITFlattenLayer:<br>
<dl><dt><a name="JITFlattenLayer-__init__"><strong>__init__</strong></a>(self)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;layer&nbsp;with&nbsp;placeholder&nbsp;values&nbsp;for&nbsp;input&nbsp;and&nbsp;output&nbsp;dimensions.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_shape:&nbsp;(tuple)&nbsp;-&nbsp;Shape&nbsp;of&nbsp;the&nbsp;input&nbsp;data,&nbsp;initialized&nbsp;to&nbsp;(0,&nbsp;0,&nbsp;0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;will&nbsp;be&nbsp;set&nbsp;during&nbsp;the&nbsp;forward&nbsp;pass.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size:&nbsp;(int)&nbsp;-&nbsp;Size&nbsp;of&nbsp;the&nbsp;output,&nbsp;initialized&nbsp;to&nbsp;0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;will&nbsp;be&nbsp;set&nbsp;during&nbsp;the&nbsp;forward&nbsp;pass.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size:&nbsp;(int)&nbsp;-&nbsp;Size&nbsp;of&nbsp;the&nbsp;input,&nbsp;initialized&nbsp;to&nbsp;0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;will&nbsp;be&nbsp;set&nbsp;during&nbsp;the&nbsp;forward&nbsp;pass.<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_cache:&nbsp;(any)&nbsp;-&nbsp;Cache&nbsp;for&nbsp;input&nbsp;data,&nbsp;to&nbsp;be&nbsp;set&nbsp;during&nbsp;the&nbsp;forward&nbsp;pass.</span></dd></dl>

<dl><dt><a name="JITFlattenLayer-backward"><strong>backward</strong></a>(self, dA, reg_lambda=0)</dt><dd><span class="code">Reshapes&nbsp;the&nbsp;gradient&nbsp;back&nbsp;to&nbsp;the&nbsp;original&nbsp;input&nbsp;shape.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dA&nbsp;(np.ndarray):&nbsp;Gradient&nbsp;of&nbsp;the&nbsp;loss&nbsp;with&nbsp;respect&nbsp;to&nbsp;the&nbsp;layer's&nbsp;output,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shape&nbsp;(batch_size,&nbsp;flattened_size)<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float):&nbsp;Regularization&nbsp;parameter&nbsp;(unused&nbsp;in&nbsp;<a href="#FlattenLayer">FlattenLayer</a>).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Gradient&nbsp;with&nbsp;respect&nbsp;to&nbsp;the&nbsp;input,&nbsp;reshaped&nbsp;to&nbsp;original&nbsp;input&nbsp;shape.</span></dd></dl>

<dl><dt><a name="JITFlattenLayer-forward"><strong>forward</strong></a>(self, X)</dt><dd><span class="code">Flattens&nbsp;the&nbsp;input&nbsp;tensor.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(np.ndarray):&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(batch_size,&nbsp;channels,&nbsp;height,&nbsp;width)<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Flattened&nbsp;output&nbsp;of&nbsp;shape&nbsp;(batch_size,&nbsp;flattened_size)</span></dd></dl>

<hr>
Data descriptors inherited from JITFlattenLayer:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITHuberLoss">class <strong>JITHuberLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#JITHuberLoss">JITHuberLoss</a>(delta=1.0)<br>
&nbsp;<br>
Custom&nbsp;Huber&nbsp;loss&nbsp;implementation&nbsp;using&nbsp;numba.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;delta&nbsp;(float):&nbsp;The&nbsp;threshold&nbsp;parameter&nbsp;for&nbsp;Huber&nbsp;loss.&nbsp;Default&nbsp;is&nbsp;1.0.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="JITHuberLoss-__init__"><strong>__init__</strong></a>(self, delta=1.0)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#JITHuberLoss">JITHuberLoss</a>&nbsp;instance.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;delta&nbsp;(float):&nbsp;The&nbsp;threshold&nbsp;at&nbsp;which&nbsp;the&nbsp;loss&nbsp;function&nbsp;transitions<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;quadratic&nbsp;to&nbsp;linear.&nbsp;Default&nbsp;is&nbsp;1.0.</span></dd></dl>

<dl><dt><a name="JITHuberLoss-calculate_loss"><strong>calculate_loss</strong></a>(self, y_pred, y_true)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;Huber&nbsp;loss&nbsp;using&nbsp;the&nbsp;stored&nbsp;delta.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(np.ndarray):&nbsp;Predicted&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(np.ndarray):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;calculated&nbsp;Huber&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITMeanAbsoluteErrorLoss">class <strong>JITMeanAbsoluteErrorLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;mean&nbsp;absolute&nbsp;error&nbsp;loss&nbsp;implementation&nbsp;using&nbsp;numba.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="JITMeanAbsoluteErrorLoss-calculate_loss"><strong>calculate_loss</strong></a>(self, y_pred, y_true)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;mean&nbsp;absolute&nbsp;error&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITMeanSquaredErrorLoss">class <strong>JITMeanSquaredErrorLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;mean&nbsp;squared&nbsp;error&nbsp;loss&nbsp;implementation&nbsp;using&nbsp;numba.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="JITMeanSquaredErrorLoss-calculate_loss"><strong>calculate_loss</strong></a>(self, y_pred, y_true)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;mean&nbsp;squared&nbsp;error&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITRNNLayer">class <strong>JITRNNLayer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#JITRNNLayer">JITRNNLayer</a>(input_size,&nbsp;hidden_size,&nbsp;activation='tanh')<br>
&nbsp;<br>
A&nbsp;recurrent&nbsp;layer&nbsp;implementation&nbsp;for&nbsp;neural&nbsp;networks&nbsp;using&nbsp;Numba&nbsp;JIT&nbsp;compilation.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="JITRNNLayer-__init__"><strong>__init__</strong></a>(self, input_size, hidden_size, activation='tanh')</dt><dd><span class="code">Will&nbsp;be&nbsp;implemented&nbsp;later.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="JITSGDOptimizer">class <strong>JITSGDOptimizer</strong></a>(JITSGDOptimizer)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#JITSGDOptimizer">JITSGDOptimizer</a>(*args,&nbsp;**kwargs)<br>
&nbsp;<br>
Stochastic&nbsp;Gradient&nbsp;Descent&nbsp;(SGD)&nbsp;optimizer&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
Formula:&nbsp;w&nbsp;=&nbsp;w&nbsp;-&nbsp;learning_rate&nbsp;*&nbsp;dW,&nbsp;b&nbsp;=&nbsp;b&nbsp;-&nbsp;learning_rate&nbsp;*&nbsp;db<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;0.001.<br>
&nbsp;&nbsp;&nbsp;&nbsp;momentum&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;momentum&nbsp;factor.&nbsp;Defaults&nbsp;to&nbsp;0.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter.&nbsp;Defaults&nbsp;to&nbsp;0.0.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.neural_networks.optimizers_jit.html#JITSGDOptimizer">JITSGDOptimizer</a></dd>
<dd>JITSGDOptimizer</dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>class_type</strong> = jitclass.JITSGDOptimizer#27bc57f4bd0&lt;learning_ra...eg_lambda:float64,velocity:array(float64, 3d, C)&gt;</dl>

<hr>
Methods inherited from JITSGDOptimizer:<br>
<dl><dt><a name="JITSGDOptimizer-__init__"><strong>__init__</strong></a>(self, learning_rate=0.001, momentum=0.0, reg_lambda=0.0)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;optimizer&nbsp;with&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer&nbsp;(default&nbsp;is&nbsp;0.001).<br>
&nbsp;&nbsp;&nbsp;&nbsp;momentum:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;momentum&nbsp;factor&nbsp;for&nbsp;the&nbsp;optimizer&nbsp;(default&nbsp;is&nbsp;0.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;regularization&nbsp;parameter&nbsp;(default&nbsp;is&nbsp;0.0).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;momentum:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;momentum&nbsp;factor&nbsp;for&nbsp;the&nbsp;optimizer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;regularization&nbsp;parameter.<br>
&nbsp;&nbsp;&nbsp;&nbsp;velocity:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;velocity&nbsp;used&nbsp;for&nbsp;momentum&nbsp;updates,&nbsp;initialized&nbsp;to&nbsp;zeros.</span></dd></dl>

<dl><dt><a name="JITSGDOptimizer-initialize"><strong>initialize</strong></a>(self, layers)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;velocity&nbsp;for&nbsp;each&nbsp;layer's&nbsp;weights.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="JITSGDOptimizer-update"><strong>update</strong></a>(self, layer, dW, db, index)</dt><dd><span class="code">Updates&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;a&nbsp;layer&nbsp;using&nbsp;the&nbsp;SGD&nbsp;optimization&nbsp;algorithm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer:&nbsp;(Layer)&nbsp;-&nbsp;The&nbsp;layer&nbsp;to&nbsp;update.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dW:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;db:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;index:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="JITSGDOptimizer-update_layers"><strong>update_layers</strong></a>(self, layers, dWs, dbs)</dt><dd><span class="code">Updates&nbsp;all&nbsp;layers'&nbsp;weights&nbsp;and&nbsp;biases&nbsp;using&nbsp;the&nbsp;SGD&nbsp;optimization&nbsp;algorithm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dWs:&nbsp;(list&nbsp;of&nbsp;np.ndarray)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;for&nbsp;each&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dbs:&nbsp;(list&nbsp;of&nbsp;np.ndarray)&nbsp;-&nbsp;Gradients&nbsp;of&nbsp;the&nbsp;biases&nbsp;for&nbsp;each&nbsp;layer.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<hr>
Data descriptors inherited from JITSGDOptimizer:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="KMeans">class <strong>KMeans</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#KMeans">KMeans</a>(X,&nbsp;n_clusters=3,&nbsp;max_iter=300,&nbsp;tol=0.0001)<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;the&nbsp;K-Means&nbsp;clustering&nbsp;algorithm&nbsp;along&nbsp;with&nbsp;methods&nbsp;for&nbsp;evaluating&nbsp;the&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;and&nbsp;visualizing&nbsp;the&nbsp;clustering&nbsp;results.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_clusters:&nbsp;The&nbsp;number&nbsp;of&nbsp;clusters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;The&nbsp;tolerance&nbsp;to&nbsp;declare&nbsp;convergence.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;__init__:&nbsp;Initializes&nbsp;the&nbsp;<a href="#KMeans">KMeans</a>&nbsp;<a href="builtins.html#object">object</a>&nbsp;with&nbsp;parameters&nbsp;such&nbsp;as&nbsp;the&nbsp;data&nbsp;matrix,&nbsp;number&nbsp;of&nbsp;clusters,&nbsp;maximum&nbsp;iterations,&nbsp;and&nbsp;convergence&nbsp;tolerance.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;_handle_categorical:&nbsp;Handles&nbsp;categorical&nbsp;columns&nbsp;in&nbsp;the&nbsp;input&nbsp;data&nbsp;by&nbsp;one-hot&nbsp;encoding.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;_convert_to_ndarray:&nbsp;Converts&nbsp;input&nbsp;data&nbsp;to&nbsp;a&nbsp;NumPy&nbsp;ndarray&nbsp;and&nbsp;handles&nbsp;categorical&nbsp;columns.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;initialize_centroids:&nbsp;Randomly&nbsp;initializes&nbsp;the&nbsp;centroids&nbsp;for&nbsp;<a href="#KMeans">KMeans</a>&nbsp;clustering.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;assign_clusters:&nbsp;Assigns&nbsp;clusters&nbsp;based&nbsp;on&nbsp;the&nbsp;nearest&nbsp;centroid.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;update_centroids:&nbsp;Updates&nbsp;centroids&nbsp;based&nbsp;on&nbsp;the&nbsp;current&nbsp;cluster&nbsp;assignments.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;fit:&nbsp;Fits&nbsp;the&nbsp;<a href="#KMeans">KMeans</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;by&nbsp;iteratively&nbsp;updating&nbsp;centroids&nbsp;and&nbsp;cluster&nbsp;assignments&nbsp;until&nbsp;convergence.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;predict:&nbsp;Predicts&nbsp;the&nbsp;closest&nbsp;cluster&nbsp;each&nbsp;sample&nbsp;in&nbsp;new_X&nbsp;belongs&nbsp;to.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;elbow_method:&nbsp;Implements&nbsp;the&nbsp;elbow&nbsp;method&nbsp;to&nbsp;determine&nbsp;the&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;calinski_harabasz_index:&nbsp;Calculates&nbsp;the&nbsp;Calinski-Harabasz&nbsp;Index&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;davies_bouldin_index:&nbsp;Calculates&nbsp;the&nbsp;Davies-Bouldin&nbsp;Index&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;silhouette_score:&nbsp;Calculates&nbsp;the&nbsp;Silhouette&nbsp;Score&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;find_optimal_clusters:&nbsp;Implements&nbsp;methods&nbsp;to&nbsp;find&nbsp;the&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;using&nbsp;the&nbsp;elbow&nbsp;method,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Calinski-Harabasz&nbsp;Index,&nbsp;Davies-Bouldin&nbsp;Index,&nbsp;and&nbsp;Silhouette&nbsp;Score.&nbsp;It&nbsp;also&nbsp;plots&nbsp;the&nbsp;evaluation<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;metrics&nbsp;to&nbsp;aid&nbsp;in&nbsp;determining&nbsp;the&nbsp;optimal&nbsp;k&nbsp;value.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="KMeans-__init__"><strong>__init__</strong></a>(self, X, n_clusters=3, max_iter=300, tol=0.0001)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#KMeans">KMeans</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array,&nbsp;pandas&nbsp;DataFrame,&nbsp;or&nbsp;list).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_clusters:&nbsp;The&nbsp;number&nbsp;of&nbsp;clusters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;The&nbsp;tolerance&nbsp;to&nbsp;declare&nbsp;convergence.</span></dd></dl>

<dl><dt><a name="KMeans-assign_clusters"><strong>assign_clusters</strong></a>(self, centroids)</dt><dd><span class="code">Assign&nbsp;clusters&nbsp;based&nbsp;on&nbsp;the&nbsp;nearest&nbsp;centroid.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;centroids:&nbsp;The&nbsp;current&nbsp;centroids.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;assignments&nbsp;for&nbsp;each&nbsp;data&nbsp;point.</span></dd></dl>

<dl><dt><a name="KMeans-calinski_harabasz_index"><strong>calinski_harabasz_index</strong></a>(self, X, labels, centroids)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;Calinski-Harabasz&nbsp;Index&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;each&nbsp;data&nbsp;point.<br>
&nbsp;&nbsp;&nbsp;&nbsp;centroids:&nbsp;The&nbsp;centroids&nbsp;of&nbsp;the&nbsp;clusters.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ch_index:&nbsp;The&nbsp;computed&nbsp;Calinski-Harabasz&nbsp;Index.</span></dd></dl>

<dl><dt><a name="KMeans-davies_bouldin_index"><strong>davies_bouldin_index</strong></a>(self, X, labels, centroids)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;Davies-Bouldin&nbsp;Index&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;each&nbsp;data&nbsp;point.<br>
&nbsp;&nbsp;&nbsp;&nbsp;centroids:&nbsp;The&nbsp;centroids&nbsp;of&nbsp;the&nbsp;clusters.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;db_index:&nbsp;The&nbsp;computed&nbsp;Davies-Bouldin&nbsp;Index.</span></dd></dl>

<dl><dt><a name="KMeans-elbow_method"><strong>elbow_method</strong></a>(self, max_k=10)</dt><dd><span class="code">Implement&nbsp;the&nbsp;elbow&nbsp;method&nbsp;to&nbsp;determine&nbsp;the&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_k:&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;clusters&nbsp;to&nbsp;test.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;distortions:&nbsp;A&nbsp;list&nbsp;of&nbsp;distortions&nbsp;for&nbsp;each&nbsp;k.</span></dd></dl>

<dl><dt><a name="KMeans-find_optimal_clusters"><strong>find_optimal_clusters</strong></a>(self, max_k=10, true_k=None, save_dir=None)</dt><dd><span class="code">Find&nbsp;the&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;using&nbsp;various&nbsp;evaluation&nbsp;metrics&nbsp;and&nbsp;plot&nbsp;the&nbsp;results.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_k:&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;clusters&nbsp;to&nbsp;consider.<br>
&nbsp;&nbsp;&nbsp;&nbsp;true_k:&nbsp;The&nbsp;true&nbsp;number&nbsp;of&nbsp;clusters&nbsp;in&nbsp;the&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_dir:&nbsp;The&nbsp;directory&nbsp;to&nbsp;save&nbsp;the&nbsp;plot&nbsp;(optional).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ch_optimal_k:&nbsp;The&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;based&nbsp;on&nbsp;the&nbsp;Calinski-Harabasz&nbsp;Index.<br>
&nbsp;&nbsp;&nbsp;&nbsp;db_optimal_k:&nbsp;The&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;based&nbsp;on&nbsp;the&nbsp;Davies-Bouldin&nbsp;Index.<br>
&nbsp;&nbsp;&nbsp;&nbsp;silhouette_optimal_k:&nbsp;The&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;based&nbsp;on&nbsp;the&nbsp;Silhouette&nbsp;Score.</span></dd></dl>

<dl><dt><a name="KMeans-fit"><strong>fit</strong></a>(self)</dt><dd><span class="code">Fit&nbsp;the&nbsp;<a href="#KMeans">KMeans</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data.</span></dd></dl>

<dl><dt><a name="KMeans-initialize_centroids"><strong>initialize_centroids</strong></a>(self)</dt><dd><span class="code">Randomly&nbsp;initialize&nbsp;the&nbsp;centroids.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;centroids:&nbsp;The&nbsp;initialized&nbsp;centroids.</span></dd></dl>

<dl><dt><a name="KMeans-predict"><strong>predict</strong></a>(self, new_X)</dt><dd><span class="code">Predict&nbsp;the&nbsp;closest&nbsp;cluster&nbsp;each&nbsp;sample&nbsp;in&nbsp;new_X&nbsp;belongs&nbsp;to.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;new_X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;to&nbsp;predict&nbsp;(numpy&nbsp;array).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels:&nbsp;The&nbsp;predicted&nbsp;cluster&nbsp;labels.</span></dd></dl>

<dl><dt><a name="KMeans-silhouette_score"><strong>silhouette_score</strong></a>(self, X, labels)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;silhouette&nbsp;score&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;each&nbsp;data&nbsp;point.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;silhouette_score:&nbsp;The&nbsp;computed&nbsp;silhouette&nbsp;score.</span></dd></dl>

<dl><dt><a name="KMeans-update_centroids"><strong>update_centroids</strong></a>(self)</dt><dd><span class="code">Update&nbsp;the&nbsp;centroids&nbsp;based&nbsp;on&nbsp;the&nbsp;current&nbsp;cluster&nbsp;assignments.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;centroids:&nbsp;The&nbsp;updated&nbsp;centroids.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="KNeighborsClassifier">class <strong>KNeighborsClassifier</strong></a>(<a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">sega_learn.nearest_neighbors.base.KNeighborsBase</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#KNeighborsClassifier">KNeighborsClassifier</a>(n_neighbors=5,&nbsp;distance_metric='euclidean',&nbsp;one_hot_encode=False,&nbsp;fp_precision=&amp;lt;class&nbsp;'numpy.float64'&amp;gt;,&nbsp;numba=False)<br>
&nbsp;<br>
K-Nearest&nbsp;Neighbors&nbsp;classifier.<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;the&nbsp;k-nearest&nbsp;neighbors&nbsp;algorithm&nbsp;for&nbsp;classification.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.nearest_neighbors.knn_classifier.html#KNeighborsClassifier">KNeighborsClassifier</a></dd>
<dd><a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">sega_learn.nearest_neighbors.base.KNeighborsBase</a></dd>
<dd><a href="abc.html#ABC">abc.ABC</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="KNeighborsClassifier-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;the&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;provided&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features)&nbsp;-&nbsp;The&nbsp;input&nbsp;data&nbsp;for&nbsp;which&nbsp;to&nbsp;predict&nbsp;the&nbsp;class&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;predictions:&nbsp;array,&nbsp;shape&nbsp;(n_samples,)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;input&nbsp;data.</span></dd></dl>

<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>__abstractmethods__</strong> = frozenset()</dl>

<hr>
Methods inherited from <a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">sega_learn.nearest_neighbors.base.KNeighborsBase</a>:<br>
<dl><dt><a name="KNeighborsClassifier-__init__"><strong>__init__</strong></a>(self, n_neighbors=5, distance_metric='euclidean', one_hot_encode=False, fp_precision=&lt;class 'numpy.float64'&gt;, numba=False)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">KNeighborsBase</a>&nbsp;class.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_neighbors:&nbsp;int,&nbsp;default=5.&nbsp;The&nbsp;number&nbsp;of&nbsp;neighbors&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;KNN&nbsp;algorithm.<br>
&nbsp;&nbsp;&nbsp;&nbsp;distance_metric:&nbsp;str,&nbsp;default='euclidean'.&nbsp;The&nbsp;distance&nbsp;metric&nbsp;to&nbsp;use&nbsp;for&nbsp;calculating&nbsp;distances.<br>
&nbsp;&nbsp;&nbsp;&nbsp;one_hot_encode:&nbsp;bool,&nbsp;default=False.&nbsp;Whether&nbsp;to&nbsp;apply&nbsp;one-hot&nbsp;encoding&nbsp;to&nbsp;the&nbsp;categorical&nbsp;columns.<br>
&nbsp;&nbsp;&nbsp;&nbsp;fp_precision:&nbsp;data&nbsp;type,&nbsp;default=np.float64.&nbsp;The&nbsp;floating&nbsp;point&nbsp;precision&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;calculations.<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba:&nbsp;bool,&nbsp;default=True.&nbsp;Whether&nbsp;to&nbsp;use&nbsp;numba&nbsp;for&nbsp;speeding&nbsp;up&nbsp;the&nbsp;calculations.</span></dd></dl>

<dl><dt><a name="KNeighborsClassifier-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;using&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features)&nbsp;-&nbsp;The&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,)&nbsp;-&nbsp;The&nbsp;target&nbsp;values.</span></dd></dl>

<dl><dt><a name="KNeighborsClassifier-get_distance_indices"><strong>get_distance_indices</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;the&nbsp;distances&nbsp;and&nbsp;return&nbsp;the&nbsp;indices&nbsp;of&nbsp;the&nbsp;nearest&nbsp;points&nbsp;im&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features)&nbsp;-&nbsp;The&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;indices:&nbsp;array,&nbsp;shape&nbsp;(n_samples,&nbsp;n_neighbors)&nbsp;-&nbsp;The&nbsp;indices&nbsp;of&nbsp;the&nbsp;nearest&nbsp;neighbors.</span></dd></dl>

<hr>
Data descriptors inherited from <a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">sega_learn.nearest_neighbors.base.KNeighborsBase</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="KNeighborsRegressor">class <strong>KNeighborsRegressor</strong></a>(<a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">sega_learn.nearest_neighbors.base.KNeighborsBase</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#KNeighborsRegressor">KNeighborsRegressor</a>(n_neighbors=5,&nbsp;distance_metric='euclidean',&nbsp;one_hot_encode=False,&nbsp;fp_precision=&amp;lt;class&nbsp;'numpy.float64'&amp;gt;,&nbsp;numba=False)<br>
&nbsp;<br>
K-Nearest&nbsp;Neighbors&nbsp;classifier.<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;the&nbsp;k-nearest&nbsp;neighbors&nbsp;algorithm&nbsp;for&nbsp;regression.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.nearest_neighbors.knn_regressor.html#KNeighborsRegressor">KNeighborsRegressor</a></dd>
<dd><a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">sega_learn.nearest_neighbors.base.KNeighborsBase</a></dd>
<dd><a href="abc.html#ABC">abc.ABC</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="KNeighborsRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;the&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;provided&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features)&nbsp;-&nbsp;The&nbsp;input&nbsp;data&nbsp;for&nbsp;which&nbsp;to&nbsp;predict&nbsp;the&nbsp;class&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;predictions:&nbsp;array,&nbsp;shape&nbsp;(n_samples,)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;input&nbsp;data.</span></dd></dl>

<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>__abstractmethods__</strong> = frozenset()</dl>

<hr>
Methods inherited from <a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">sega_learn.nearest_neighbors.base.KNeighborsBase</a>:<br>
<dl><dt><a name="KNeighborsRegressor-__init__"><strong>__init__</strong></a>(self, n_neighbors=5, distance_metric='euclidean', one_hot_encode=False, fp_precision=&lt;class 'numpy.float64'&gt;, numba=False)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">KNeighborsBase</a>&nbsp;class.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_neighbors:&nbsp;int,&nbsp;default=5.&nbsp;The&nbsp;number&nbsp;of&nbsp;neighbors&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;KNN&nbsp;algorithm.<br>
&nbsp;&nbsp;&nbsp;&nbsp;distance_metric:&nbsp;str,&nbsp;default='euclidean'.&nbsp;The&nbsp;distance&nbsp;metric&nbsp;to&nbsp;use&nbsp;for&nbsp;calculating&nbsp;distances.<br>
&nbsp;&nbsp;&nbsp;&nbsp;one_hot_encode:&nbsp;bool,&nbsp;default=False.&nbsp;Whether&nbsp;to&nbsp;apply&nbsp;one-hot&nbsp;encoding&nbsp;to&nbsp;the&nbsp;categorical&nbsp;columns.<br>
&nbsp;&nbsp;&nbsp;&nbsp;fp_precision:&nbsp;data&nbsp;type,&nbsp;default=np.float64.&nbsp;The&nbsp;floating&nbsp;point&nbsp;precision&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;calculations.<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba:&nbsp;bool,&nbsp;default=True.&nbsp;Whether&nbsp;to&nbsp;use&nbsp;numba&nbsp;for&nbsp;speeding&nbsp;up&nbsp;the&nbsp;calculations.</span></dd></dl>

<dl><dt><a name="KNeighborsRegressor-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;using&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features)&nbsp;-&nbsp;The&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,)&nbsp;-&nbsp;The&nbsp;target&nbsp;values.</span></dd></dl>

<dl><dt><a name="KNeighborsRegressor-get_distance_indices"><strong>get_distance_indices</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;the&nbsp;distances&nbsp;and&nbsp;return&nbsp;the&nbsp;indices&nbsp;of&nbsp;the&nbsp;nearest&nbsp;points&nbsp;im&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features)&nbsp;-&nbsp;The&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;indices:&nbsp;array,&nbsp;shape&nbsp;(n_samples,&nbsp;n_neighbors)&nbsp;-&nbsp;The&nbsp;indices&nbsp;of&nbsp;the&nbsp;nearest&nbsp;neighbors.</span></dd></dl>

<hr>
Data descriptors inherited from <a href="sega_learn.nearest_neighbors.base.html#KNeighborsBase">sega_learn.nearest_neighbors.base.KNeighborsBase</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Lasso">class <strong>Lasso</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#Lasso">Lasso</a>(alpha=1.0,&nbsp;fit_intercept=True,&nbsp;max_iter=10000,&nbsp;tol=0.0001,&nbsp;compile_numba=False)<br>
&nbsp;<br>
Fits&nbsp;the&nbsp;<a href="#Lasso">Lasso</a>&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
<a href="#Lasso">Lasso</a>&nbsp;regression&nbsp;implements&nbsp;L1&nbsp;regularization,&nbsp;which&nbsp;helps&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;a&nbsp;penalty&nbsp;term&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;feature&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;target&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;custom_metrics:&nbsp;(dict:&nbsp;str&nbsp;-&gt;&nbsp;callable),&nbsp;optional&nbsp;-&nbsp;Custom&nbsp;metrics&nbsp;for&nbsp;evaluation&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;If&nbsp;True,&nbsp;prints&nbsp;progress&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef_:&nbsp;(np.ndarray)&nbsp;-&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;linear&nbsp;regression&nbsp;problem.&nbsp;If&nbsp;`fit_intercept`&nbsp;is&nbsp;True,&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;the&nbsp;intercept.<br>
&nbsp;&nbsp;&nbsp;&nbsp;intercept_:&nbsp;(float)&nbsp;-&nbsp;Independent&nbsp;term&nbsp;in&nbsp;the&nbsp;linear&nbsp;model.&nbsp;Set&nbsp;to&nbsp;0.0&nbsp;if&nbsp;`fit_intercept`&nbsp;is&nbsp;False.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;results:&nbsp;(list)&nbsp;-&nbsp;A&nbsp;list&nbsp;of&nbsp;dictionaries&nbsp;containing&nbsp;model&nbsp;performance&nbsp;metrics.<br>
&nbsp;&nbsp;&nbsp;&nbsp;predictions:&nbsp;(dict)&nbsp;-&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;predictions&nbsp;for&nbsp;each&nbsp;model.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="Lasso-__init__"><strong>__init__</strong></a>(self, alpha=1.0, fit_intercept=True, max_iter=10000, tol=0.0001, compile_numba=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#Lasso">Lasso</a>&nbsp;Regression&nbsp;model.<br>
&nbsp;<br>
<a href="#Lasso">Lasso</a>&nbsp;regression&nbsp;implements&nbsp;L1&nbsp;regularization,&nbsp;which&nbsp;helps&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;a&nbsp;penalty&nbsp;term&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;alpha:&nbsp;(float)&nbsp;-&nbsp;Regularization&nbsp;strength;&nbsp;must&nbsp;be&nbsp;a&nbsp;positive&nbsp;float&nbsp;(default&nbsp;is&nbsp;1.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;fit_intercept:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model&nbsp;(default&nbsp;is&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;the&nbsp;coordinate&nbsp;descent&nbsp;solver&nbsp;(default&nbsp;is&nbsp;10000).<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Tolerance&nbsp;for&nbsp;the&nbsp;optimization.&nbsp;The&nbsp;optimization&nbsp;stops&nbsp;when&nbsp;the&nbsp;change&nbsp;in&nbsp;the&nbsp;coefficients&nbsp;is&nbsp;less&nbsp;than&nbsp;this&nbsp;tolerance&nbsp;(default&nbsp;is&nbsp;1e-4).<br>
&nbsp;&nbsp;&nbsp;&nbsp;compile_numba:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;precompile&nbsp;the&nbsp;numba&nbsp;functions&nbsp;(default&nbsp;is&nbsp;False).&nbsp;If&nbsp;True,&nbsp;the&nbsp;numba&nbsp;fitting&nbsp;functions&nbsp;will&nbsp;be&nbsp;compiled&nbsp;before&nbsp;use.</span></dd></dl>

<dl><dt><a name="Lasso-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;the&nbsp;string&nbsp;representation&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="Lasso-fit"><strong>fit</strong></a>(self, X, y, numba=False)</dt><dd><span class="code">Fits&nbsp;the&nbsp;<a href="#Lasso">Lasso</a>&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data&nbsp;using&nbsp;coordinate&nbsp;descent.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;use&nbsp;numba&nbsp;for&nbsp;faster&nbsp;computation&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#Lasso">Lasso</a>)&nbsp;-&nbsp;The&nbsp;fitted&nbsp;<a href="#Lasso">Lasso</a>&nbsp;Regression&nbsp;model.</span></dd></dl>

<dl><dt><a name="Lasso-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Computes&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;formula&nbsp;:&nbsp;str:&nbsp;The&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="Lasso-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;using&nbsp;the&nbsp;<a href="#Lasso">Lasso</a>&nbsp;Regression&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;Predicted&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="LinearDiscriminantAnalysis">class <strong>LinearDiscriminantAnalysis</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#LinearDiscriminantAnalysis">LinearDiscriminantAnalysis</a>(solver='svd',&nbsp;priors=None)<br>
&nbsp;<br>
Implements&nbsp;Linear&nbsp;Discriminant&nbsp;Analysis.<br>
&nbsp;<br>
A&nbsp;classifier&nbsp;with&nbsp;a&nbsp;linear&nbsp;decision&nbsp;boundary,&nbsp;generated&nbsp;by&nbsp;fitting&nbsp;class&nbsp;conditional&nbsp;densities&nbsp;to&nbsp;the&nbsp;data&nbsp;and&nbsp;using&nbsp;Bayes'&nbsp;rule.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;solver:&nbsp;(str)&nbsp;-&nbsp;{'svd',&nbsp;'lsqr',&nbsp;'eigen'},&nbsp;default='svd'.&nbsp;Solver&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;LDA.<br>
&nbsp;&nbsp;&nbsp;&nbsp;priors:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Prior&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;classes&nbsp;(default&nbsp;is&nbsp;None).<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="LinearDiscriminantAnalysis-__init__"><strong>__init__</strong></a>(self, solver='svd', priors=None)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;Linear&nbsp;Discriminant&nbsp;Analysis&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;solver:&nbsp;(str)&nbsp;-&nbsp;{'svd',&nbsp;'lsqr',&nbsp;'eigen'},&nbsp;default='svd'.&nbsp;Solver&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;LDA.<br>
&nbsp;&nbsp;&nbsp;&nbsp;priors:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Prior&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;classes&nbsp;(default&nbsp;is&nbsp;None).</span></dd></dl>

<dl><dt><a name="LinearDiscriminantAnalysis-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Computes&nbsp;the&nbsp;log-likelihood&nbsp;of&nbsp;each&nbsp;class&nbsp;for&nbsp;the&nbsp;input&nbsp;data.&nbsp;The&nbsp;decision&nbsp;function&nbsp;is&nbsp;the&nbsp;log-likelihood&nbsp;of&nbsp;each&nbsp;class.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Test&nbsp;feature&nbsp;data.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;scores:&nbsp;(np.ndarray)&nbsp;-&nbsp;Log-likelihood&nbsp;of&nbsp;each&nbsp;class&nbsp;for&nbsp;the&nbsp;input&nbsp;samples.</span></dd></dl>

<dl><dt><a name="LinearDiscriminantAnalysis-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fits&nbsp;the&nbsp;LDA&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data.</span></dd></dl>

<dl><dt><a name="LinearDiscriminantAnalysis-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Test&nbsp;feature&nbsp;data.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;predictions:&nbsp;(np.ndarray)&nbsp;-&nbsp;Predicted&nbsp;class&nbsp;labels.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="LinearSVC">class <strong>LinearSVC</strong></a>(<a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#LinearSVC">LinearSVC</a>(C=1.0,&nbsp;tol=0.0001,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;numba=False)<br>
&nbsp;<br>
<a href="#LinearSVC">LinearSVC</a>&nbsp;is&nbsp;a&nbsp;linear&nbsp;Support&nbsp;Vector&nbsp;Classifier&nbsp;(SVC)&nbsp;implementation&nbsp;that&nbsp;uses&nbsp;gradient&nbsp;descent&nbsp;for&nbsp;optimization.<br>
&nbsp;<br>
It&nbsp;supports&nbsp;binary&nbsp;and&nbsp;multi-class&nbsp;classification&nbsp;using&nbsp;a&nbsp;one-vs-rest&nbsp;strategy.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C&nbsp;(float):&nbsp;Regularization&nbsp;parameter.&nbsp;Default&nbsp;is&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol&nbsp;(float):&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria.&nbsp;Default&nbsp;is&nbsp;1e-4.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter&nbsp;(int):&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;use&nbsp;Numba-accelerated&nbsp;computations.&nbsp;Default&nbsp;is&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;(ndarray):&nbsp;Weight&nbsp;vector&nbsp;for&nbsp;the&nbsp;linear&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;b&nbsp;(float):&nbsp;Bias&nbsp;term&nbsp;for&nbsp;the&nbsp;linear&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba_available&nbsp;(bool):&nbsp;Indicates&nbsp;if&nbsp;Numba&nbsp;is&nbsp;available&nbsp;for&nbsp;use.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#LinearSVC-__init__">__init__</a>(self,&nbsp;C=1.0,&nbsp;tol=1e-4,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;numba=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;<a href="#LinearSVC">LinearSVC</a>&nbsp;instance&nbsp;with&nbsp;hyperparameters&nbsp;and&nbsp;checks&nbsp;for&nbsp;Numba&nbsp;availability.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_fit(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;the&nbsp;<a href="#LinearSVC">LinearSVC</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data&nbsp;using&nbsp;gradient&nbsp;descent.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_predict_binary(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predicts&nbsp;class&nbsp;labels&nbsp;{-1,&nbsp;1}&nbsp;for&nbsp;binary&nbsp;classification.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_predict_multiclass(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;multi-class&nbsp;classification&nbsp;using&nbsp;one-vs-rest&nbsp;strategy.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#LinearSVC-decision_function">decision_function</a>(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;raw&nbsp;decision&nbsp;function&nbsp;values&nbsp;before&nbsp;thresholding.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_score_binary(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;the&nbsp;mean&nbsp;accuracy&nbsp;of&nbsp;predictions&nbsp;for&nbsp;binary&nbsp;classification.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_score_multiclass(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;the&nbsp;mean&nbsp;accuracy&nbsp;of&nbsp;predictions&nbsp;for&nbsp;multi-class&nbsp;classification.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.svm.linerarSVM.html#LinearSVC">LinearSVC</a></dd>
<dd><a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="LinearSVC-__init__"><strong>__init__</strong></a>(self, C=1.0, tol=0.0001, max_iter=1000, learning_rate=0.01, numba=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#LinearSVC">LinearSVC</a>&nbsp;instance&nbsp;with&nbsp;hyperparameters&nbsp;and&nbsp;checks&nbsp;for&nbsp;Numba&nbsp;availability.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C:&nbsp;(float)&nbsp;-&nbsp;Regularization&nbsp;parameter.&nbsp;Default&nbsp;is&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float)&nbsp;-&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria.&nbsp;Default&nbsp;is&nbsp;1e-4.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float)&nbsp;-&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;use&nbsp;Numba-accelerated&nbsp;computations.&nbsp;Default&nbsp;is&nbsp;False.</span></dd></dl>

<dl><dt><a name="LinearSVC-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;raw&nbsp;decision&nbsp;function&nbsp;values&nbsp;before&nbsp;thresholding.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features)):&nbsp;Input&nbsp;samples.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;scores&nbsp;(array&nbsp;of&nbsp;shape&nbsp;(n_samples,)):&nbsp;Decision&nbsp;function&nbsp;values.</span></dd></dl>

<hr>
Methods inherited from <a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>:<br>
<dl><dt><a name="LinearSVC-__sklearn_is_fitted__"><strong>__sklearn_is_fitted__</strong></a>(self)</dt><dd><span class="code">Checks&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted&nbsp;(for&nbsp;sklearn&nbsp;compatibility).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fitted:&nbsp;(bool)&nbsp;-&nbsp;True&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted,&nbsp;otherwise&nbsp;False.</span></dd></dl>

<dl><dt><a name="LinearSVC-fit"><strong>fit</strong></a>(self, X, y=None)</dt><dd><span class="code">Fits&nbsp;the&nbsp;SVM&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Training&nbsp;vectors.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Target&nbsp;values.&nbsp;Default&nbsp;is&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;fitted&nbsp;instance.</span></dd></dl>

<dl><dt><a name="LinearSVC-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><span class="code">Retrieves&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;deep:&nbsp;(bool)&nbsp;-&nbsp;If&nbsp;True,&nbsp;returns&nbsp;parameters&nbsp;of&nbsp;subobjects&nbsp;as&nbsp;well.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;params:&nbsp;(dict)&nbsp;-&nbsp;Dictionary&nbsp;of&nbsp;hyperparameter&nbsp;names&nbsp;and&nbsp;values.</span></dd></dl>

<dl><dt><a name="LinearSVC-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Input&nbsp;samples.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;predicted_labels:&nbsp;(ndarray&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Predicted&nbsp;class&nbsp;labels.</span></dd></dl>

<dl><dt><a name="LinearSVC-score"><strong>score</strong></a>(self, X, y)</dt><dd><span class="code">Computes&nbsp;the&nbsp;mean&nbsp;accuracy&nbsp;of&nbsp;the&nbsp;model&nbsp;on&nbsp;the&nbsp;given&nbsp;test&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Test&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;True&nbsp;class&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;score:&nbsp;(float)&nbsp;-&nbsp;Mean&nbsp;accuracy&nbsp;of&nbsp;predictions.</span></dd></dl>

<dl><dt><a name="LinearSVC-set_params"><strong>set_params</strong></a>(self, **parameters)</dt><dd><span class="code">Sets&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;**parameters:&nbsp;(dict)&nbsp;-&nbsp;Hyperparameter&nbsp;names&nbsp;and&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;updated&nbsp;estimator&nbsp;instance.</span></dd></dl>

<hr>
Data descriptors inherited from <a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="LinearSVR">class <strong>LinearSVR</strong></a>(<a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#LinearSVR">LinearSVR</a>(C=1.0,&nbsp;tol=0.0001,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;epsilon=0.1,&nbsp;numba=False)<br>
&nbsp;<br>
<a href="#LinearSVR">LinearSVR</a>:&nbsp;A&nbsp;linear&nbsp;Support&nbsp;Vector&nbsp;Regression&nbsp;(SVR)&nbsp;model&nbsp;using&nbsp;epsilon-insensitive&nbsp;loss.<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;a&nbsp;linear&nbsp;SVR&nbsp;model&nbsp;with&nbsp;support&nbsp;for&nbsp;mini-batch&nbsp;gradient&nbsp;descent<br>
and&nbsp;optional&nbsp;acceleration&nbsp;using&nbsp;Numba.&nbsp;It&nbsp;is&nbsp;designed&nbsp;for&nbsp;regression&nbsp;tasks&nbsp;and&nbsp;uses<br>
epsilon-insensitive&nbsp;loss&nbsp;to&nbsp;handle&nbsp;errors&nbsp;within&nbsp;a&nbsp;specified&nbsp;margin.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C&nbsp;(float):&nbsp;Regularization&nbsp;parameter.&nbsp;Default&nbsp;is&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol&nbsp;(float):&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria.&nbsp;Default&nbsp;is&nbsp;1e-4.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter&nbsp;(int):&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float):&nbsp;Epsilon&nbsp;parameter&nbsp;for&nbsp;epsilon-insensitive&nbsp;loss.&nbsp;Default&nbsp;is&nbsp;0.1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;use&nbsp;Numba&nbsp;for&nbsp;acceleration.&nbsp;Default&nbsp;is&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;(ndarray):&nbsp;Weight&nbsp;vector&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;b&nbsp;(float):&nbsp;Bias&nbsp;term&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba_available&nbsp;(bool):&nbsp;Indicates&nbsp;if&nbsp;Numba&nbsp;is&nbsp;available&nbsp;for&nbsp;acceleration.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train&nbsp;(ndarray):&nbsp;Training&nbsp;data&nbsp;used&nbsp;for&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train&nbsp;(ndarray):&nbsp;Target&nbsp;values&nbsp;used&nbsp;for&nbsp;fitting.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#LinearSVR-__init__">__init__</a>(self,&nbsp;C=1.0,&nbsp;tol=1e-4,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;epsilon=0.1,&nbsp;numba=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initialize&nbsp;the&nbsp;<a href="#LinearSVR">LinearSVR</a>&nbsp;model&nbsp;with&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_fit(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fit&nbsp;the&nbsp;<a href="#LinearSVR">LinearSVR</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data&nbsp;using&nbsp;mini-batch&nbsp;gradient&nbsp;descent.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#LinearSVR-predict">predict</a>(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predict&nbsp;continuous&nbsp;target&nbsp;values&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#LinearSVR-decision_function">decision_function</a>(self,&nbsp;X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute&nbsp;raw&nbsp;decision&nbsp;function&nbsp;values&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#LinearSVR-score">score</a>(self,&nbsp;X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute&nbsp;the&nbsp;coefficient&nbsp;of&nbsp;determination&nbsp;(R&nbsp;score)&nbsp;for&nbsp;the&nbsp;model's&nbsp;predictions.<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValueError:&nbsp;If&nbsp;a&nbsp;non-linear&nbsp;kernel&nbsp;is&nbsp;specified,&nbsp;as&nbsp;<a href="#LinearSVR">LinearSVR</a>&nbsp;only&nbsp;supports&nbsp;linear&nbsp;kernels.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.svm.linerarSVM.html#LinearSVR">LinearSVR</a></dd>
<dd><a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="LinearSVR-__init__"><strong>__init__</strong></a>(self, C=1.0, tol=0.0001, max_iter=1000, learning_rate=0.01, epsilon=0.1, numba=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#LinearSVR">LinearSVR</a>&nbsp;instance&nbsp;with&nbsp;hyperparameters&nbsp;and&nbsp;checks&nbsp;for&nbsp;Numba&nbsp;availability.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C:&nbsp;(float)&nbsp;-&nbsp;Regularization&nbsp;parameter.&nbsp;Default&nbsp;is&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float)&nbsp;-&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria.&nbsp;Default&nbsp;is&nbsp;1e-4.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float)&nbsp;-&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;gradient&nbsp;descent.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon:&nbsp;(float)&nbsp;-&nbsp;Epsilon&nbsp;parameter&nbsp;for&nbsp;epsilon-insensitive&nbsp;loss.&nbsp;Default&nbsp;is&nbsp;0.1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;use&nbsp;Numba-accelerated&nbsp;computations.&nbsp;Default&nbsp;is&nbsp;False.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="LinearSVR-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;raw&nbsp;decision&nbsp;function&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Input&nbsp;samples.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;scores:&nbsp;(array&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Predicted&nbsp;values.</span></dd></dl>

<dl><dt><a name="LinearSVR-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;continuous&nbsp;target&nbsp;values&nbsp;for&nbsp;input&nbsp;samples.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Input&nbsp;samples.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(array&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Predicted&nbsp;values.</span></dd></dl>

<dl><dt><a name="LinearSVR-score"><strong>score</strong></a>(self, X, y)</dt><dd><span class="code">Compute&nbsp;the&nbsp;coefficient&nbsp;of&nbsp;determination&nbsp;(R&nbsp;score).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Test&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;score:&nbsp;(float)&nbsp;-&nbsp;R&nbsp;score&nbsp;of&nbsp;predictions.</span></dd></dl>

<hr>
Methods inherited from <a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>:<br>
<dl><dt><a name="LinearSVR-__sklearn_is_fitted__"><strong>__sklearn_is_fitted__</strong></a>(self)</dt><dd><span class="code">Checks&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted&nbsp;(for&nbsp;sklearn&nbsp;compatibility).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fitted:&nbsp;(bool)&nbsp;-&nbsp;True&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted,&nbsp;otherwise&nbsp;False.</span></dd></dl>

<dl><dt><a name="LinearSVR-fit"><strong>fit</strong></a>(self, X, y=None)</dt><dd><span class="code">Fits&nbsp;the&nbsp;SVM&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Training&nbsp;vectors.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Target&nbsp;values.&nbsp;Default&nbsp;is&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;fitted&nbsp;instance.</span></dd></dl>

<dl><dt><a name="LinearSVR-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><span class="code">Retrieves&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;deep:&nbsp;(bool)&nbsp;-&nbsp;If&nbsp;True,&nbsp;returns&nbsp;parameters&nbsp;of&nbsp;subobjects&nbsp;as&nbsp;well.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;params:&nbsp;(dict)&nbsp;-&nbsp;Dictionary&nbsp;of&nbsp;hyperparameter&nbsp;names&nbsp;and&nbsp;values.</span></dd></dl>

<dl><dt><a name="LinearSVR-set_params"><strong>set_params</strong></a>(self, **parameters)</dt><dd><span class="code">Sets&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;**parameters:&nbsp;(dict)&nbsp;-&nbsp;Hyperparameter&nbsp;names&nbsp;and&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;updated&nbsp;estimator&nbsp;instance.</span></dd></dl>

<hr>
Data descriptors inherited from <a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="LogisticRegression">class <strong>LogisticRegression</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#LogisticRegression">LogisticRegression</a>(learning_rate=0.01,&nbsp;max_iter=1000)<br>
&nbsp;<br>
Implements&nbsp;Logistic&nbsp;Regression&nbsp;using&nbsp;gradient&nbsp;descent.&nbsp;Supports&nbsp;binary&nbsp;and&nbsp;multiclass&nbsp;classification.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float)&nbsp;-&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;gradient&nbsp;updates&nbsp;(default&nbsp;is&nbsp;0.01).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;(default&nbsp;is&nbsp;1000).<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="LogisticRegression-__init__"><strong>__init__</strong></a>(self, learning_rate=0.01, max_iter=1000)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;classifier&nbsp;with&nbsp;specified&nbsp;hyperparameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;step&nbsp;size&nbsp;for&nbsp;updating&nbsp;weights&nbsp;during&nbsp;training.&nbsp;Defaults&nbsp;to&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;the&nbsp;training&nbsp;process.&nbsp;Defaults&nbsp;to&nbsp;1000.</span></dd></dl>

<dl><dt><a name="LogisticRegression-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fits&nbsp;the&nbsp;Logistic&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<dl><dt><a name="LogisticRegression-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Test&nbsp;feature&nbsp;data.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;predictions:&nbsp;(np.ndarray)&nbsp;-&nbsp;Predicted&nbsp;class&nbsp;labels.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="MeanAbsoluteErrorLoss">class <strong>MeanAbsoluteErrorLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;mean&nbsp;absolute&nbsp;error&nbsp;loss&nbsp;implementation&nbsp;using&nbsp;numpy.<br>
&nbsp;<br>
Formula:&nbsp;mean(abs(y_true&nbsp;-&nbsp;y_pred))<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#MeanAbsoluteErrorLoss-__call__">__call__</a>(self,&nbsp;y_true,&nbsp;y_pred):&nbsp;Calculate&nbsp;the&nbsp;mean&nbsp;absolute&nbsp;error&nbsp;loss.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="MeanAbsoluteErrorLoss-__call__"><strong>__call__</strong></a>(self, y_true, y_pred)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;mean&nbsp;absolute&nbsp;error&nbsp;loss.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(np.ndarray):&nbsp;The&nbsp;true&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(np.ndarray):&nbsp;The&nbsp;predicted&nbsp;values&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;mean&nbsp;absolute&nbsp;error&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="MeanSquaredErrorLoss">class <strong>MeanSquaredErrorLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;mean&nbsp;squared&nbsp;error&nbsp;loss&nbsp;implementation&nbsp;using&nbsp;numpy.<br>
&nbsp;<br>
Formula:&nbsp;mean((y_true&nbsp;-&nbsp;y_pred)&nbsp;**&nbsp;2)<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#MeanSquaredErrorLoss-__call__">__call__</a>(self,&nbsp;y_true,&nbsp;y_pred):&nbsp;Calculate&nbsp;the&nbsp;mean&nbsp;squared&nbsp;error&nbsp;loss.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="MeanSquaredErrorLoss-__call__"><strong>__call__</strong></a>(self, y_true, y_pred)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;mean&nbsp;squared&nbsp;error&nbsp;loss.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(np.ndarray):&nbsp;The&nbsp;true&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(np.ndarray):&nbsp;The&nbsp;predicted&nbsp;values&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;mean&nbsp;squared&nbsp;error&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Metrics">class <strong>Metrics</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Implements&nbsp;various&nbsp;regression&nbsp;and&nbsp;classification&nbsp;metrics.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Class methods defined here:<br>
<dl><dt><a name="Metrics-accuracy"><strong>accuracy</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;accuracy&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;accuracy:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;accuracy&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-classification_report"><strong>classification_report</strong></a>(y_true, y_pred)</dt><dd><span class="code">Generates&nbsp;a&nbsp;classification&nbsp;report&nbsp;for&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;report:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;classification&nbsp;report.</span></dd></dl>

<dl><dt><a name="Metrics-confusion_matrix"><strong>confusion_matrix</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;confusion&nbsp;matrix&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;cm:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;confusion&nbsp;matrix.</span></dd></dl>

<dl><dt><a name="Metrics-f1_score"><strong>f1_score</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;F1&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;f1_score:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;F1&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-log_loss"><strong>log_loss</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;log&nbsp;loss&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;probabilities.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;log_loss:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;log&nbsp;loss.</span></dd></dl>

<dl><dt><a name="Metrics-mean_absolute_error"><strong>mean_absolute_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;absolute&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;mae:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;mean&nbsp;absolute&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-mean_absolute_percentage_error"><strong>mean_absolute_percentage_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;absolute&nbsp;percentage&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;mape:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;mean&nbsp;absolute&nbsp;percentage&nbsp;error&nbsp;as&nbsp;a&nbsp;decimal.&nbsp;Returns&nbsp;np.nan&nbsp;if&nbsp;y_true&nbsp;is&nbsp;all&nbsp;zeros.</span></dd></dl>

<dl><dt><a name="Metrics-mean_percentage_error"><strong>mean_percentage_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;percentage&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;mpe:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;mean&nbsp;percentage&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-mean_squared_error"><strong>mean_squared_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;squared&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;mse:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;mean&nbsp;squared&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-precision"><strong>precision</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;precision&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;precision:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;precision&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-r_squared"><strong>r_squared</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;R-squared&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;r_squared:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;R-squared&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-recall"><strong>recall</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;recall&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;recall:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;recall&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-root_mean_squared_error"><strong>root_mean_squared_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;root&nbsp;mean&nbsp;squared&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;rmse:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;root&nbsp;mean&nbsp;squared&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-show_classification_report"><strong>show_classification_report</strong></a>(y_true, y_pred)</dt><dd><span class="code">Generates&nbsp;and&nbsp;displays&nbsp;a&nbsp;classification&nbsp;report&nbsp;for&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;report:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;classification&nbsp;report.</span></dd></dl>

<dl><dt><a name="Metrics-show_confusion_matrix"><strong>show_confusion_matrix</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;and&nbsp;displays&nbsp;the&nbsp;confusion&nbsp;matrix&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;true&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;cm:&nbsp;(np.ndarray)&nbsp;-&nbsp;The&nbsp;confusion&nbsp;matrix.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="ModelSelectionUtility">class <strong>ModelSelectionUtility</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">A&nbsp;utility&nbsp;class&nbsp;for&nbsp;hyperparameter&nbsp;tuning&nbsp;and&nbsp;cross-validation&nbsp;of&nbsp;machine&nbsp;learning&nbsp;models.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Static methods defined here:<br>
<dl><dt><a name="ModelSelectionUtility-cross_validate"><strong>cross_validate</strong></a>(model, X, y, params, cv=5, metric='mse', direction='minimize', verbose=False)</dt><dd><span class="code">Implements&nbsp;a&nbsp;custom&nbsp;cross-validation&nbsp;for&nbsp;hyperparameter&nbsp;tuning.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;The&nbsp;model&nbsp;Object&nbsp;to&nbsp;be&nbsp;tuned.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;feature&nbsp;columns.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;label&nbsp;column.<br>
&nbsp;&nbsp;&nbsp;&nbsp;params:&nbsp;(dict)&nbsp;-&nbsp;The&nbsp;hyperparameters&nbsp;to&nbsp;be&nbsp;tuned.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cv:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;folds&nbsp;for&nbsp;cross-validation.&nbsp;Default&nbsp;is&nbsp;5.<br>
&nbsp;&nbsp;&nbsp;&nbsp;metric:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;metric&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;evaluation.&nbsp;Default&nbsp;is&nbsp;'mse'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Regression&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'mse',&nbsp;'r2',&nbsp;'mae',&nbsp;'rmse',&nbsp;'mape',&nbsp;'mpe'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Classification&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'accuracy',&nbsp;'precision',&nbsp;'recall',&nbsp;'f1',&nbsp;'log_loss'<br>
&nbsp;&nbsp;&nbsp;&nbsp;direction:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;direction&nbsp;to&nbsp;optimize&nbsp;the&nbsp;metric.&nbsp;Default&nbsp;is&nbsp;'minimize'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;(bool)&nbsp;-&nbsp;A&nbsp;flag&nbsp;to&nbsp;display&nbsp;the&nbsp;training&nbsp;progress.&nbsp;Default&nbsp;is&nbsp;False.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuple:&nbsp;A&nbsp;tuple&nbsp;containing&nbsp;the&nbsp;scores&nbsp;(list)&nbsp;and&nbsp;the&nbsp;trained&nbsp;model.</span></dd></dl>

<dl><dt><a name="ModelSelectionUtility-get_param_combinations"><strong>get_param_combinations</strong></a>(param_grid)</dt><dd><span class="code">Generates&nbsp;all&nbsp;possible&nbsp;combinations&nbsp;of&nbsp;hyperparameters.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;param_combinations&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;dictionaries&nbsp;containing&nbsp;hyperparameter&nbsp;combinations.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="NeuralNetworkBase">class <strong>NeuralNetworkBase</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#NeuralNetworkBase">NeuralNetworkBase</a>(layers,&nbsp;dropout_rate=0.0,&nbsp;reg_lambda=0.0,&nbsp;activations=None,&nbsp;loss_function=None,&nbsp;regressor=False)<br>
&nbsp;<br>
<a href="#NeuralNetworkBase">NeuralNetworkBase</a>&nbsp;is&nbsp;an&nbsp;abstract&nbsp;base&nbsp;class&nbsp;for&nbsp;building&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
It&nbsp;provides&nbsp;a&nbsp;framework&nbsp;for&nbsp;initializing&nbsp;layers,&nbsp;performing&nbsp;forward&nbsp;and&nbsp;backward&nbsp;propagation,<br>
training,&nbsp;evaluating,&nbsp;and&nbsp;predicting&nbsp;with&nbsp;a&nbsp;neural&nbsp;network.&nbsp;Subclasses&nbsp;should&nbsp;implement<br>
the&nbsp;abstract&nbsp;methods&nbsp;to&nbsp;define&nbsp;specific&nbsp;behavior.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer_sizes&nbsp;(list):&nbsp;Sizes&nbsp;of&nbsp;the&nbsp;layers&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dropout_rate&nbsp;(float):&nbsp;Dropout&nbsp;rate&nbsp;for&nbsp;regularization.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float):&nbsp;Regularization&nbsp;strength&nbsp;for&nbsp;L2&nbsp;regularization.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activations&nbsp;(list):&nbsp;<a href="#Activation">Activation</a>&nbsp;functions&nbsp;for&nbsp;each&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers&nbsp;(list):&nbsp;List&nbsp;of&nbsp;layer&nbsp;objects&nbsp;or&nbsp;configurations.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights&nbsp;(list):&nbsp;List&nbsp;of&nbsp;weight&nbsp;matrices&nbsp;for&nbsp;the&nbsp;layers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;biases&nbsp;(list):&nbsp;List&nbsp;of&nbsp;bias&nbsp;vectors&nbsp;for&nbsp;the&nbsp;layers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer_outputs&nbsp;(ndarray):&nbsp;Outputs&nbsp;of&nbsp;each&nbsp;layer&nbsp;during&nbsp;forward&nbsp;propagation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;is_binary&nbsp;(bool):&nbsp;Whether&nbsp;the&nbsp;network&nbsp;is&nbsp;for&nbsp;binary&nbsp;classification.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-__init__">__init__</a>(layers,&nbsp;dropout_rate=0.0,&nbsp;reg_lambda=0.0,&nbsp;activations=None,&nbsp;loss_function=None,&nbsp;regressor=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;neural&nbsp;network&nbsp;with&nbsp;the&nbsp;given&nbsp;layers&nbsp;and&nbsp;parameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-initialize_layers">initialize_layers</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abstract&nbsp;method&nbsp;to&nbsp;initialize&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;the&nbsp;layers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-forward">forward</a>(X,&nbsp;training=True):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abstract&nbsp;method&nbsp;to&nbsp;perform&nbsp;forward&nbsp;propagation&nbsp;through&nbsp;the&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-backward">backward</a>(y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abstract&nbsp;method&nbsp;to&nbsp;perform&nbsp;backward&nbsp;propagation&nbsp;through&nbsp;the&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-train">train</a>(X_train,&nbsp;y_train,&nbsp;X_val=None,&nbsp;y_val=None,&nbsp;optimizer=None,&nbsp;epochs=100,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;batch_size=32,&nbsp;early_stopping_threshold=10,&nbsp;lr_scheduler=None,&nbsp;p=True,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;use_tqdm=True,&nbsp;n_jobs=1,&nbsp;track_metrics=False,&nbsp;track_adv_metrics=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abstract&nbsp;method&nbsp;to&nbsp;train&nbsp;the&nbsp;neural&nbsp;network&nbsp;using&nbsp;the&nbsp;provided&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-evaluate">evaluate</a>(X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abstract&nbsp;method&nbsp;to&nbsp;evaluate&nbsp;the&nbsp;neural&nbsp;network&nbsp;on&nbsp;the&nbsp;provided&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-predict">predict</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abstract&nbsp;method&nbsp;to&nbsp;make&nbsp;predictions&nbsp;using&nbsp;the&nbsp;trained&nbsp;neural&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-calculate_loss">calculate_loss</a>(X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abstract&nbsp;method&nbsp;to&nbsp;calculate&nbsp;the&nbsp;loss&nbsp;of&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-apply_dropout">apply_dropout</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Applies&nbsp;dropout&nbsp;to&nbsp;the&nbsp;activation&nbsp;values&nbsp;for&nbsp;regularization.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-compute_l2_reg">compute_l2_reg</a>(weights):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes&nbsp;the&nbsp;L2&nbsp;regularization&nbsp;term&nbsp;for&nbsp;the&nbsp;given&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-calculate_precision_recall_f1">calculate_precision_recall_f1</a>(X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Calculates&nbsp;precision,&nbsp;recall,&nbsp;and&nbsp;F1&nbsp;score&nbsp;for&nbsp;the&nbsp;predictions.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-create_scheduler">create_scheduler</a>(scheduler_type,&nbsp;optimizer,&nbsp;**kwargs):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates&nbsp;a&nbsp;learning&nbsp;rate&nbsp;scheduler&nbsp;based&nbsp;on&nbsp;the&nbsp;specified&nbsp;type.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NeuralNetworkBase-plot_metrics">plot_metrics</a>(save_dir=None):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Plots&nbsp;the&nbsp;training&nbsp;and&nbsp;validation&nbsp;metrics,&nbsp;including&nbsp;loss,&nbsp;accuracy,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;learning&nbsp;rate,&nbsp;and&nbsp;optionally&nbsp;precision,&nbsp;recall,&nbsp;and&nbsp;F1&nbsp;score.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="NeuralNetworkBase-__init__"><strong>__init__</strong></a>(self, layers, dropout_rate=0.0, reg_lambda=0.0, activations=None, loss_function=None, regressor=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;neural&nbsp;network&nbsp;with&nbsp;the&nbsp;specified&nbsp;layers,&nbsp;dropout&nbsp;rate,&nbsp;regularization,&nbsp;and&nbsp;activations.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers:&nbsp;(list)&nbsp;-&nbsp;A&nbsp;list&nbsp;of&nbsp;integers&nbsp;representing&nbsp;the&nbsp;sizes&nbsp;of&nbsp;each&nbsp;layer&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;Layer&nbsp;objects.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dropout_rate:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;dropout&nbsp;rate&nbsp;for&nbsp;regularization&nbsp;(default&nbsp;is&nbsp;0.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;The&nbsp;regularization&nbsp;strength&nbsp;(default&nbsp;is&nbsp;0.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;activations:&nbsp;(list&nbsp;of&nbsp;str),&nbsp;optional&nbsp;-&nbsp;A&nbsp;list&nbsp;of&nbsp;activation&nbsp;functions&nbsp;for&nbsp;each&nbsp;layer&nbsp;(default&nbsp;is&nbsp;None,&nbsp;which&nbsp;sets&nbsp;"relu"&nbsp;for&nbsp;hidden&nbsp;layers&nbsp;and&nbsp;"softmax"&nbsp;for&nbsp;the&nbsp;output&nbsp;layer).<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss_function:&nbsp;(callable),&nbsp;optional&nbsp;-&nbsp;Custom&nbsp;loss&nbsp;function&nbsp;to&nbsp;use&nbsp;(default&nbsp;is&nbsp;None,&nbsp;which&nbsp;uses&nbsp;the&nbsp;default&nbsp;calculate_loss&nbsp;implementation).<br>
&nbsp;&nbsp;&nbsp;&nbsp;regressor:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;If&nbsp;True,&nbsp;the&nbsp;network&nbsp;is&nbsp;treated&nbsp;as&nbsp;a&nbsp;regressor&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValueError:&nbsp;If&nbsp;`layers`&nbsp;is&nbsp;not&nbsp;a&nbsp;list&nbsp;of&nbsp;integers&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;Layer&nbsp;objects.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-apply_dropout"><strong>apply_dropout</strong></a>(self, X)</dt><dd><span class="code">Applies&nbsp;dropout&nbsp;to&nbsp;the&nbsp;activation&nbsp;X.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(ndarray)&nbsp;-&nbsp;<a href="#Activation">Activation</a>&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ndarray:&nbsp;<a href="#Activation">Activation</a>&nbsp;values&nbsp;after&nbsp;applying&nbsp;dropout.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-backward"><strong>backward</strong></a>(self, y)</dt><dd><span class="code">Performs&nbsp;backward&nbsp;propagation&nbsp;through&nbsp;the&nbsp;network.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-calculate_loss"><strong>calculate_loss</strong></a>(self, X, y)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;loss&nbsp;of&nbsp;the&nbsp;neural&nbsp;network.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-calculate_precision_recall_f1"><strong>calculate_precision_recall_f1</strong></a>(self, X, y)</dt><dd><span class="code">Calculates&nbsp;precision,&nbsp;recall,&nbsp;and&nbsp;F1&nbsp;score.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(ndarray)&nbsp;-&nbsp;Input&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(ndarray)&nbsp;-&nbsp;Target&nbsp;labels<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;precision:&nbsp;(float)&nbsp;-&nbsp;Precision&nbsp;score<br>
&nbsp;&nbsp;&nbsp;&nbsp;recall:&nbsp;(float)&nbsp;-&nbsp;Recall&nbsp;score<br>
&nbsp;&nbsp;&nbsp;&nbsp;f1:&nbsp;(float)&nbsp;-&nbsp;F1&nbsp;score</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-compute_l2_reg"><strong>compute_l2_reg</strong></a>(self, weights)</dt><dd><span class="code">Computes&nbsp;the&nbsp;L2&nbsp;regularization&nbsp;term.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;weight&nbsp;matrices.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;L2&nbsp;regularization&nbsp;term.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-create_scheduler"><strong>create_scheduler</strong></a>(self, scheduler_type, optimizer, **kwargs)</dt><dd><span class="code">Creates&nbsp;a&nbsp;learning&nbsp;rate&nbsp;scheduler.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-evaluate"><strong>evaluate</strong></a>(self, X, y)</dt><dd><span class="code">Evaluates&nbsp;the&nbsp;neural&nbsp;network&nbsp;on&nbsp;the&nbsp;provided&nbsp;data.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-forward"><strong>forward</strong></a>(self, X, training=True)</dt><dd><span class="code">Performs&nbsp;forward&nbsp;propagation&nbsp;through&nbsp;the&nbsp;network.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-initialize_layers"><strong>initialize_layers</strong></a>(self)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;the&nbsp;layers.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-plot_metrics"><strong>plot_metrics</strong></a>(self, save_dir=None)</dt><dd><span class="code">Plots&nbsp;the&nbsp;training&nbsp;and&nbsp;validation&nbsp;metrics.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Makes&nbsp;predictions&nbsp;using&nbsp;the&nbsp;trained&nbsp;neural&nbsp;network.</span></dd></dl>

<dl><dt><a name="NeuralNetworkBase-train"><strong>train</strong></a>(self, X_train, y_train, X_val=None, y_val=None, optimizer=None, epochs=100, batch_size=32, early_stopping_threshold=10, lr_scheduler=None, p=True, use_tqdm=True, n_jobs=1, track_metrics=False, track_adv_metrics=False)</dt><dd><span class="code">Trains&nbsp;the&nbsp;neural&nbsp;network&nbsp;using&nbsp;the&nbsp;provided&nbsp;training&nbsp;data.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="NumbaBackendNeuralNetwork">class <strong>NumbaBackendNeuralNetwork</strong></a>(<a href="sega_learn.neural_networks.neuralNetworkBase.html#NeuralNetworkBase">sega_learn.neural_networks.neuralNetworkBase.NeuralNetworkBase</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#NumbaBackendNeuralNetwork">NumbaBackendNeuralNetwork</a>(layers,&nbsp;dropout_rate=0.2,&nbsp;reg_lambda=0.01,&nbsp;activations=None,&nbsp;loss_function=None,&nbsp;regressor=False,&nbsp;compile_numba=True,&nbsp;progress_bar=True)<br>
&nbsp;<br>
A&nbsp;neural&nbsp;network&nbsp;implementation&nbsp;using&nbsp;Numba&nbsp;for&nbsp;Just-In-Time&nbsp;(JIT)&nbsp;compilation&nbsp;to&nbsp;optimize&nbsp;performance.<br>
&nbsp;<br>
This&nbsp;class&nbsp;supports&nbsp;forward&nbsp;and&nbsp;backward&nbsp;propagation,&nbsp;training,&nbsp;evaluation,&nbsp;and&nbsp;hyperparameter&nbsp;tuning<br>
with&nbsp;various&nbsp;optimizers&nbsp;and&nbsp;activation&nbsp;functions.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;compiled&nbsp;(bool):&nbsp;Indicates&nbsp;whether&nbsp;Numba&nbsp;functions&nbsp;are&nbsp;compiled.<br>
&nbsp;&nbsp;&nbsp;&nbsp;trainable_layers&nbsp;(list):&nbsp;Layers&nbsp;with&nbsp;trainable&nbsp;parameters&nbsp;(weights&nbsp;and&nbsp;biases).<br>
&nbsp;&nbsp;&nbsp;&nbsp;progress_bar&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;display&nbsp;a&nbsp;progress&nbsp;bar&nbsp;during&nbsp;training.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-__init__">__init__</a>(layers,&nbsp;dropout_rate,&nbsp;reg_lambda,&nbsp;activations,&nbsp;compile_numba,&nbsp;progress_bar):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;neural&nbsp;network&nbsp;with&nbsp;the&nbsp;specified&nbsp;parameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-store_init_layers">store_init_layers</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stores&nbsp;the&nbsp;initial&nbsp;layers&nbsp;and&nbsp;their&nbsp;parameters&nbsp;for&nbsp;restoration&nbsp;after&nbsp;initialization.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-restore_layers">restore_layers</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Restores&nbsp;the&nbsp;layers&nbsp;and&nbsp;their&nbsp;parameters&nbsp;after&nbsp;initialization.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-initialize_new_layers">initialize_new_layers</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;layers&nbsp;of&nbsp;the&nbsp;neural&nbsp;network&nbsp;with&nbsp;specified&nbsp;sizes&nbsp;and&nbsp;activation&nbsp;functions.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-forward">forward</a>(X,&nbsp;training):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Performs&nbsp;forward&nbsp;propagation&nbsp;through&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-backward">backward</a>(y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Performs&nbsp;backward&nbsp;propagation&nbsp;to&nbsp;calculate&nbsp;gradients.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-is_not_instance_of_classes">is_not_instance_of_classes</a>(obj,&nbsp;classes):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Checks&nbsp;if&nbsp;an&nbsp;<a href="builtins.html#object">object</a>&nbsp;is&nbsp;not&nbsp;an&nbsp;instance&nbsp;of&nbsp;any&nbsp;class&nbsp;in&nbsp;a&nbsp;list&nbsp;of&nbsp;classes.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-train">train</a>(X_train,&nbsp;y_train,&nbsp;X_val,&nbsp;y_val,&nbsp;optimizer,&nbsp;epochs,&nbsp;batch_size,&nbsp;early_stopping_threshold,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lr_scheduler,&nbsp;p,&nbsp;use_tqdm,&nbsp;n_jobs,&nbsp;track_metrics,&nbsp;track_adv_metrics,&nbsp;save_animation,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;save_path,&nbsp;fps,&nbsp;dpi,&nbsp;frame_every):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Trains&nbsp;the&nbsp;neural&nbsp;network&nbsp;model&nbsp;with&nbsp;the&nbsp;specified&nbsp;parameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-evaluate">evaluate</a>(X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Evaluates&nbsp;the&nbsp;neural&nbsp;network&nbsp;on&nbsp;the&nbsp;given&nbsp;data&nbsp;and&nbsp;returns&nbsp;accuracy&nbsp;and&nbsp;predictions.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-predict">predict</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predicts&nbsp;the&nbsp;output&nbsp;for&nbsp;the&nbsp;given&nbsp;input&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-calculate_loss">calculate_loss</a>(X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Calculates&nbsp;the&nbsp;loss&nbsp;with&nbsp;L2&nbsp;regularization.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_create_optimizer(optimizer_type,&nbsp;learning_rate,&nbsp;JIT):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Helper&nbsp;method&nbsp;to&nbsp;create&nbsp;optimizer&nbsp;instances.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-tune_hyperparameters">tune_hyperparameters</a>(X_train,&nbsp;y_train,&nbsp;X_val,&nbsp;y_val,&nbsp;param_grid,&nbsp;layer_configs,&nbsp;optimizer_types,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lr_range,&nbsp;epochs,&nbsp;batch_size):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Performs&nbsp;hyperparameter&nbsp;tuning&nbsp;using&nbsp;grid&nbsp;search.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#NumbaBackendNeuralNetwork-compile_numba_functions">compile_numba_functions</a>(progress_bar):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compiles&nbsp;all&nbsp;Numba&nbsp;JIT&nbsp;functions&nbsp;to&nbsp;improve&nbsp;performance.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.neural_networks.neuralNetworkNumbaBackend.html#NumbaBackendNeuralNetwork">NumbaBackendNeuralNetwork</a></dd>
<dd><a href="sega_learn.neural_networks.neuralNetworkBase.html#NeuralNetworkBase">sega_learn.neural_networks.neuralNetworkBase.NeuralNetworkBase</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="NumbaBackendNeuralNetwork-__init__"><strong>__init__</strong></a>(self, layers, dropout_rate=0.2, reg_lambda=0.01, activations=None, loss_function=None, regressor=False, compile_numba=True, progress_bar=True)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;Numba&nbsp;backend&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;layer&nbsp;sizes&nbsp;or&nbsp;Layer&nbsp;objects.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dropout_rate:&nbsp;(float)&nbsp;-&nbsp;Dropout&nbsp;rate&nbsp;for&nbsp;regularization.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda:&nbsp;(float)&nbsp;-&nbsp;L2&nbsp;regularization&nbsp;parameter.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activations:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;activation&nbsp;functions&nbsp;for&nbsp;each&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss_function:&nbsp;(callable)&nbsp;optional&nbsp;-&nbsp;Custom&nbsp;loss&nbsp;function&nbsp;(default:&nbsp;selects&nbsp;based&nbsp;on&nbsp;task).<br>
&nbsp;&nbsp;&nbsp;&nbsp;regressor:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;the&nbsp;model&nbsp;is&nbsp;a&nbsp;regressor&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;compile_numba:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;compile&nbsp;Numba&nbsp;functions.<br>
&nbsp;&nbsp;&nbsp;&nbsp;progress_bar:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;display&nbsp;a&nbsp;progress&nbsp;bar.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-backward"><strong>backward</strong></a>(self, y)</dt><dd><span class="code">Performs&nbsp;backward&nbsp;propagation&nbsp;to&nbsp;calculate&nbsp;the&nbsp;gradients.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(ndarray):&nbsp;Target&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(m,&nbsp;output_size).</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-calculate_loss"><strong>calculate_loss</strong></a>(self, X, y)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;loss&nbsp;with&nbsp;L2&nbsp;regularization.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(ndarray):&nbsp;Input&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(ndarray):&nbsp;Target&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;calculated&nbsp;loss&nbsp;value.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-compile_numba_functions"><strong>compile_numba_functions</strong></a>(self, progress_bar=True)</dt><dd><span class="code">Compiles&nbsp;all&nbsp;Numba&nbsp;JIT&nbsp;functions&nbsp;to&nbsp;improve&nbsp;performance.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;progress_bar&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;display&nbsp;a&nbsp;progress&nbsp;bar.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-evaluate"><strong>evaluate</strong></a>(self, X, y)</dt><dd><span class="code">Evaluates&nbsp;the&nbsp;neural&nbsp;network&nbsp;on&nbsp;the&nbsp;given&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(ndarray):&nbsp;Input&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(ndarray):&nbsp;Target&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuple:&nbsp;Accuracy&nbsp;and&nbsp;predicted&nbsp;labels.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-forward"><strong>forward</strong></a>(self, X, training=True)</dt><dd><span class="code">Performs&nbsp;forward&nbsp;propagation&nbsp;through&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(ndarray):&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(batch_size,&nbsp;input_size).<br>
&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;(bool):&nbsp;Whether&nbsp;the&nbsp;network&nbsp;is&nbsp;in&nbsp;training&nbsp;mode&nbsp;(applies&nbsp;dropout).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ndarray:&nbsp;Output&nbsp;predictions&nbsp;of&nbsp;shape&nbsp;(batch_size,&nbsp;output_size).</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-initialize_new_layers"><strong>initialize_new_layers</strong></a>(self)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;layers&nbsp;of&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Each&nbsp;layer&nbsp;is&nbsp;created&nbsp;with&nbsp;the&nbsp;specified&nbsp;number&nbsp;of&nbsp;neurons&nbsp;and&nbsp;activation&nbsp;function.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;output&nbsp;for&nbsp;the&nbsp;given&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(ndarray):&nbsp;Input&nbsp;data.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ndarray:&nbsp;Predicted&nbsp;outputs.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-restore_layers"><strong>restore_layers</strong></a>(self)</dt><dd><span class="code">Restores&nbsp;the&nbsp;layers&nbsp;after&nbsp;initialization.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-store_init_layers"><strong>store_init_layers</strong></a>(self)</dt><dd><span class="code">Stores&nbsp;the&nbsp;layers&nbsp;to&nbsp;restore&nbsp;after&nbsp;initialization.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-train"><strong>train</strong></a>(self, X_train, y_train, X_val=None, y_val=None, optimizer=None, epochs=100, batch_size=32, early_stopping_threshold=10, lr_scheduler=None, p=True, use_tqdm=True, n_jobs=1, track_metrics=False, track_adv_metrics=False, save_animation=False, save_path='training_animation.mp4', fps=1, dpi=100, frame_every=1)</dt><dd><span class="code">Trains&nbsp;the&nbsp;neural&nbsp;network&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(ndarray)&nbsp;-&nbsp;Training&nbsp;data&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(ndarray)&nbsp;-&nbsp;Training&nbsp;data&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_val:&nbsp;(ndarray)&nbsp;-&nbsp;Validation&nbsp;data&nbsp;features,&nbsp;optional.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_val:&nbsp;(ndarray)&nbsp;-&nbsp;Validation&nbsp;data&nbsp;labels,&nbsp;optional.<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer:&nbsp;(Optimizer)&nbsp;-&nbsp;Optimizer&nbsp;for&nbsp;updating&nbsp;parameters&nbsp;(default:&nbsp;JITAdam,&nbsp;lr=0.0001).<br>
&nbsp;&nbsp;&nbsp;&nbsp;epochs:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;training&nbsp;epochs&nbsp;(default:&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;batch_size:&nbsp;(int)&nbsp;-&nbsp;Batch&nbsp;size&nbsp;for&nbsp;mini-batch&nbsp;gradient&nbsp;descent&nbsp;(default:&nbsp;32).<br>
&nbsp;&nbsp;&nbsp;&nbsp;early_stopping_threshold:&nbsp;(int)&nbsp;-&nbsp;Patience&nbsp;for&nbsp;early&nbsp;stopping&nbsp;(default:&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_scheduler:&nbsp;(Scheduler)&nbsp;-&nbsp;Learning&nbsp;rate&nbsp;scheduler&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;p:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;print&nbsp;training&nbsp;progress&nbsp;(default:&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;use_tqdm:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;use&nbsp;tqdm&nbsp;for&nbsp;progress&nbsp;bar&nbsp;(default:&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;jobs&nbsp;for&nbsp;parallel&nbsp;processing&nbsp;(default:&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;track_metrics:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;track&nbsp;training&nbsp;metrics&nbsp;(default:&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;track_adv_metrics:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;track&nbsp;advanced&nbsp;metrics&nbsp;(default:&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_animation:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;save&nbsp;the&nbsp;animation&nbsp;of&nbsp;metrics&nbsp;(default:&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_path:&nbsp;(str)&nbsp;-&nbsp;Path&nbsp;to&nbsp;save&nbsp;the&nbsp;animation&nbsp;file.&nbsp;File&nbsp;extension&nbsp;must&nbsp;be&nbsp;.mp4&nbsp;or&nbsp;.gif&nbsp;(default:&nbsp;'training_animation.mp4').<br>
&nbsp;&nbsp;&nbsp;&nbsp;fps:&nbsp;(int)&nbsp;-&nbsp;Frames&nbsp;per&nbsp;second&nbsp;for&nbsp;the&nbsp;saved&nbsp;animation&nbsp;(default:&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;dpi:&nbsp;(int)&nbsp;-&nbsp;DPI&nbsp;for&nbsp;the&nbsp;saved&nbsp;animation&nbsp;(default:&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;frame_every:&nbsp;(int)&nbsp;-&nbsp;Capture&nbsp;frame&nbsp;every&nbsp;N&nbsp;epochs&nbsp;(to&nbsp;reduce&nbsp;file&nbsp;size)&nbsp;(default:&nbsp;1).</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-tune_hyperparameters"><strong>tune_hyperparameters</strong></a>(self, X_train, y_train, X_val, y_val, param_grid, layer_configs=None, optimizer_types=None, lr_range=(0.0001, 0.01, 5), epochs=30, batch_size=32)</dt><dd><span class="code">Performs&nbsp;hyperparameter&nbsp;tuning&nbsp;using&nbsp;grid&nbsp;search.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_val:&nbsp;(np.ndarray)&nbsp;-&nbsp;Validation&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_val:&nbsp;(np.ndarray)&nbsp;-&nbsp;Validation&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;param_grid:&nbsp;(dict)&nbsp;-&nbsp;Dictionary&nbsp;of&nbsp;parameters&nbsp;to&nbsp;try.<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer_configs:&nbsp;(list),&nbsp;optional&nbsp;-&nbsp;List&nbsp;of&nbsp;layer&nbsp;configurations&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer_types:&nbsp;(list),&nbsp;optional&nbsp;-&nbsp;List&nbsp;of&nbsp;optimizer&nbsp;types&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_range:&nbsp;(tuple),&nbsp;optional&nbsp;-&nbsp;(min_lr,&nbsp;max_lr,&nbsp;num_steps)&nbsp;for&nbsp;learning&nbsp;rates&nbsp;(default&nbsp;is&nbsp;(0.0001,&nbsp;0.01,&nbsp;5)).<br>
&nbsp;&nbsp;&nbsp;&nbsp;epochs:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Max&nbsp;epochs&nbsp;for&nbsp;each&nbsp;trial&nbsp;(default&nbsp;is&nbsp;30).<br>
&nbsp;&nbsp;&nbsp;&nbsp;batch_size:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Batch&nbsp;size&nbsp;for&nbsp;training&nbsp;(default&nbsp;is&nbsp;32).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_params:&nbsp;(dict)&nbsp;-&nbsp;Best&nbsp;hyperparameters&nbsp;found.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_accuracy:&nbsp;(float)&nbsp;-&nbsp;Best&nbsp;validation&nbsp;accuracy.</span></dd></dl>

<hr>
Static methods defined here:<br>
<dl><dt><a name="NumbaBackendNeuralNetwork-is_not_instance_of_classes"><strong>is_not_instance_of_classes</strong></a>(obj, classes)</dt><dd><span class="code">Checks&nbsp;if&nbsp;an&nbsp;<a href="builtins.html#object">object</a>&nbsp;is&nbsp;not&nbsp;an&nbsp;instance&nbsp;of&nbsp;any&nbsp;class&nbsp;in&nbsp;a&nbsp;list&nbsp;of&nbsp;classes.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;obj:&nbsp;The&nbsp;<a href="builtins.html#object">object</a>&nbsp;to&nbsp;check.<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes:&nbsp;A&nbsp;list&nbsp;of&nbsp;classes.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;bool:&nbsp;True&nbsp;if&nbsp;the&nbsp;<a href="builtins.html#object">object</a>&nbsp;is&nbsp;not&nbsp;an&nbsp;instance&nbsp;of&nbsp;any&nbsp;class&nbsp;in&nbsp;the&nbsp;list&nbsp;of&nbsp;classes,&nbsp;False&nbsp;otherwise.</span></dd></dl>

<hr>
Methods inherited from <a href="sega_learn.neural_networks.neuralNetworkBase.html#NeuralNetworkBase">sega_learn.neural_networks.neuralNetworkBase.NeuralNetworkBase</a>:<br>
<dl><dt><a name="NumbaBackendNeuralNetwork-apply_dropout"><strong>apply_dropout</strong></a>(self, X)</dt><dd><span class="code">Applies&nbsp;dropout&nbsp;to&nbsp;the&nbsp;activation&nbsp;X.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(ndarray)&nbsp;-&nbsp;<a href="#Activation">Activation</a>&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ndarray:&nbsp;<a href="#Activation">Activation</a>&nbsp;values&nbsp;after&nbsp;applying&nbsp;dropout.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-calculate_precision_recall_f1"><strong>calculate_precision_recall_f1</strong></a>(self, X, y)</dt><dd><span class="code">Calculates&nbsp;precision,&nbsp;recall,&nbsp;and&nbsp;F1&nbsp;score.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(ndarray)&nbsp;-&nbsp;Input&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(ndarray)&nbsp;-&nbsp;Target&nbsp;labels<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;precision:&nbsp;(float)&nbsp;-&nbsp;Precision&nbsp;score<br>
&nbsp;&nbsp;&nbsp;&nbsp;recall:&nbsp;(float)&nbsp;-&nbsp;Recall&nbsp;score<br>
&nbsp;&nbsp;&nbsp;&nbsp;f1:&nbsp;(float)&nbsp;-&nbsp;F1&nbsp;score</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-compute_l2_reg"><strong>compute_l2_reg</strong></a>(self, weights)</dt><dd><span class="code">Computes&nbsp;the&nbsp;L2&nbsp;regularization&nbsp;term.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights:&nbsp;(list)&nbsp;-&nbsp;List&nbsp;of&nbsp;weight&nbsp;matrices.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;L2&nbsp;regularization&nbsp;term.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-create_scheduler"><strong>create_scheduler</strong></a>(self, scheduler_type, optimizer, **kwargs)</dt><dd><span class="code">Creates&nbsp;a&nbsp;learning&nbsp;rate&nbsp;scheduler.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-initialize_layers"><strong>initialize_layers</strong></a>(self)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;the&nbsp;layers.</span></dd></dl>

<dl><dt><a name="NumbaBackendNeuralNetwork-plot_metrics"><strong>plot_metrics</strong></a>(self, save_dir=None)</dt><dd><span class="code">Plots&nbsp;the&nbsp;training&nbsp;and&nbsp;validation&nbsp;metrics.</span></dd></dl>

<hr>
Data descriptors inherited from <a href="sega_learn.neural_networks.neuralNetworkBase.html#NeuralNetworkBase">sega_learn.neural_networks.neuralNetworkBase.NeuralNetworkBase</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="OneClassSVM">class <strong>OneClassSVM</strong></a>(<a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#OneClassSVM">OneClassSVM</a>(C=1.0,&nbsp;tol=0.0001,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;kernel='linear',&nbsp;degree=3,&nbsp;gamma='scale',&nbsp;coef0=0.0)<br>
&nbsp;<br>
<a href="#OneClassSVM">OneClassSVM</a>&nbsp;is&nbsp;a&nbsp;custom&nbsp;implementation&nbsp;of&nbsp;a&nbsp;One-Class&nbsp;Support&nbsp;Vector&nbsp;Machine&nbsp;(SVM)&nbsp;for&nbsp;anomaly&nbsp;detection&nbsp;using&nbsp;gradient&nbsp;descent.<br>
&nbsp;<br>
It&nbsp;inherits&nbsp;from&nbsp;the&nbsp;<a href="#BaseSVM">BaseSVM</a>&nbsp;class&nbsp;and&nbsp;supports&nbsp;various&nbsp;kernel&nbsp;functions.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;support_vectors_&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_support_vectors,&nbsp;n_features)):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;support&nbsp;vectors&nbsp;identified&nbsp;during&nbsp;training.<br>
&nbsp;&nbsp;&nbsp;&nbsp;support_vector_alphas_&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_support_vectors,)):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;Lagrange&nbsp;multipliers&nbsp;(alpha)&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;support&nbsp;vectors.<br>
&nbsp;&nbsp;&nbsp;&nbsp;b&nbsp;(float):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;bias&nbsp;term&nbsp;(rho)&nbsp;computed&nbsp;during&nbsp;training.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#OneClassSVM-__init__">__init__</a>(C=1.0,&nbsp;tol=1e-4,&nbsp;max_iter=1000,&nbsp;learning_rate=0.01,&nbsp;kernel="linear",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;degree=3,&nbsp;gamma="scale",&nbsp;coef0=0.0):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initialize&nbsp;the&nbsp;<a href="#OneClassSVM">OneClassSVM</a>&nbsp;with&nbsp;hyperparameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_fit(X,&nbsp;y=None):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fit&nbsp;the&nbsp;<a href="#OneClassSVM">OneClassSVM</a>&nbsp;model&nbsp;using&nbsp;gradient&nbsp;descent&nbsp;for&nbsp;anomaly&nbsp;detection.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#OneClassSVM-decision_function">decision_function</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute&nbsp;the&nbsp;decision&nbsp;function&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#OneClassSVM-predict">predict</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predict&nbsp;whether&nbsp;the&nbsp;input&nbsp;samples&nbsp;are&nbsp;inliers&nbsp;(1)&nbsp;or&nbsp;outliers&nbsp;(-1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#OneClassSVM-score">score</a>(X,&nbsp;y):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute&nbsp;the&nbsp;mean&nbsp;accuracy&nbsp;of&nbsp;predictions&nbsp;compared&nbsp;to&nbsp;true&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#OneClassSVM-__sklearn_is_fitted__">__sklearn_is_fitted__</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Check&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted.&nbsp;For&nbsp;compatibility&nbsp;with&nbsp;sklearn.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt>Method resolution order:</dt>
<dd><a href="sega_learn.svm.oneClassSVM.html#OneClassSVM">OneClassSVM</a></dd>
<dd><a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="OneClassSVM-__init__"><strong>__init__</strong></a>(self, C=1.0, tol=0.0001, max_iter=1000, learning_rate=0.01, kernel='linear', degree=3, gamma='scale', coef0=0.0)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#OneClassSVM">OneClassSVM</a>&nbsp;with&nbsp;hyperparameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C:&nbsp;(float)&nbsp;-&nbsp;Regularization&nbsp;parameter&nbsp;(default&nbsp;is&nbsp;1.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float)&nbsp;-&nbsp;Tolerance&nbsp;for&nbsp;stopping&nbsp;criteria&nbsp;(default&nbsp;is&nbsp;1e-4).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;(default&nbsp;is&nbsp;1000).<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float)&nbsp;-&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;gradient&nbsp;descent&nbsp;(default&nbsp;is&nbsp;0.01).<br>
&nbsp;&nbsp;&nbsp;&nbsp;kernel:&nbsp;(str)&nbsp;-&nbsp;Kernel&nbsp;type&nbsp;("linear",&nbsp;"poly",&nbsp;"rbf",&nbsp;"sigmoid")&nbsp;(default&nbsp;is&nbsp;"linear").<br>
&nbsp;&nbsp;&nbsp;&nbsp;degree:&nbsp;(int)&nbsp;-&nbsp;Degree&nbsp;for&nbsp;polynomial&nbsp;kernel&nbsp;(default&nbsp;is&nbsp;3).<br>
&nbsp;&nbsp;&nbsp;&nbsp;gamma:&nbsp;(str&nbsp;or&nbsp;float)&nbsp;-&nbsp;Kernel&nbsp;coefficient&nbsp;("scale",&nbsp;"auto",&nbsp;or&nbsp;float)&nbsp;(default&nbsp;is&nbsp;"scale").<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef0:&nbsp;(float)&nbsp;-&nbsp;Independent&nbsp;term&nbsp;in&nbsp;kernel&nbsp;function&nbsp;(default&nbsp;is&nbsp;0.0).</span></dd></dl>

<dl><dt><a name="OneClassSVM-__sklearn_is_fitted__"><strong>__sklearn_is_fitted__</strong></a>(self)</dt><dd><span class="code">Check&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted.&nbsp;For&nbsp;compatibility&nbsp;with&nbsp;sklearn.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fitted:&nbsp;(bool)&nbsp;-&nbsp;True&nbsp;if&nbsp;the&nbsp;model&nbsp;has&nbsp;been&nbsp;fitted,&nbsp;otherwise&nbsp;False.</span></dd></dl>

<dl><dt><a name="OneClassSVM-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Compute&nbsp;the&nbsp;decision&nbsp;function&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;samples.</span></dd></dl>

<dl><dt><a name="OneClassSVM-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;whether&nbsp;the&nbsp;input&nbsp;samples&nbsp;are&nbsp;inliers&nbsp;(1)&nbsp;or&nbsp;outliers&nbsp;(-1).</span></dd></dl>

<dl><dt><a name="OneClassSVM-score"><strong>score</strong></a>(self, X, y)</dt><dd><span class="code">Compute&nbsp;the&nbsp;mean&nbsp;accuracy&nbsp;of&nbsp;predictions.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Test&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;True&nbsp;labels&nbsp;(+1&nbsp;for&nbsp;inliers,&nbsp;-1&nbsp;for&nbsp;outliers).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;score:&nbsp;(float)&nbsp;-&nbsp;Mean&nbsp;accuracy&nbsp;of&nbsp;predictions.</span></dd></dl>

<hr>
Methods inherited from <a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>:<br>
<dl><dt><a name="OneClassSVM-fit"><strong>fit</strong></a>(self, X, y=None)</dt><dd><span class="code">Fits&nbsp;the&nbsp;SVM&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features))&nbsp;-&nbsp;Training&nbsp;vectors.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,))&nbsp;-&nbsp;Target&nbsp;values.&nbsp;Default&nbsp;is&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;fitted&nbsp;instance.</span></dd></dl>

<dl><dt><a name="OneClassSVM-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><span class="code">Retrieves&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;deep:&nbsp;(bool)&nbsp;-&nbsp;If&nbsp;True,&nbsp;returns&nbsp;parameters&nbsp;of&nbsp;subobjects&nbsp;as&nbsp;well.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;params:&nbsp;(dict)&nbsp;-&nbsp;Dictionary&nbsp;of&nbsp;hyperparameter&nbsp;names&nbsp;and&nbsp;values.</span></dd></dl>

<dl><dt><a name="OneClassSVM-set_params"><strong>set_params</strong></a>(self, **parameters)</dt><dd><span class="code">Sets&nbsp;the&nbsp;hyperparameters&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;**parameters:&nbsp;(dict)&nbsp;-&nbsp;Hyperparameter&nbsp;names&nbsp;and&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#BaseSVM">BaseSVM</a>)&nbsp;-&nbsp;The&nbsp;updated&nbsp;estimator&nbsp;instance.</span></dd></dl>

<hr>
Data descriptors inherited from <a href="sega_learn.svm.baseSVM.html#BaseSVM">sega_learn.svm.baseSVM.BaseSVM</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="OrdinaryLeastSquares">class <strong>OrdinaryLeastSquares</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#OrdinaryLeastSquares">OrdinaryLeastSquares</a>(fit_intercept=True)&nbsp;-&amp;gt;&nbsp;None<br>
&nbsp;<br>
Ordinary&nbsp;Least&nbsp;Squares&nbsp;(OLS)&nbsp;linear&nbsp;regression&nbsp;model.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef_&nbsp;:&nbsp;ndarray&nbsp;of&nbsp;shape&nbsp;(n_features,)&nbsp;or&nbsp;(n_features&nbsp;+&nbsp;1,)&nbsp;-&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;linear&nbsp;regression&nbsp;problem.&nbsp;If&nbsp;`fit_intercept`&nbsp;is&nbsp;True,&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;the&nbsp;intercept.<br>
&nbsp;&nbsp;&nbsp;&nbsp;intercept_&nbsp;:&nbsp;float&nbsp;-&nbsp;Independent&nbsp;term&nbsp;in&nbsp;the&nbsp;linear&nbsp;model.&nbsp;Set&nbsp;to&nbsp;0.0&nbsp;if&nbsp;`fit_intercept`&nbsp;is&nbsp;False.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#OrdinaryLeastSquares-fit">fit</a>(X,&nbsp;y):&nbsp;Fit&nbsp;the&nbsp;linear&nbsp;model&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#OrdinaryLeastSquares-predict">predict</a>(X):&nbsp;Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#OrdinaryLeastSquares-get_formula">get_formula</a>():&nbsp;Returns&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model&nbsp;as&nbsp;a&nbsp;string.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="OrdinaryLeastSquares-__init__"><strong>__init__</strong></a>(self, fit_intercept=True) -&gt; None</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#OrdinaryLeastSquares">OrdinaryLeastSquares</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fit_intercept:&nbsp;(bool)&nbsp;-&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model&nbsp;(default&nbsp;is&nbsp;True).</span></dd></dl>

<dl><dt><a name="OrdinaryLeastSquares-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;the&nbsp;string&nbsp;representation&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="OrdinaryLeastSquares-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fits&nbsp;the&nbsp;linear&nbsp;regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#OrdinaryLeastSquares">OrdinaryLeastSquares</a>)&nbsp;-&nbsp;The&nbsp;fitted&nbsp;linear&nbsp;regression&nbsp;model.</span></dd></dl>

<dl><dt><a name="OrdinaryLeastSquares-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model&nbsp;as&nbsp;a&nbsp;string.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;formula:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="OrdinaryLeastSquares-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;using&nbsp;the&nbsp;linear&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;Predicted&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="PCA">class <strong>PCA</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#PCA">PCA</a>(n_components)<br>
&nbsp;<br>
Principal&nbsp;Component&nbsp;Analysis&nbsp;(<a href="#PCA">PCA</a>)&nbsp;implementation.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="PCA-__init__"><strong>__init__</strong></a>(self, n_components)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#PCA">PCA</a>&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_components:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;principal&nbsp;components&nbsp;to&nbsp;keep.</span></dd></dl>

<dl><dt><a name="PCA-fit"><strong>fit</strong></a>(self, X)</dt><dd><span class="code">Fits&nbsp;the&nbsp;<a href="#PCA">PCA</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValueError:&nbsp;If&nbsp;input&nbsp;data&nbsp;is&nbsp;not&nbsp;a&nbsp;2D&nbsp;numpy&nbsp;array&nbsp;or&nbsp;if&nbsp;n_components&nbsp;exceeds&nbsp;the&nbsp;number&nbsp;of&nbsp;features.</span></dd></dl>

<dl><dt><a name="PCA-fit_transform"><strong>fit_transform</strong></a>(self, X)</dt><dd><span class="code">Fits&nbsp;the&nbsp;<a href="#PCA">PCA</a>&nbsp;model&nbsp;and&nbsp;applies&nbsp;dimensionality&nbsp;reduction&nbsp;on&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_transformed:&nbsp;(np.ndarray)&nbsp;-&nbsp;Data&nbsp;transformed&nbsp;into&nbsp;the&nbsp;principal&nbsp;component&nbsp;space&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_components).</span></dd></dl>

<dl><dt><a name="PCA-get_components"><strong>get_components</strong></a>(self)</dt><dd><span class="code">Retrieves&nbsp;the&nbsp;principal&nbsp;components.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;components_:&nbsp;(np.ndarray)&nbsp;-&nbsp;Array&nbsp;of&nbsp;principal&nbsp;components&nbsp;of&nbsp;shape&nbsp;(n_features,&nbsp;n_components).</span></dd></dl>

<dl><dt><a name="PCA-get_explained_variance_ratio"><strong>get_explained_variance_ratio</strong></a>(self)</dt><dd><span class="code">Retrieves&nbsp;the&nbsp;explained&nbsp;variance&nbsp;ratio.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;explained_variance_ratio_:&nbsp;(np.ndarray)&nbsp;-&nbsp;Array&nbsp;of&nbsp;explained&nbsp;variance&nbsp;ratios&nbsp;for&nbsp;each&nbsp;principal&nbsp;component.</span></dd></dl>

<dl><dt><a name="PCA-inverse_transform"><strong>inverse_transform</strong></a>(self, X_reduced)</dt><dd><span class="code">Reconstructs&nbsp;the&nbsp;original&nbsp;data&nbsp;from&nbsp;the&nbsp;reduced&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_reduced:&nbsp;(np.ndarray)&nbsp;-&nbsp;Reduced&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_components).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_original:&nbsp;(np.ndarray)&nbsp;-&nbsp;Reconstructed&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValueError:&nbsp;If&nbsp;input&nbsp;data&nbsp;is&nbsp;not&nbsp;a&nbsp;2D&nbsp;numpy&nbsp;array.</span></dd></dl>

<dl><dt><a name="PCA-transform"><strong>transform</strong></a>(self, X)</dt><dd><span class="code">Applies&nbsp;dimensionality&nbsp;reduction&nbsp;on&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_transformed:&nbsp;(np.ndarray)&nbsp;-&nbsp;Data&nbsp;transformed&nbsp;into&nbsp;the&nbsp;principal&nbsp;component&nbsp;space&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_components).<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValueError:&nbsp;If&nbsp;input&nbsp;data&nbsp;is&nbsp;not&nbsp;a&nbsp;2D&nbsp;numpy&nbsp;array&nbsp;or&nbsp;if&nbsp;its&nbsp;dimensions&nbsp;do&nbsp;not&nbsp;match&nbsp;the&nbsp;fitted&nbsp;data.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="PassiveAggressiveRegressor">class <strong>PassiveAggressiveRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#PassiveAggressiveRegressor">PassiveAggressiveRegressor</a>(C=1.0,&nbsp;max_iter=1000,&nbsp;tol=0.001)<br>
&nbsp;<br>
Fits&nbsp;the&nbsp;Passive&nbsp;Aggressive&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_steps:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;save&nbsp;the&nbsp;weights&nbsp;and&nbsp;intercept&nbsp;at&nbsp;each&nbsp;iteration&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;If&nbsp;True,&nbsp;prints&nbsp;progress&nbsp;during&nbsp;training&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef_:&nbsp;(np.ndarray)&nbsp;-&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;regression&nbsp;problem.<br>
&nbsp;&nbsp;&nbsp;&nbsp;intercept_:&nbsp;(float)&nbsp;-&nbsp;Independent&nbsp;term&nbsp;in&nbsp;the&nbsp;linear&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;steps_:&nbsp;(list&nbsp;of&nbsp;tuples),&nbsp;optional&nbsp;-&nbsp;The&nbsp;weights&nbsp;and&nbsp;intercept&nbsp;at&nbsp;each&nbsp;iteration&nbsp;if&nbsp;`save_steps`&nbsp;is&nbsp;True.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="PassiveAggressiveRegressor-__init__"><strong>__init__</strong></a>(self, C=1.0, max_iter=1000, tol=0.001)</dt><dd><span class="code">Fits&nbsp;the&nbsp;Passive&nbsp;Aggressive&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;C:&nbsp;(float)&nbsp;-&nbsp;Regularization&nbsp;parameter/step&nbsp;size&nbsp;(default&nbsp;is&nbsp;1.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;passes&nbsp;over&nbsp;the&nbsp;training&nbsp;data&nbsp;(default&nbsp;is&nbsp;1000).<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;stopping&nbsp;criterion&nbsp;(default&nbsp;is&nbsp;1e-3).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef_:&nbsp;(np.ndarray)&nbsp;-&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;regression&nbsp;problem.<br>
&nbsp;&nbsp;&nbsp;&nbsp;intercept_:&nbsp;(float)&nbsp;-&nbsp;Independent&nbsp;term&nbsp;in&nbsp;the&nbsp;linear&nbsp;model.</span></dd></dl>

<dl><dt><a name="PassiveAggressiveRegressor-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;the&nbsp;string&nbsp;representation&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="PassiveAggressiveRegressor-fit"><strong>fit</strong></a>(self, X, y, save_steps=False, verbose=False)</dt><dd><span class="code">Fits&nbsp;the&nbsp;Passive&nbsp;Aggressive&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_steps:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;save&nbsp;the&nbsp;weights&nbsp;and&nbsp;intercept&nbsp;at&nbsp;each&nbsp;iteration&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;If&nbsp;True,&nbsp;prints&nbsp;progress&nbsp;during&nbsp;training&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="PassiveAggressiveRegressor-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Computes&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;formula&nbsp;:&nbsp;str:&nbsp;The&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="PassiveAggressiveRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model.&nbsp;Dot&nbsp;product&nbsp;of&nbsp;X&nbsp;and&nbsp;the&nbsp;coefficients.</span></dd></dl>

<dl><dt><a name="PassiveAggressiveRegressor-predict_all_steps"><strong>predict_all_steps</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model&nbsp;at&nbsp;each&nbsp;iteration.&nbsp;(save_steps=True).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Perceptron">class <strong>Perceptron</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#Perceptron">Perceptron</a>(max_iter=1000,&nbsp;learning_rate=0.01)<br>
&nbsp;<br>
Implements&nbsp;the&nbsp;<a href="#Perceptron">Perceptron</a>&nbsp;algorithm&nbsp;for&nbsp;binary&nbsp;and&nbsp;multiclass&nbsp;classification.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int)&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;(default&nbsp;is&nbsp;1000).<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:&nbsp;(float)&nbsp;-&nbsp;Learning&nbsp;rate&nbsp;for&nbsp;weight&nbsp;updates&nbsp;(default&nbsp;is&nbsp;0.01).<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="Perceptron-__init__"><strong>__init__</strong></a>(self, max_iter=1000, learning_rate=0.01)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;classifier&nbsp;with&nbsp;the&nbsp;specified&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;and&nbsp;learning&nbsp;rate.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;the&nbsp;training&nbsp;process.&nbsp;Defaults&nbsp;to&nbsp;1000.<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimization&nbsp;algorithm.&nbsp;Defaults&nbsp;to&nbsp;0.01.</span></dd></dl>

<dl><dt><a name="Perceptron-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fits&nbsp;the&nbsp;<a href="#Perceptron">Perceptron</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<dl><dt><a name="Perceptron-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Test&nbsp;feature&nbsp;data.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;predictions:&nbsp;(np.ndarray)&nbsp;-&nbsp;Predicted&nbsp;class&nbsp;labels.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="PolynomialTransform">class <strong>PolynomialTransform</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#PolynomialTransform">PolynomialTransform</a>(degree=2)<br>
&nbsp;<br>
Implements&nbsp;Polynomial&nbsp;Feature&nbsp;Transformation.<br>
&nbsp;<br>
Polynomial&nbsp;feature&nbsp;transformation&nbsp;creates&nbsp;new&nbsp;features&nbsp;by&nbsp;raising&nbsp;existing&nbsp;features&nbsp;to&nbsp;a&nbsp;power&nbsp;or&nbsp;creating&nbsp;interaction&nbsp;terms.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;degree&nbsp;(int):&nbsp;The&nbsp;degree&nbsp;of&nbsp;the&nbsp;polynomial&nbsp;features&nbsp;(default&nbsp;is&nbsp;2).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_samples&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_features&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;features&nbsp;in&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_output_features&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;output&nbsp;features&nbsp;after&nbsp;transformation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;combinations&nbsp;(list&nbsp;of&nbsp;tuples):&nbsp;The&nbsp;combinations&nbsp;of&nbsp;features&nbsp;for&nbsp;polynomial&nbsp;terms.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="PolynomialTransform-__init__"><strong>__init__</strong></a>(self, degree=2)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#PolynomialTransform">PolynomialTransform</a>&nbsp;<a href="builtins.html#object">object</a>.</span></dd></dl>

<dl><dt><a name="PolynomialTransform-fit"><strong>fit</strong></a>(self, X)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Uses&nbsp;itertools.combinations_with_replacement&nbsp;to&nbsp;generate&nbsp;all&nbsp;possible&nbsp;combinations&nbsp;of&nbsp;features(X)&nbsp;of&nbsp;degree&nbsp;n.</span></dd></dl>

<dl><dt><a name="PolynomialTransform-fit_transform"><strong>fit_transform</strong></a>(self, X)</dt><dd><span class="code">Fit&nbsp;to&nbsp;data,&nbsp;then&nbsp;transform&nbsp;it.</span></dd></dl>

<dl><dt><a name="PolynomialTransform-transform"><strong>transform</strong></a>(self, X)</dt><dd><span class="code">Transform&nbsp;the&nbsp;data&nbsp;into&nbsp;polynomial&nbsp;features&nbsp;by&nbsp;computing&nbsp;the&nbsp;product&nbsp;of&nbsp;the&nbsp;features&nbsp;for&nbsp;each&nbsp;combination&nbsp;of&nbsp;features.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="QuadraticDiscriminantAnalysis">class <strong>QuadraticDiscriminantAnalysis</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#QuadraticDiscriminantAnalysis">QuadraticDiscriminantAnalysis</a>(priors=None,&nbsp;reg_param=0.0)<br>
&nbsp;<br>
Implements&nbsp;Quadratic&nbsp;Discriminant&nbsp;Analysis.<br>
&nbsp;<br>
The&nbsp;quadratic&nbsp;term&nbsp;allows&nbsp;for&nbsp;more&nbsp;flexibility&nbsp;in&nbsp;modeling&nbsp;the&nbsp;class&nbsp;conditional<br>
A&nbsp;classifier&nbsp;with&nbsp;a&nbsp;quadratic&nbsp;decision&nbsp;boundary,&nbsp;generated&nbsp;by&nbsp;fitting&nbsp;class&nbsp;conditional&nbsp;densities&nbsp;to&nbsp;the&nbsp;data&nbsp;and&nbsp;using&nbsp;Bayes'&nbsp;rule.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;priors:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Prior&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;classes&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_param:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Regularization&nbsp;parameter&nbsp;(default&nbsp;is&nbsp;0.0).<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="QuadraticDiscriminantAnalysis-__init__"><strong>__init__</strong></a>(self, priors=None, reg_param=0.0)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;Quadratic&nbsp;Discriminant&nbsp;Analysis&nbsp;model&nbsp;with&nbsp;the&nbsp;specified&nbsp;prior&nbsp;probabilities&nbsp;and&nbsp;regularization&nbsp;parameter.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;priors:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Prior&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;classes&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_param:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Regularization&nbsp;parameter&nbsp;(default&nbsp;is&nbsp;0.0).</span></dd></dl>

<dl><dt><a name="QuadraticDiscriminantAnalysis-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Apply&nbsp;decision&nbsp;function&nbsp;to&nbsp;an&nbsp;array&nbsp;of&nbsp;samples.<br>
&nbsp;<br>
The&nbsp;decision&nbsp;function&nbsp;is&nbsp;the&nbsp;log-likelihood&nbsp;of&nbsp;each&nbsp;class.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Test&nbsp;feature&nbsp;data.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;scores:&nbsp;(np.ndarray)&nbsp;-&nbsp;Log-likelihood&nbsp;of&nbsp;each&nbsp;class&nbsp;for&nbsp;the&nbsp;input&nbsp;samples.</span></dd></dl>

<dl><dt><a name="QuadraticDiscriminantAnalysis-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;according&nbsp;to&nbsp;the&nbsp;given&nbsp;training&nbsp;data.&nbsp;Uses&nbsp;the&nbsp;means&nbsp;and&nbsp;covariance&nbsp;matrices&nbsp;of&nbsp;each&nbsp;class.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data.</span></dd></dl>

<dl><dt><a name="QuadraticDiscriminantAnalysis-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Perform&nbsp;classification&nbsp;on&nbsp;an&nbsp;array&nbsp;of&nbsp;test&nbsp;vectors&nbsp;X.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Test&nbsp;feature&nbsp;data.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;predictions:&nbsp;(np.ndarray)&nbsp;-&nbsp;Predicted&nbsp;class&nbsp;labels.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RANSAC">class <strong>RANSAC</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RANSAC">RANSAC</a>(n=10,&nbsp;k=100,&nbsp;t=0.05,&nbsp;d=10,&nbsp;model=None,&nbsp;auto_scale_t=False,&nbsp;scale_t_factor=2,&nbsp;auto_scale_n=False,&nbsp;scale_n_factor=2)<br>
&nbsp;<br>
Fits&nbsp;the&nbsp;<a href="#RANSAC">RANSAC</a>&nbsp;(RANdom&nbsp;SAmple&nbsp;Consensus)&nbsp;algorithm&nbsp;for&nbsp;robust&nbsp;linear&nbsp;regression.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;feature&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;target&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Number&nbsp;of&nbsp;data&nbsp;points&nbsp;to&nbsp;estimate&nbsp;parameters&nbsp;(default&nbsp;is&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;k:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Maximum&nbsp;iterations&nbsp;allowed&nbsp;(default&nbsp;is&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;t:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Threshold&nbsp;value&nbsp;to&nbsp;determine&nbsp;if&nbsp;points&nbsp;are&nbsp;fit&nbsp;well,&nbsp;in&nbsp;terms&nbsp;of&nbsp;residuals&nbsp;(default&nbsp;is&nbsp;0.05).<br>
&nbsp;&nbsp;&nbsp;&nbsp;d:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Number&nbsp;of&nbsp;close&nbsp;data&nbsp;points&nbsp;required&nbsp;to&nbsp;assert&nbsp;model&nbsp;fits&nbsp;well&nbsp;(default&nbsp;is&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;(<a href="builtins.html#object">object</a>),&nbsp;optional&nbsp;-&nbsp;The&nbsp;model&nbsp;to&nbsp;use&nbsp;for&nbsp;fitting.&nbsp;If&nbsp;None,&nbsp;uses&nbsp;Ordinary&nbsp;Least&nbsp;Squares&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;auto_scale_t:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;automatically&nbsp;scale&nbsp;the&nbsp;threshold&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;scale_t_factor:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Factor&nbsp;by&nbsp;which&nbsp;to&nbsp;scale&nbsp;the&nbsp;threshold&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit&nbsp;(default&nbsp;is&nbsp;2).<br>
&nbsp;&nbsp;&nbsp;&nbsp;auto_scale_n:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;automatically&nbsp;scale&nbsp;the&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;scale_n_factor:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Factor&nbsp;by&nbsp;which&nbsp;to&nbsp;scale&nbsp;the&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit&nbsp;(default&nbsp;is&nbsp;2).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_fit:&nbsp;(<a href="builtins.html#object">object</a>)&nbsp;-&nbsp;The&nbsp;best&nbsp;model&nbsp;fit.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_error:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;best&nbsp;error&nbsp;achieved&nbsp;by&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_n:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;best&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;used&nbsp;to&nbsp;fit&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_t:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;best&nbsp;threshold&nbsp;value&nbsp;used&nbsp;to&nbsp;determine&nbsp;if&nbsp;points&nbsp;are&nbsp;fit&nbsp;well,&nbsp;in&nbsp;terms&nbsp;of&nbsp;residuals.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_model:&nbsp;(<a href="builtins.html#object">object</a>)&nbsp;-&nbsp;The&nbsp;best&nbsp;model&nbsp;fit.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RANSAC-__init__"><strong>__init__</strong></a>(self, n=10, k=100, t=0.05, d=10, model=None, auto_scale_t=False, scale_t_factor=2, auto_scale_n=False, scale_n_factor=2)</dt><dd><span class="code">Fits&nbsp;the&nbsp;<a href="#RANSAC">RANSAC</a>&nbsp;(RANdom&nbsp;SAmple&nbsp;Consensus)&nbsp;algorithm&nbsp;for&nbsp;robust&nbsp;linear&nbsp;regression.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_train:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;feature&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_test:&nbsp;(np.ndarray),&nbsp;optional&nbsp;-&nbsp;Testing&nbsp;target&nbsp;data&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Number&nbsp;of&nbsp;data&nbsp;points&nbsp;to&nbsp;estimate&nbsp;parameters&nbsp;(default&nbsp;is&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;k:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Maximum&nbsp;iterations&nbsp;allowed&nbsp;(default&nbsp;is&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;t:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Threshold&nbsp;value&nbsp;to&nbsp;determine&nbsp;if&nbsp;points&nbsp;are&nbsp;fit&nbsp;well,&nbsp;in&nbsp;terms&nbsp;of&nbsp;residuals&nbsp;(default&nbsp;is&nbsp;0.05).<br>
&nbsp;&nbsp;&nbsp;&nbsp;d:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Number&nbsp;of&nbsp;close&nbsp;data&nbsp;points&nbsp;required&nbsp;to&nbsp;assert&nbsp;model&nbsp;fits&nbsp;well&nbsp;(default&nbsp;is&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;(<a href="builtins.html#object">object</a>),&nbsp;optional&nbsp;-&nbsp;The&nbsp;model&nbsp;to&nbsp;use&nbsp;for&nbsp;fitting.&nbsp;If&nbsp;None,&nbsp;uses&nbsp;Ordinary&nbsp;Least&nbsp;Squares&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;auto_scale_t:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;automatically&nbsp;scale&nbsp;the&nbsp;threshold&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;scale_t_factor:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Factor&nbsp;by&nbsp;which&nbsp;to&nbsp;scale&nbsp;the&nbsp;threshold&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit&nbsp;(default&nbsp;is&nbsp;2).<br>
&nbsp;&nbsp;&nbsp;&nbsp;auto_scale_n:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;automatically&nbsp;scale&nbsp;the&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;scale_n_factor:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Factor&nbsp;by&nbsp;which&nbsp;to&nbsp;scale&nbsp;the&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit&nbsp;(default&nbsp;is&nbsp;2).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_fit:&nbsp;(<a href="builtins.html#object">object</a>)&nbsp;-&nbsp;The&nbsp;best&nbsp;model&nbsp;fit.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_error:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;best&nbsp;error&nbsp;achieved&nbsp;by&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_n:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;best&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;used&nbsp;to&nbsp;fit&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_t:&nbsp;(float)&nbsp;-&nbsp;The&nbsp;best&nbsp;threshold&nbsp;value&nbsp;used&nbsp;to&nbsp;determine&nbsp;if&nbsp;points&nbsp;are&nbsp;fit&nbsp;well,&nbsp;in&nbsp;terms&nbsp;of&nbsp;residuals.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_model:&nbsp;(<a href="builtins.html#object">object</a>)&nbsp;-&nbsp;The&nbsp;best&nbsp;model&nbsp;fit.</span></dd></dl>

<dl><dt><a name="RANSAC-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;the&nbsp;string&nbsp;representation&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="RANSAC-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fits&nbsp;the&nbsp;<a href="#RANSAC">RANSAC</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="RANSAC-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Computes&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model&nbsp;if&nbsp;fit,&nbsp;else&nbsp;returns&nbsp;"No&nbsp;model&nbsp;fit&nbsp;available".</span></dd></dl>

<dl><dt><a name="RANSAC-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;using&nbsp;the&nbsp;best&nbsp;fit&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;Predicted&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RNNLayer">class <strong>RNNLayer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RNNLayer">RNNLayer</a>(input_size,&nbsp;hidden_size,&nbsp;activation='tanh')<br>
&nbsp;<br>
Will&nbsp;be&nbsp;implemented&nbsp;later.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RNNLayer-__init__"><strong>__init__</strong></a>(self, input_size, hidden_size, activation='tanh')</dt><dd><span class="code">Will&nbsp;be&nbsp;implemented&nbsp;later.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RandomForestClassifier">class <strong>RandomForestClassifier</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RandomForestClassifier">RandomForestClassifier</a>(forest_size=100,&nbsp;max_depth=10,&nbsp;min_samples_split=2,&nbsp;n_jobs=-1,&nbsp;random_seed=None,&nbsp;X=None,&nbsp;y=None)<br>
&nbsp;<br>
<a href="#RandomForestClassifier">RandomForestClassifier</a>&nbsp;is&nbsp;a&nbsp;custom&nbsp;implementation&nbsp;of&nbsp;a&nbsp;Random&nbsp;Forest&nbsp;classifier.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;trees&nbsp;in&nbsp;the&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;jobs&nbsp;to&nbsp;run&nbsp;in&nbsp;parallel.&nbsp;Defaults&nbsp;to&nbsp;-1&nbsp;(use&nbsp;all&nbsp;available&nbsp;processors).<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int&nbsp;or&nbsp;None):&nbsp;The&nbsp;seed&nbsp;for&nbsp;random&nbsp;number&nbsp;generation.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;trees&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;trained&nbsp;decision&nbsp;trees.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bootstraps&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;bootstrapped&nbsp;indices&nbsp;for&nbsp;out-of-bag&nbsp;(OOB)&nbsp;scoring.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(numpy.ndarray&nbsp;or&nbsp;None):&nbsp;The&nbsp;feature&nbsp;matrix&nbsp;used&nbsp;for&nbsp;training.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(numpy.ndarray&nbsp;or&nbsp;None):&nbsp;The&nbsp;target&nbsp;labels&nbsp;used&nbsp;for&nbsp;training.<br>
&nbsp;&nbsp;&nbsp;&nbsp;accuracy&nbsp;(float):&nbsp;The&nbsp;accuracy&nbsp;of&nbsp;the&nbsp;model&nbsp;after&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;precision&nbsp;(float):&nbsp;The&nbsp;precision&nbsp;of&nbsp;the&nbsp;model&nbsp;after&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;recall&nbsp;(float):&nbsp;The&nbsp;recall&nbsp;of&nbsp;the&nbsp;model&nbsp;after&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;f1_score&nbsp;(float):&nbsp;The&nbsp;F1&nbsp;score&nbsp;of&nbsp;the&nbsp;model&nbsp;after&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;log_loss&nbsp;(float&nbsp;or&nbsp;None):&nbsp;The&nbsp;log&nbsp;loss&nbsp;of&nbsp;the&nbsp;model&nbsp;after&nbsp;fitting&nbsp;(only&nbsp;for&nbsp;binary&nbsp;classification).<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-__init__">__init__</a>(forest_size=100,&nbsp;max_depth=10,&nbsp;n_jobs=-1,&nbsp;random_seed=None,&nbsp;X=None,&nbsp;y=None):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initializes&nbsp;the&nbsp;<a href="#RandomForestClassifier">RandomForestClassifier</a>&nbsp;<a href="builtins.html#object">object</a>&nbsp;with&nbsp;the&nbsp;specified&nbsp;parameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-fit">fit</a>(X=None,&nbsp;y=None,&nbsp;verbose=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fits&nbsp;the&nbsp;random&nbsp;forest&nbsp;model&nbsp;to&nbsp;the&nbsp;provided&nbsp;data&nbsp;using&nbsp;parallel&nbsp;processing.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-calculate_metrics">calculate_metrics</a>(y_true,&nbsp;y_pred):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Calculates&nbsp;evaluation&nbsp;metrics&nbsp;(accuracy,&nbsp;precision,&nbsp;recall,&nbsp;F1&nbsp;score,&nbsp;and&nbsp;log&nbsp;loss)&nbsp;for&nbsp;classification.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-predict">predict</a>(X):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Predicts&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;provided&nbsp;data&nbsp;using&nbsp;the&nbsp;trained&nbsp;random&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-get_stats">get_stats</a>(verbose=False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns&nbsp;the&nbsp;evaluation&nbsp;metrics&nbsp;(accuracy,&nbsp;precision,&nbsp;recall,&nbsp;F1&nbsp;score,&nbsp;and&nbsp;log&nbsp;loss)&nbsp;as&nbsp;a&nbsp;dictionary.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RandomForestClassifier-__init__"><strong>__init__</strong></a>(self, forest_size=100, max_depth=10, min_samples_split=2, n_jobs=-1, random_seed=None, X=None, y=None)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;RandomForest&nbsp;<a href="builtins.html#object">object</a>.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-calculate_metrics"><strong>calculate_metrics</strong></a>(self, y_true, y_pred)</dt><dd><span class="code">Calculate&nbsp;evaluation&nbsp;metrics&nbsp;for&nbsp;classification.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-fit"><strong>fit</strong></a>(self, X=None, y=None, sample_weight=None, verbose=False)</dt><dd><span class="code">Fit&nbsp;the&nbsp;random&nbsp;forest&nbsp;with&nbsp;parallel&nbsp;processing.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-get_params"><strong>get_params</strong></a>(self)</dt><dd><span class="code">Get&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;<a href="#RandomForestClassifier">RandomForestClassifier</a>.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-get_stats"><strong>get_stats</strong></a>(self, verbose=False)</dt><dd><span class="code">Return&nbsp;the&nbsp;evaluation&nbsp;metrics.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;provided&nbsp;data.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-predict_proba"><strong>predict_proba</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;class&nbsp;probabilities&nbsp;for&nbsp;the&nbsp;provided&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;A&nbsp;2D&nbsp;array&nbsp;where&nbsp;each&nbsp;row&nbsp;represents&nbsp;the&nbsp;probability&nbsp;distribution<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;over&nbsp;the&nbsp;classes&nbsp;for&nbsp;a&nbsp;record.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RandomForestRegressor">class <strong>RandomForestRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RandomForestRegressor">RandomForestRegressor</a>(forest_size=100,&nbsp;max_depth=10,&nbsp;min_samples_split=2,&nbsp;n_jobs=-1,&nbsp;random_seed=None,&nbsp;X=None,&nbsp;y=None)<br>
&nbsp;<br>
A&nbsp;class&nbsp;representing&nbsp;a&nbsp;Random&nbsp;Forest&nbsp;model&nbsp;for&nbsp;regression.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_estimators&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;trees&nbsp;in&nbsp;the&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_jobs&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;jobs&nbsp;to&nbsp;run&nbsp;in&nbsp;parallel&nbsp;for&nbsp;fitting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int):&nbsp;Seed&nbsp;for&nbsp;random&nbsp;number&nbsp;generation&nbsp;for&nbsp;reproducibility.<br>
&nbsp;&nbsp;&nbsp;&nbsp;trees&nbsp;(list):&nbsp;List&nbsp;holding&nbsp;the&nbsp;fitted&nbsp;<a href="#RegressorTree">RegressorTree</a>&nbsp;instances.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(numpy.ndarray&nbsp;or&nbsp;None):&nbsp;The&nbsp;feature&nbsp;matrix&nbsp;used&nbsp;for&nbsp;training.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(numpy.ndarray&nbsp;or&nbsp;None):&nbsp;The&nbsp;target&nbsp;labels&nbsp;used&nbsp;for&nbsp;training.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-fit">fit</a>(X=None,&nbsp;y=None,&nbsp;verbose=False):&nbsp;Fits&nbsp;the&nbsp;random&nbsp;forest&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-calculate_metrics">calculate_metrics</a>(y_true,&nbsp;y_pred):&nbsp;Calculates&nbsp;the&nbsp;evaluation&nbsp;metrics.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-predict">predict</a>(X):&nbsp;Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-get_stats">get_stats</a>(verbose=False):&nbsp;Returns&nbsp;the&nbsp;evaluation&nbsp;metrics.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RandomForestRegressor-__init__"><strong>__init__</strong></a>(self, forest_size=100, max_depth=10, min_samples_split=2, n_jobs=-1, random_seed=None, X=None, y=None)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;Random&nbsp;Forest&nbsp;Regressor.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-calculate_metrics"><strong>calculate_metrics</strong></a>(self, y_true, y_pred)</dt><dd><span class="code">Calculate&nbsp;common&nbsp;regression&nbsp;metrics.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like):&nbsp;Predicted&nbsp;target&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics&nbsp;(MSE,&nbsp;R^2,&nbsp;MAE,&nbsp;RMSE,&nbsp;MAPE).</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-fit"><strong>fit</strong></a>(self, X=None, y=None, sample_weight=None, verbose=False)</dt><dd><span class="code">Fit&nbsp;the&nbsp;random&nbsp;forest&nbsp;to&nbsp;the&nbsp;training&nbsp;data&nbsp;X&nbsp;and&nbsp;y.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Training&nbsp;input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(array-like):&nbsp;Training&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight&nbsp;(array-like):&nbsp;Sample&nbsp;weights&nbsp;for&nbsp;each&nbsp;instance&nbsp;in&nbsp;X.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;progress&nbsp;messages.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;The&nbsp;fitted&nbsp;<a href="#RandomForestRegressor">RandomForestRegressor</a>&nbsp;instance.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-get_params"><strong>get_params</strong></a>(self)</dt><dd><span class="code">Get&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;Random&nbsp;Forest&nbsp;Regressor.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-get_stats"><strong>get_stats</strong></a>(self, y_true, y_pred, verbose=False)</dt><dd><span class="code">Calculate&nbsp;and&nbsp;optionally&nbsp;print&nbsp;evaluation&nbsp;metrics.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_true&nbsp;(array-like):&nbsp;True&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred&nbsp;(array-like):&nbsp;Predicted&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;progress&nbsp;messages&nbsp;(e.g.,&nbsp;residuals).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;calculated&nbsp;metrics&nbsp;(MSE,&nbsp;R^2,&nbsp;MAE,&nbsp;RMSE,&nbsp;MAPE).</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;target&nbsp;values&nbsp;for&nbsp;input&nbsp;features&nbsp;X&nbsp;using&nbsp;the&nbsp;trained&nbsp;random&nbsp;forest.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like):&nbsp;Input&nbsp;features&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;Predicted&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RandomOverSampler">class <strong>RandomOverSampler</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RandomOverSampler">RandomOverSampler</a>(random_state=None)<br>
&nbsp;<br>
Randomly&nbsp;over-sample&nbsp;the&nbsp;minority&nbsp;class&nbsp;by&nbsp;duplicating&nbsp;examples.<br>
&nbsp;<br>
This&nbsp;technique&nbsp;helps&nbsp;to&nbsp;balance&nbsp;the&nbsp;class&nbsp;distribution&nbsp;by&nbsp;randomly&nbsp;duplicating&nbsp;samples&nbsp;from&nbsp;the&nbsp;minority&nbsp;class.<br>
It&nbsp;is&nbsp;a&nbsp;simple&nbsp;yet&nbsp;effective&nbsp;method&nbsp;to&nbsp;address&nbsp;class&nbsp;imbalance&nbsp;in&nbsp;datasets.<br>
&nbsp;<br>
Algorithm&nbsp;Steps:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;1:&nbsp;Identify&nbsp;the&nbsp;minority&nbsp;class&nbsp;and&nbsp;its&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;2:&nbsp;Calculate&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;needed&nbsp;to&nbsp;balance&nbsp;the&nbsp;class&nbsp;distribution.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;3:&nbsp;Randomly&nbsp;select&nbsp;samples&nbsp;from&nbsp;the&nbsp;minority&nbsp;class&nbsp;with&nbsp;replacement.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;4:&nbsp;Duplicate&nbsp;the&nbsp;selected&nbsp;samples&nbsp;to&nbsp;create&nbsp;a&nbsp;balanced&nbsp;dataset.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RandomOverSampler-__init__"><strong>__init__</strong></a>(self, random_state=None)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#RandomOverSampler">RandomOverSampler</a>&nbsp;with&nbsp;an&nbsp;optional&nbsp;random&nbsp;state.</span></dd></dl>

<dl><dt><a name="RandomOverSampler-fit_resample"><strong>fit_resample</strong></a>(self, X, y)</dt><dd><span class="code">Resamples&nbsp;the&nbsp;dataset&nbsp;to&nbsp;balance&nbsp;the&nbsp;class&nbsp;distribution&nbsp;by&nbsp;duplicating&nbsp;minority&nbsp;class&nbsp;samples.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;Feature&nbsp;matrix.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;Target&nbsp;vector.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuple:&nbsp;(np.ndarray,&nbsp;np.ndarray)&nbsp;-&nbsp;Resampled&nbsp;feature&nbsp;matrix&nbsp;and&nbsp;target&nbsp;vector.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RandomSearchCV">class <strong>RandomSearchCV</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RandomSearchCV">RandomSearchCV</a>(model,&nbsp;param_grid,&nbsp;iter=10,&nbsp;cv=5,&nbsp;metric='mse',&nbsp;direction='minimize')<br>
&nbsp;<br>
Implements&nbsp;a&nbsp;random&nbsp;search&nbsp;cross-validation&nbsp;for&nbsp;hyperparameter&nbsp;tuning.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RandomSearchCV-__init__"><strong>__init__</strong></a>(self, model, param_grid, iter=10, cv=5, metric='mse', direction='minimize')</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#RandomSearchCV">RandomSearchCV</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;The&nbsp;model&nbsp;Object&nbsp;to&nbsp;be&nbsp;tuned.<br>
&nbsp;&nbsp;&nbsp;&nbsp;param_grid:&nbsp;(list)&nbsp;-&nbsp;A&nbsp;list&nbsp;of&nbsp;dictionaries&nbsp;containing&nbsp;hyperparameters&nbsp;to&nbsp;be&nbsp;tuned.<br>
&nbsp;&nbsp;&nbsp;&nbsp;iter:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;random&nbsp;search.&nbsp;Default&nbsp;is&nbsp;10.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cv:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;folds&nbsp;for&nbsp;cross-validation.&nbsp;Default&nbsp;is&nbsp;5.<br>
&nbsp;&nbsp;&nbsp;&nbsp;metric:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;metric&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;evaluation.&nbsp;Default&nbsp;is&nbsp;'mse'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Regression&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'mse',&nbsp;'r2',&nbsp;'mae',&nbsp;'rmse',&nbsp;'mape',&nbsp;'mpe'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Classification&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'accuracy',&nbsp;'precision',&nbsp;'recall',&nbsp;'f1',&nbsp;'log_loss'<br>
&nbsp;&nbsp;&nbsp;&nbsp;direction:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;direction&nbsp;to&nbsp;optimize&nbsp;the&nbsp;metric.&nbsp;Default&nbsp;is&nbsp;'minimize'.</span></dd></dl>

<dl><dt><a name="RandomSearchCV-fit"><strong>fit</strong></a>(self, X, y, verbose=False)</dt><dd><span class="code">Fits&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;for&nbsp;iter&nbsp;random&nbsp;hyperparameter&nbsp;combinations.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;feature&nbsp;columns.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;label&nbsp;column.<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;(bool)&nbsp;-&nbsp;A&nbsp;flag&nbsp;to&nbsp;display&nbsp;the&nbsp;training&nbsp;progress.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;model:&nbsp;The&nbsp;best&nbsp;model&nbsp;with&nbsp;the&nbsp;optimal&nbsp;hyperparameters.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RandomUnderSampler">class <strong>RandomUnderSampler</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RandomUnderSampler">RandomUnderSampler</a>(random_state=None)<br>
&nbsp;<br>
Randomly&nbsp;under-sample&nbsp;the&nbsp;majority&nbsp;class&nbsp;by&nbsp;removing&nbsp;examples.<br>
&nbsp;<br>
This&nbsp;technique&nbsp;helps&nbsp;to&nbsp;balance&nbsp;the&nbsp;class&nbsp;distribution&nbsp;by&nbsp;randomly&nbsp;removing&nbsp;samples&nbsp;from&nbsp;the&nbsp;majority&nbsp;class.<br>
It&nbsp;is&nbsp;a&nbsp;simple&nbsp;yet&nbsp;effective&nbsp;method&nbsp;to&nbsp;address&nbsp;class&nbsp;imbalance&nbsp;in&nbsp;datasets.<br>
&nbsp;<br>
Algorithm&nbsp;Steps:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;1:&nbsp;Identify&nbsp;the&nbsp;majority&nbsp;class&nbsp;and&nbsp;its&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;2:&nbsp;Calculate&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;to&nbsp;remove&nbsp;to&nbsp;balance&nbsp;the&nbsp;class&nbsp;distribution.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;3:&nbsp;Randomly&nbsp;select&nbsp;samples&nbsp;from&nbsp;the&nbsp;majority&nbsp;class&nbsp;without&nbsp;replacement.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;4:&nbsp;Remove&nbsp;the&nbsp;selected&nbsp;samples&nbsp;to&nbsp;create&nbsp;a&nbsp;balanced&nbsp;dataset.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RandomUnderSampler-__init__"><strong>__init__</strong></a>(self, random_state=None)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#RandomUnderSampler">RandomUnderSampler</a>&nbsp;with&nbsp;an&nbsp;optional&nbsp;random&nbsp;state.</span></dd></dl>

<dl><dt><a name="RandomUnderSampler-fit_resample"><strong>fit_resample</strong></a>(self, X, y)</dt><dd><span class="code">Resamples&nbsp;the&nbsp;dataset&nbsp;to&nbsp;balance&nbsp;the&nbsp;class&nbsp;distribution&nbsp;by&nbsp;removing&nbsp;majority&nbsp;class&nbsp;samples.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;Feature&nbsp;matrix.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;Target&nbsp;vector.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuple:&nbsp;(np.ndarray,&nbsp;np.ndarray)&nbsp;-&nbsp;Resampled&nbsp;feature&nbsp;matrix&nbsp;and&nbsp;target&nbsp;vector.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RegressorTree">class <strong>RegressorTree</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RegressorTree">RegressorTree</a>(max_depth=5,&nbsp;min_samples_split=2)<br>
&nbsp;<br>
A&nbsp;class&nbsp;representing&nbsp;a&nbsp;decision&nbsp;tree&nbsp;for&nbsp;regression.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_features:&nbsp;(int)&nbsp;-&nbsp;The&nbsp;number&nbsp;of&nbsp;features&nbsp;in&nbsp;the&nbsp;dataset.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RegressorTree-fit">fit</a>(X,&nbsp;y,&nbsp;verbose=False):&nbsp;Fits&nbsp;the&nbsp;decision&nbsp;tree&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RegressorTree-predict">predict</a>(X):&nbsp;Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_traverse_tree(x,&nbsp;node):&nbsp;Traverses&nbsp;the&nbsp;decision&nbsp;tree&nbsp;for&nbsp;a&nbsp;single&nbsp;sample&nbsp;x.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_leran_recursive(indices,&nbsp;depth):&nbsp;Recursive&nbsp;helper&nbsp;function&nbsp;for&nbsp;learning.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RegressorTree-__init__"><strong>__init__</strong></a>(self, max_depth=5, min_samples_split=2)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node.</span></dd></dl>

<dl><dt><a name="RegressorTree-fit"><strong>fit</strong></a>(self, X, y, sample_weight=None, verbose=False)</dt><dd><span class="code">Fit&nbsp;the&nbsp;decision&nbsp;tree&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;target&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample_weight:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;sample&nbsp;weights&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;(bool)&nbsp;-&nbsp;If&nbsp;True,&nbsp;print&nbsp;detailed&nbsp;logs&nbsp;during&nbsp;fitting.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;The&nbsp;learned&nbsp;decision&nbsp;tree.</span></dd></dl>

<dl><dt><a name="RegressorTree-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;the&nbsp;target&nbsp;value&nbsp;for&nbsp;a&nbsp;record&nbsp;or&nbsp;batch&nbsp;of&nbsp;records&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;The&nbsp;input&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;np.ndarray:&nbsp;The&nbsp;predicted&nbsp;target&nbsp;values.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RegressorTreeUtility">class <strong>RegressorTreeUtility</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RegressorTreeUtility">RegressorTreeUtility</a>(X,&nbsp;y,&nbsp;min_samples_split,&nbsp;n_features)<br>
&nbsp;<br>
Utility&nbsp;class&nbsp;containing&nbsp;helper&nbsp;functions&nbsp;for&nbsp;building&nbsp;the&nbsp;Regressor&nbsp;Tree.<br>
&nbsp;<br>
Handles&nbsp;variance&nbsp;calculation,&nbsp;leaf&nbsp;value&nbsp;calculation,&nbsp;and&nbsp;finding&nbsp;the&nbsp;best&nbsp;split.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RegressorTreeUtility-__init__"><strong>__init__</strong></a>(self, X, y, min_samples_split, n_features)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;utility&nbsp;class&nbsp;with&nbsp;references&nbsp;to&nbsp;data&nbsp;and&nbsp;parameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(np.ndarray):&nbsp;Reference&nbsp;to&nbsp;the&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(np.ndarray):&nbsp;Reference&nbsp;to&nbsp;the&nbsp;target&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;(int):&nbsp;Minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;a&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_features&nbsp;(int):&nbsp;Total&nbsp;number&nbsp;of&nbsp;features&nbsp;in&nbsp;X.</span></dd></dl>

<dl><dt><a name="RegressorTreeUtility-best_split"><strong>best_split</strong></a>(self, indices, sample_weight=None)</dt><dd><span class="code">Finds&nbsp;the&nbsp;best&nbsp;split&nbsp;for&nbsp;the&nbsp;data&nbsp;subset&nbsp;defined&nbsp;by&nbsp;indices.</span></dd></dl>

<dl><dt><a name="RegressorTreeUtility-calculate_leaf_value"><strong>calculate_leaf_value</strong></a>(self, indices, sample_weight=None)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;weighted&nbsp;mean&nbsp;value&nbsp;for&nbsp;a&nbsp;leaf&nbsp;node.</span></dd></dl>

<dl><dt><a name="RegressorTreeUtility-calculate_variance"><strong>calculate_variance</strong></a>(self, indices, sample_weight=None)</dt><dd><span class="code">Calculate&nbsp;weighted&nbsp;variance&nbsp;for&nbsp;the&nbsp;subset&nbsp;defined&nbsp;by&nbsp;indices.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Ridge">class <strong>Ridge</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#Ridge">Ridge</a>(alpha=1.0,&nbsp;fit_intercept=True,&nbsp;max_iter=10000,&nbsp;tol=0.0001,&nbsp;compile_numba=False)<br>
&nbsp;<br>
Fits&nbsp;the&nbsp;<a href="#Ridge">Ridge</a>&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
<a href="#Ridge">Ridge</a>&nbsp;regression&nbsp;implements&nbsp;L2&nbsp;regularization,&nbsp;which&nbsp;helps&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;a&nbsp;penalty&nbsp;term&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;alpha:&nbsp;(float)&nbsp;-&nbsp;Regularization&nbsp;strength;&nbsp;must&nbsp;be&nbsp;a&nbsp;positive&nbsp;float&nbsp;(default&nbsp;is&nbsp;1.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;fit_intercept:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model&nbsp;(default&nbsp;is&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;the&nbsp;coordinate&nbsp;descent&nbsp;solver&nbsp;(default&nbsp;is&nbsp;10000).<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Tolerance&nbsp;for&nbsp;the&nbsp;optimization.&nbsp;The&nbsp;optimization&nbsp;stops&nbsp;when&nbsp;the&nbsp;change&nbsp;in&nbsp;the&nbsp;coefficients&nbsp;is&nbsp;less&nbsp;than&nbsp;this&nbsp;tolerance&nbsp;(default&nbsp;is&nbsp;1e-4).<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef_:&nbsp;(np.ndarray)&nbsp;-&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;linear&nbsp;regression&nbsp;problem.&nbsp;If&nbsp;`fit_intercept`&nbsp;is&nbsp;True,&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;the&nbsp;intercept.<br>
&nbsp;&nbsp;&nbsp;&nbsp;intercept_:&nbsp;(float)&nbsp;-&nbsp;Independent&nbsp;term&nbsp;in&nbsp;the&nbsp;linear&nbsp;model.&nbsp;Set&nbsp;to&nbsp;0.0&nbsp;if&nbsp;`fit_intercept`&nbsp;is&nbsp;False.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#Ridge-fit">fit</a>(X,&nbsp;y):&nbsp;Fits&nbsp;the&nbsp;<a href="#Ridge">Ridge</a>&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#Ridge-predict">predict</a>(X):&nbsp;Predicts&nbsp;using&nbsp;the&nbsp;<a href="#Ridge">Ridge</a>&nbsp;Regression&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#Ridge-get_formula">get_formula</a>():&nbsp;Returns&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model&nbsp;as&nbsp;a&nbsp;string.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="Ridge-__init__"><strong>__init__</strong></a>(self, alpha=1.0, fit_intercept=True, max_iter=10000, tol=0.0001, compile_numba=False)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#Ridge">Ridge</a>&nbsp;Regression&nbsp;model.<br>
&nbsp;<br>
<a href="#Ridge">Ridge</a>&nbsp;regression&nbsp;implements&nbsp;L2&nbsp;regularization,&nbsp;which&nbsp;helps&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;a&nbsp;penalty&nbsp;term&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;alpha:&nbsp;(float)&nbsp;-&nbsp;Regularization&nbsp;strength;&nbsp;must&nbsp;be&nbsp;a&nbsp;positive&nbsp;float&nbsp;(default&nbsp;is&nbsp;1.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;fit_intercept:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model&nbsp;(default&nbsp;is&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iter:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;the&nbsp;coordinate&nbsp;descent&nbsp;solver&nbsp;(default&nbsp;is&nbsp;10000).<br>
&nbsp;&nbsp;&nbsp;&nbsp;tol:&nbsp;(float),&nbsp;optional&nbsp;-&nbsp;Tolerance&nbsp;for&nbsp;the&nbsp;optimization.&nbsp;The&nbsp;optimization&nbsp;stops&nbsp;when&nbsp;the&nbsp;change&nbsp;in&nbsp;the&nbsp;coefficients&nbsp;is&nbsp;less&nbsp;than&nbsp;this&nbsp;tolerance&nbsp;(default&nbsp;is&nbsp;1e-4).<br>
&nbsp;&nbsp;&nbsp;&nbsp;compile_numba:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;precompile&nbsp;the&nbsp;numba&nbsp;functions&nbsp;(default&nbsp;is&nbsp;False).&nbsp;If&nbsp;True,&nbsp;the&nbsp;numba&nbsp;fitting&nbsp;functions&nbsp;will&nbsp;be&nbsp;compiled&nbsp;before&nbsp;use.</span></dd></dl>

<dl><dt><a name="Ridge-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;the&nbsp;string&nbsp;representation&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="Ridge-fit"><strong>fit</strong></a>(self, X, y, numba=False)</dt><dd><span class="code">Fits&nbsp;the&nbsp;<a href="#Ridge">Ridge</a>&nbsp;Regression&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Training&nbsp;target&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;numba:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;Whether&nbsp;to&nbsp;use&nbsp;numba&nbsp;for&nbsp;faster&nbsp;computation&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;self:&nbsp;(<a href="#Ridge">Ridge</a>)&nbsp;-&nbsp;The&nbsp;fitted&nbsp;<a href="#Ridge">Ridge</a>&nbsp;Regression&nbsp;model.</span></dd></dl>

<dl><dt><a name="Ridge-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Computes&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;formula:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;formula&nbsp;of&nbsp;the&nbsp;model&nbsp;as&nbsp;a&nbsp;string.</span></dd></dl>

<dl><dt><a name="Ridge-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;using&nbsp;the&nbsp;<a href="#Ridge">Ridge</a>&nbsp;Regression&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Feature&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;(np.ndarray)&nbsp;-&nbsp;Predicted&nbsp;target&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="SGDOptimizer">class <strong>SGDOptimizer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#SGDOptimizer">SGDOptimizer</a>(learning_rate=0.001,&nbsp;momentum=0.0,&nbsp;reg_lambda=0.0)<br>
&nbsp;<br>
Stochastic&nbsp;Gradient&nbsp;Descent&nbsp;(SGD)&nbsp;optimizer&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
Formula:&nbsp;w&nbsp;=&nbsp;w&nbsp;-&nbsp;learning_rate&nbsp;*&nbsp;dW,&nbsp;b&nbsp;=&nbsp;b&nbsp;-&nbsp;learning_rate&nbsp;*&nbsp;db<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;0.001.<br>
&nbsp;&nbsp;&nbsp;&nbsp;momentum&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;momentum&nbsp;factor.&nbsp;Defaults&nbsp;to&nbsp;0.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter.&nbsp;Defaults&nbsp;to&nbsp;0.0.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="SGDOptimizer-__init__"><strong>__init__</strong></a>(self, learning_rate=0.001, momentum=0.0, reg_lambda=0.0)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;optimizer&nbsp;with&nbsp;specified&nbsp;parameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;step&nbsp;size&nbsp;for&nbsp;updating&nbsp;weights.&nbsp;Defaults&nbsp;to&nbsp;0.001.<br>
&nbsp;&nbsp;&nbsp;&nbsp;momentum&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;momentum&nbsp;factor&nbsp;to&nbsp;accelerate&nbsp;gradient&nbsp;descent.&nbsp;Defaults&nbsp;to&nbsp;0.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter&nbsp;to&nbsp;prevent&nbsp;overfitting.&nbsp;Defaults&nbsp;to&nbsp;0.0.</span></dd></dl>

<dl><dt><a name="SGDOptimizer-initialize"><strong>initialize</strong></a>(self, layers)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;velocity&nbsp;for&nbsp;each&nbsp;layer's&nbsp;weights.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layers&nbsp;(list):&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="SGDOptimizer-update"><strong>update</strong></a>(self, layer, dW, db, index)</dt><dd><span class="code">Updates&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;a&nbsp;layer&nbsp;using&nbsp;the&nbsp;SGD&nbsp;optimization&nbsp;algorithm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer&nbsp;(Layer):&nbsp;The&nbsp;layer&nbsp;to&nbsp;update.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dW&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;db&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;index&nbsp;(int):&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;layer.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="SMOTE">class <strong>SMOTE</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#SMOTE">SMOTE</a>(random_state=None,&nbsp;k_neighbors=5)<br>
&nbsp;<br>
Synthetic&nbsp;Minority&nbsp;Over-sampling&nbsp;Technique&nbsp;(<a href="#SMOTE">SMOTE</a>)&nbsp;for&nbsp;balancing&nbsp;class&nbsp;distribution.<br>
&nbsp;<br>
<a href="#SMOTE">SMOTE</a>&nbsp;generates&nbsp;synthetic&nbsp;samples&nbsp;for&nbsp;the&nbsp;minority&nbsp;class&nbsp;by&nbsp;interpolating&nbsp;between&nbsp;existing&nbsp;samples.<br>
This&nbsp;helps&nbsp;to&nbsp;create&nbsp;a&nbsp;more&nbsp;balanced&nbsp;dataset,&nbsp;which&nbsp;can&nbsp;improve&nbsp;the&nbsp;performance&nbsp;of&nbsp;machine&nbsp;learning&nbsp;models.<br>
&nbsp;<br>
Algorithm&nbsp;Steps:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;1:&nbsp;Identify&nbsp;the&nbsp;minority&nbsp;class&nbsp;and&nbsp;its&nbsp;samples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;2:&nbsp;For&nbsp;each&nbsp;sample&nbsp;in&nbsp;the&nbsp;minority&nbsp;class,&nbsp;find&nbsp;its&nbsp;k&nbsp;nearest&nbsp;neighbors&nbsp;(using&nbsp;Euclidean&nbsp;distance.)<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;3:&nbsp;Randomly&nbsp;select&nbsp;one&nbsp;or&nbsp;more&nbsp;of&nbsp;these&nbsp;neighbors.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Step&nbsp;4:&nbsp;Create&nbsp;synthetic&nbsp;samples&nbsp;by&nbsp;interpolating&nbsp;between&nbsp;the&nbsp;original&nbsp;sample&nbsp;and&nbsp;the&nbsp;selected&nbsp;neighbors.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="SMOTE-__init__"><strong>__init__</strong></a>(self, random_state=None, k_neighbors=5)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#SMOTE">SMOTE</a>&nbsp;with&nbsp;an&nbsp;optional&nbsp;random&nbsp;state&nbsp;and&nbsp;number&nbsp;of&nbsp;neighbors.</span></dd></dl>

<dl><dt><a name="SMOTE-fit_resample"><strong>fit_resample</strong></a>(self, X, y, force_equal=False)</dt><dd><span class="code">Resamples&nbsp;the&nbsp;dataset&nbsp;to&nbsp;balance&nbsp;the&nbsp;class&nbsp;distribution&nbsp;by&nbsp;generating&nbsp;synthetic&nbsp;samples.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(array-like)&nbsp;-&nbsp;Feature&nbsp;matrix.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(array-like)&nbsp;-&nbsp;Target&nbsp;vector.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_equal:&nbsp;(bool),&nbsp;optional&nbsp;-&nbsp;If&nbsp;True,&nbsp;resample&nbsp;until&nbsp;classes&nbsp;are&nbsp;equal&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuple:&nbsp;(np.ndarray,&nbsp;np.ndarray)&nbsp;-&nbsp;Resampled&nbsp;feature&nbsp;matrix&nbsp;and&nbsp;target&nbsp;vector.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="SVD">class <strong>SVD</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#SVD">SVD</a>(n_components)<br>
&nbsp;<br>
Singular&nbsp;Value&nbsp;Decomposition&nbsp;(<a href="#SVD">SVD</a>)&nbsp;implementation.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="SVD-__init__"><strong>__init__</strong></a>(self, n_components)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#SVD">SVD</a>&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_components:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;singular&nbsp;values&nbsp;and&nbsp;vectors&nbsp;to&nbsp;keep.</span></dd></dl>

<dl><dt><a name="SVD-fit"><strong>fit</strong></a>(self, X)</dt><dd><span class="code">Fits&nbsp;the&nbsp;<a href="#SVD">SVD</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValueError:&nbsp;If&nbsp;input&nbsp;data&nbsp;is&nbsp;not&nbsp;a&nbsp;2D&nbsp;numpy&nbsp;array&nbsp;or&nbsp;if&nbsp;n_components&nbsp;exceeds&nbsp;the&nbsp;minimum&nbsp;dimension&nbsp;of&nbsp;the&nbsp;input&nbsp;data.</span></dd></dl>

<dl><dt><a name="SVD-fit_transform"><strong>fit_transform</strong></a>(self, X)</dt><dd><span class="code">Fits&nbsp;the&nbsp;<a href="#SVD">SVD</a>&nbsp;model&nbsp;and&nbsp;applies&nbsp;the&nbsp;transformation&nbsp;on&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_transformed:&nbsp;(np.ndarray)&nbsp;-&nbsp;Data&nbsp;transformed&nbsp;into&nbsp;the&nbsp;singular&nbsp;value&nbsp;space&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_components).</span></dd></dl>

<dl><dt><a name="SVD-get_singular_values"><strong>get_singular_values</strong></a>(self)</dt><dd><span class="code">Retrieves&nbsp;the&nbsp;singular&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;S:&nbsp;(np.ndarray)&nbsp;-&nbsp;Array&nbsp;of&nbsp;singular&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_components,).</span></dd></dl>

<dl><dt><a name="SVD-get_singular_vectors"><strong>get_singular_vectors</strong></a>(self)</dt><dd><span class="code">Retrieves&nbsp;the&nbsp;singular&nbsp;vectors.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;U:&nbsp;(np.ndarray)&nbsp;-&nbsp;Left&nbsp;singular&nbsp;vectors&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_components).<br>
&nbsp;&nbsp;&nbsp;&nbsp;Vt:&nbsp;(np.ndarray)&nbsp;-&nbsp;Right&nbsp;singular&nbsp;vectors&nbsp;of&nbsp;shape&nbsp;(n_components,&nbsp;n_features).</span></dd></dl>

<dl><dt><a name="SVD-transform"><strong>transform</strong></a>(self, X)</dt><dd><span class="code">Applies&nbsp;the&nbsp;<a href="#SVD">SVD</a>&nbsp;transformation&nbsp;on&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_transformed:&nbsp;(np.ndarray)&nbsp;-&nbsp;Data&nbsp;transformed&nbsp;into&nbsp;the&nbsp;singular&nbsp;value&nbsp;space&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_components).<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValueError:&nbsp;If&nbsp;input&nbsp;data&nbsp;is&nbsp;not&nbsp;a&nbsp;2D&nbsp;numpy&nbsp;array.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Scaler">class <strong>Scaler</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#Scaler">Scaler</a>(method='standard')<br>
&nbsp;<br>
A&nbsp;class&nbsp;for&nbsp;scaling&nbsp;data&nbsp;by&nbsp;standardization&nbsp;and&nbsp;normalization.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="Scaler-__init__"><strong>__init__</strong></a>(self, method='standard')</dt><dd><span class="code">Initializes&nbsp;the&nbsp;scaler&nbsp;with&nbsp;the&nbsp;specified&nbsp;method.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;method:&nbsp;(str)&nbsp;-&nbsp;The&nbsp;scaling&nbsp;method&nbsp;to&nbsp;use.&nbsp;Options&nbsp;are&nbsp;'standard',&nbsp;'minmax',&nbsp;or&nbsp;'normalize'.</span></dd></dl>

<dl><dt><a name="Scaler-fit"><strong>fit</strong></a>(self, X)</dt><dd><span class="code">Fits&nbsp;the&nbsp;scaler&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;data&nbsp;to&nbsp;fit&nbsp;the&nbsp;scaler&nbsp;to.</span></dd></dl>

<dl><dt><a name="Scaler-fit_transform"><strong>fit_transform</strong></a>(self, X)</dt><dd><span class="code">Fits&nbsp;the&nbsp;scaler&nbsp;to&nbsp;the&nbsp;data&nbsp;and&nbsp;then&nbsp;transforms&nbsp;it.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;data&nbsp;to&nbsp;fit&nbsp;and&nbsp;transform.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_transformed:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;transformed&nbsp;data.</span></dd></dl>

<dl><dt><a name="Scaler-inverse_transform"><strong>inverse_transform</strong></a>(self, X)</dt><dd><span class="code">Inverse&nbsp;transforms&nbsp;the&nbsp;data&nbsp;using&nbsp;the&nbsp;fitted&nbsp;scaler.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;data&nbsp;to&nbsp;inverse&nbsp;transform.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_inverse:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;inverse&nbsp;transformed&nbsp;data.</span></dd></dl>

<dl><dt><a name="Scaler-transform"><strong>transform</strong></a>(self, X)</dt><dd><span class="code">Transforms&nbsp;the&nbsp;data&nbsp;using&nbsp;the&nbsp;fitted&nbsp;scaler.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;data&nbsp;to&nbsp;transform.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X_transformed:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;transformed&nbsp;data.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="VotingClassifier">class <strong>VotingClassifier</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#VotingClassifier">VotingClassifier</a>(estimators,&nbsp;weights=None)<br>
&nbsp;<br>
Implements&nbsp;a&nbsp;hard&nbsp;voting&nbsp;classifier.<br>
&nbsp;<br>
Aggregates&nbsp;predictions&nbsp;from&nbsp;multiple&nbsp;fitted&nbsp;classification&nbsp;models&nbsp;based&nbsp;on<br>
majority&nbsp;vote&nbsp;(optionally&nbsp;weighted).<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="VotingClassifier-__init__"><strong>__init__</strong></a>(self, estimators, weights=None)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#VotingClassifier">VotingClassifier</a>&nbsp;<a href="builtins.html#object">object</a>&nbsp;for&nbsp;hard&nbsp;voting.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;estimators&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;*fitted*&nbsp;classifier&nbsp;objects.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Each&nbsp;estimator&nbsp;must&nbsp;have&nbsp;a&nbsp;`predict`&nbsp;method.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_estimators,),&nbsp;optional):&nbsp;Sequence&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weights&nbsp;(float&nbsp;or&nbsp;int)&nbsp;to&nbsp;weight&nbsp;the&nbsp;occurrences&nbsp;of&nbsp;predicted&nbsp;class<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;labels&nbsp;during&nbsp;voting.&nbsp;Uses&nbsp;uniform&nbsp;weights&nbsp;if&nbsp;None.&nbsp;Defaults&nbsp;to&nbsp;None.</span></dd></dl>

<dl><dt><a name="VotingClassifier-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><span class="code">Get&nbsp;parameters&nbsp;for&nbsp;this&nbsp;estimator.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;deep&nbsp;(bool,&nbsp;optional):&nbsp;If&nbsp;True,&nbsp;will&nbsp;return&nbsp;the&nbsp;parameters&nbsp;for&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;estimator&nbsp;and&nbsp;contained&nbsp;subobjects&nbsp;that&nbsp;are&nbsp;estimators.&nbsp;(Not&nbsp;fully&nbsp;implemented&nbsp;for&nbsp;deep=True&nbsp;yet).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;params&nbsp;(dict):&nbsp;Parameter&nbsp;names&nbsp;mapped&nbsp;to&nbsp;their&nbsp;values.</span></dd></dl>

<dl><dt><a name="VotingClassifier-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;class&nbsp;labels&nbsp;for&nbsp;X&nbsp;using&nbsp;hard&nbsp;voting.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features)):&nbsp;The&nbsp;input&nbsp;samples.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;maj&nbsp;(np.ndarray&nbsp;of&nbsp;shape&nbsp;(n_samples,)):&nbsp;Predicted&nbsp;class&nbsp;labels&nbsp;based&nbsp;on&nbsp;majority&nbsp;vote.</span></dd></dl>

<dl><dt><a name="VotingClassifier-show_models"><strong>show_models</strong></a>(self)</dt><dd><span class="code">Print&nbsp;the&nbsp;models&nbsp;and&nbsp;their&nbsp;weights.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="VotingRegressor">class <strong>VotingRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#VotingRegressor">VotingRegressor</a>(models,&nbsp;model_weights=None)<br>
&nbsp;<br>
Implements&nbsp;a&nbsp;voting&nbsp;regressor.<br>
&nbsp;<br>
Takes&nbsp;a&nbsp;list&nbsp;of&nbsp;fitted&nbsp;models&nbsp;and&nbsp;their&nbsp;weights&nbsp;and&nbsp;returns&nbsp;a&nbsp;weighted&nbsp;average&nbsp;of&nbsp;the&nbsp;predictions.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="VotingRegressor-__init__"><strong>__init__</strong></a>(self, models, model_weights=None)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#VotingRegressor">VotingRegressor</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;models:&nbsp;list&nbsp;of&nbsp;models&nbsp;to&nbsp;be&nbsp;stacked<br>
&nbsp;&nbsp;&nbsp;&nbsp;model_weights:&nbsp;list&nbsp;of&nbsp;weights&nbsp;for&nbsp;each&nbsp;model.&nbsp;Default&nbsp;is&nbsp;None.</span></dd></dl>

<dl><dt><a name="VotingRegressor-get_params"><strong>get_params</strong></a>(self)</dt><dd><span class="code">Get&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;<a href="#VotingRegressor">VotingRegressor</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;params:&nbsp;dictionary&nbsp;of&nbsp;parameters</span></dd></dl>

<dl><dt><a name="VotingRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;the&nbsp;target&nbsp;variable&nbsp;using&nbsp;the&nbsp;fitted&nbsp;models.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;input&nbsp;features<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_pred:&nbsp;predicted&nbsp;target&nbsp;variable</span></dd></dl>

<dl><dt><a name="VotingRegressor-show_models"><strong>show_models</strong></a>(self, formula=False)</dt><dd><span class="code">Print&nbsp;the&nbsp;models&nbsp;and&nbsp;their&nbsp;weights.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="lr_scheduler_exp">class <strong>lr_scheduler_exp</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#lr_scheduler_exp">lr_scheduler_exp</a>(optimizer,&nbsp;lr_decay=0.1,&nbsp;lr_decay_epoch=10)<br>
&nbsp;<br>
Learning&nbsp;rate&nbsp;scheduler&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
Reduces&nbsp;the&nbsp;learning&nbsp;rate&nbsp;exponentially&nbsp;by&nbsp;lr_decay&nbsp;every&nbsp;lr_decay_epoch&nbsp;epochs.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="lr_scheduler_exp-__init__"><strong>__init__</strong></a>(self, optimizer, lr_decay=0.1, lr_decay_epoch=10)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;scheduler&nbsp;with&nbsp;the&nbsp;given&nbsp;optimizer&nbsp;and&nbsp;learning&nbsp;rate&nbsp;decay&nbsp;parameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer&nbsp;(Optimizer):&nbsp;The&nbsp;optimizer&nbsp;whose&nbsp;learning&nbsp;rate&nbsp;will&nbsp;be&nbsp;scheduled.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_decay&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;factor&nbsp;by&nbsp;which&nbsp;the&nbsp;learning&nbsp;rate&nbsp;will&nbsp;be&nbsp;multiplied&nbsp;at&nbsp;each&nbsp;decay&nbsp;step.&nbsp;Default&nbsp;is&nbsp;0.1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_decay_epoch&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;number&nbsp;of&nbsp;epochs&nbsp;after&nbsp;which&nbsp;the&nbsp;learning&nbsp;rate&nbsp;will&nbsp;be&nbsp;decayed.&nbsp;Default&nbsp;is&nbsp;10.</span></dd></dl>

<dl><dt><a name="lr_scheduler_exp-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;a&nbsp;string&nbsp;representation&nbsp;of&nbsp;the&nbsp;scheduler.</span></dd></dl>

<dl><dt><a name="lr_scheduler_exp-reduce"><strong>reduce</strong></a>(self)</dt><dd><span class="code">Reduces&nbsp;the&nbsp;learning&nbsp;rate&nbsp;exponentially.</span></dd></dl>

<dl><dt><a name="lr_scheduler_exp-step"><strong>step</strong></a>(self, epoch)</dt><dd><span class="code">Adjusts&nbsp;the&nbsp;learning&nbsp;rate&nbsp;based&nbsp;on&nbsp;the&nbsp;current&nbsp;epoch.&nbsp;Decays&nbsp;the&nbsp;learning&nbsp;rate&nbsp;by&nbsp;lr_decay&nbsp;every&nbsp;lr_decay_epoch&nbsp;epochs.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;epoch&nbsp;(int):&nbsp;The&nbsp;current&nbsp;epoch&nbsp;number.<br>
Returns:&nbsp;None</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="lr_scheduler_plateau">class <strong>lr_scheduler_plateau</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#lr_scheduler_plateau">lr_scheduler_plateau</a>(lr_scheduler,&nbsp;patience=5,&nbsp;threshold=0.01)<br>
&nbsp;<br>
A&nbsp;custom&nbsp;learning&nbsp;rate&nbsp;scheduler&nbsp;that&nbsp;adjusts&nbsp;the&nbsp;learning&nbsp;rate&nbsp;based&nbsp;on&nbsp;the&nbsp;plateau&nbsp;of&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_scheduler&nbsp;(<a href="builtins.html#object">object</a>):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;scheduler&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;patience&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;epochs&nbsp;to&nbsp;wait&nbsp;for&nbsp;improvement&nbsp;before&nbsp;reducing&nbsp;the&nbsp;learning&nbsp;rate.&nbsp;Default&nbsp;is&nbsp;5.<br>
&nbsp;&nbsp;&nbsp;&nbsp;threshold&nbsp;(float):&nbsp;The&nbsp;minimum&nbsp;improvement&nbsp;threshold&nbsp;required&nbsp;to&nbsp;update&nbsp;the&nbsp;best&nbsp;loss.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#lr_scheduler_plateau-step">step</a>(loss):&nbsp;Updates&nbsp;the&nbsp;learning&nbsp;rate&nbsp;based&nbsp;on&nbsp;the&nbsp;loss&nbsp;value.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="lr_scheduler_plateau-__init__"><strong>__init__</strong></a>(self, lr_scheduler, patience=5, threshold=0.01)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;scheduler&nbsp;with&nbsp;the&nbsp;given&nbsp;learning&nbsp;rate&nbsp;scheduler,&nbsp;patience,&nbsp;and&nbsp;threshold.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_scheduler&nbsp;(torch.optim.lr_scheduler):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;scheduler&nbsp;to&nbsp;be&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;patience&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;epochs&nbsp;to&nbsp;wait&nbsp;for&nbsp;improvement&nbsp;before&nbsp;taking&nbsp;action.&nbsp;Defaults&nbsp;to&nbsp;5.<br>
&nbsp;&nbsp;&nbsp;&nbsp;threshold&nbsp;(float,&nbsp;optional):&nbsp;Minimum&nbsp;change&nbsp;in&nbsp;the&nbsp;monitored&nbsp;value&nbsp;to&nbsp;qualify&nbsp;as&nbsp;an&nbsp;improvement.&nbsp;Defaults&nbsp;to&nbsp;0.01.</span></dd></dl>

<dl><dt><a name="lr_scheduler_plateau-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;a&nbsp;string&nbsp;representation&nbsp;of&nbsp;the&nbsp;scheduler.</span></dd></dl>

<dl><dt><a name="lr_scheduler_plateau-step"><strong>step</strong></a>(self, epoch, loss)</dt><dd><span class="code">Updates&nbsp;the&nbsp;learning&nbsp;rate&nbsp;based&nbsp;on&nbsp;the&nbsp;loss&nbsp;value.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;epoch&nbsp;(int):&nbsp;The&nbsp;current&nbsp;epoch&nbsp;number.<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss&nbsp;(float):&nbsp;The&nbsp;current&nbsp;loss&nbsp;value.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="lr_scheduler_step">class <strong>lr_scheduler_step</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>

<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#lr_scheduler_step">lr_scheduler_step</a>(optimizer,&nbsp;lr_decay=0.1,&nbsp;lr_decay_epoch=10)<br>
&nbsp;<br>
Learning&nbsp;rate&nbsp;scheduler&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
&nbsp;<br>
Reduces&nbsp;the&nbsp;learning&nbsp;rate&nbsp;by&nbsp;a&nbsp;factor&nbsp;of&nbsp;lr_decay&nbsp;every&nbsp;lr_decay_epoch&nbsp;epochs.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer&nbsp;(Optimizer):&nbsp;The&nbsp;optimizer&nbsp;to&nbsp;adjust&nbsp;the&nbsp;learning&nbsp;rate&nbsp;for.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_decay&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;factor&nbsp;to&nbsp;reduce&nbsp;the&nbsp;learning&nbsp;rate&nbsp;by.&nbsp;Defaults&nbsp;to&nbsp;0.1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_decay_epoch&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;number&nbsp;of&nbsp;epochs&nbsp;to&nbsp;wait&nbsp;before&nbsp;decaying&nbsp;the&nbsp;learning&nbsp;rate.&nbsp;Defaults&nbsp;to&nbsp;10<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="lr_scheduler_step-__init__"><strong>__init__</strong></a>(self, optimizer, lr_decay=0.1, lr_decay_epoch=10)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;scheduler&nbsp;with&nbsp;the&nbsp;given&nbsp;optimizer&nbsp;and&nbsp;learning&nbsp;rate&nbsp;decay&nbsp;parameters.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer&nbsp;(Optimizer):&nbsp;The&nbsp;optimizer&nbsp;whose&nbsp;learning&nbsp;rate&nbsp;will&nbsp;be&nbsp;scheduled.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_decay&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;factor&nbsp;by&nbsp;which&nbsp;the&nbsp;learning&nbsp;rate&nbsp;will&nbsp;be&nbsp;multiplied&nbsp;at&nbsp;each&nbsp;decay&nbsp;step.&nbsp;Default&nbsp;is&nbsp;0.1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_decay_epoch&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;number&nbsp;of&nbsp;epochs&nbsp;after&nbsp;which&nbsp;the&nbsp;learning&nbsp;rate&nbsp;will&nbsp;be&nbsp;decayed.&nbsp;Default&nbsp;is&nbsp;10.</span></dd></dl>

<dl><dt><a name="lr_scheduler_step-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;a&nbsp;string&nbsp;representation&nbsp;of&nbsp;the&nbsp;scheduler.</span></dd></dl>

<dl><dt><a name="lr_scheduler_step-reduce"><strong>reduce</strong></a>(self)</dt><dd><span class="code">Reduces&nbsp;the&nbsp;learning&nbsp;rate&nbsp;by&nbsp;the&nbsp;decay&nbsp;factor.</span></dd></dl>

<dl><dt><a name="lr_scheduler_step-step"><strong>step</strong></a>(self, epoch)</dt><dd><span class="code">Adjusts&nbsp;the&nbsp;learning&nbsp;rate&nbsp;based&nbsp;on&nbsp;the&nbsp;current&nbsp;epoch.&nbsp;Decays&nbsp;the&nbsp;learning&nbsp;rate&nbsp;by&nbsp;lr_decay&nbsp;every&nbsp;lr_decay_epoch&nbsp;epochs.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;epoch&nbsp;(int):&nbsp;The&nbsp;current&nbsp;epoch&nbsp;number.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table></td></tr></table><p>
<table class="section">
<tr class="decor functions-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Functions</strong></td></tr>

<tr><td class="decor functions-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><dl><dt><a name="-make_blobs"><strong>make_blobs</strong></a>(n_samples=100, n_features=2, centers=None, cluster_std=1.0, center_box=(-10.0, 10.0), shuffle=True, random_state=None)</dt><dd><span class="code">Generates&nbsp;isotropic&nbsp;Gaussian&nbsp;blobs&nbsp;for&nbsp;clustering.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_samples&nbsp;(int&nbsp;or&nbsp;array-like,&nbsp;optional):&nbsp;Total&nbsp;number&nbsp;of&nbsp;samples&nbsp;if&nbsp;int,&nbsp;or&nbsp;number&nbsp;of&nbsp;samples&nbsp;per&nbsp;cluster&nbsp;if&nbsp;array-like&nbsp;(default&nbsp;is&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_features&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;features&nbsp;(default&nbsp;is&nbsp;2).<br>
&nbsp;&nbsp;&nbsp;&nbsp;centers&nbsp;(int&nbsp;or&nbsp;array-like,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;centers&nbsp;to&nbsp;generate,&nbsp;or&nbsp;fixed&nbsp;center&nbsp;locations.&nbsp;If&nbsp;None,&nbsp;3&nbsp;centers&nbsp;are&nbsp;generated&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;cluster_std&nbsp;(float&nbsp;or&nbsp;array-like,&nbsp;optional):&nbsp;Standard&nbsp;deviation&nbsp;of&nbsp;the&nbsp;clusters&nbsp;(default&nbsp;is&nbsp;1.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;center_box&nbsp;(tuple&nbsp;of&nbsp;float,&nbsp;optional):&nbsp;Bounding&nbsp;box&nbsp;for&nbsp;each&nbsp;cluster&nbsp;center&nbsp;when&nbsp;centers&nbsp;are&nbsp;generated&nbsp;at&nbsp;random&nbsp;(default&nbsp;is&nbsp;(-10.0,&nbsp;10.0)).<br>
&nbsp;&nbsp;&nbsp;&nbsp;shuffle&nbsp;(bool,&nbsp;optional):&nbsp;Whether&nbsp;to&nbsp;shuffle&nbsp;the&nbsp;samples&nbsp;(default&nbsp;is&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int&nbsp;or&nbsp;None,&nbsp;optional):&nbsp;Random&nbsp;seed&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(np.ndarray):&nbsp;Generated&nbsp;samples&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(np.ndarray):&nbsp;Integer&nbsp;labels&nbsp;for&nbsp;cluster&nbsp;membership&nbsp;of&nbsp;each&nbsp;sample&nbsp;of&nbsp;shape&nbsp;(n_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;centers&nbsp;(np.ndarray):&nbsp;Centers&nbsp;of&nbsp;each&nbsp;cluster&nbsp;of&nbsp;shape&nbsp;(n_centers,&nbsp;n_features).</span></dd></dl>
 <dl><dt><a name="-make_classification"><strong>make_classification</strong></a>(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)</dt><dd><span class="code">Generates&nbsp;a&nbsp;random&nbsp;n-class&nbsp;classification&nbsp;problem.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_samples&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;samples&nbsp;(default&nbsp;is&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_features&nbsp;(int,&nbsp;optional):&nbsp;Total&nbsp;number&nbsp;of&nbsp;features&nbsp;(default&nbsp;is&nbsp;20).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_informative&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;informative&nbsp;features&nbsp;(default&nbsp;is&nbsp;2).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_redundant&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;redundant&nbsp;features&nbsp;(default&nbsp;is&nbsp;2).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_repeated&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;duplicated&nbsp;features&nbsp;(default&nbsp;is&nbsp;0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_classes&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;classes&nbsp;(default&nbsp;is&nbsp;2).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_clusters_per_class&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;clusters&nbsp;per&nbsp;class&nbsp;(default&nbsp;is&nbsp;2).<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights&nbsp;(array-like,&nbsp;optional):&nbsp;Proportions&nbsp;of&nbsp;samples&nbsp;assigned&nbsp;to&nbsp;each&nbsp;class&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;flip_y&nbsp;(float,&nbsp;optional):&nbsp;Fraction&nbsp;of&nbsp;samples&nbsp;whose&nbsp;class&nbsp;is&nbsp;randomly&nbsp;exchanged&nbsp;(default&nbsp;is&nbsp;0.01).<br>
&nbsp;&nbsp;&nbsp;&nbsp;class_sep&nbsp;(float,&nbsp;optional):&nbsp;Factor&nbsp;multiplying&nbsp;the&nbsp;hypercube&nbsp;size&nbsp;(default&nbsp;is&nbsp;1.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;hypercube&nbsp;(bool,&nbsp;optional):&nbsp;If&nbsp;True,&nbsp;clusters&nbsp;are&nbsp;placed&nbsp;on&nbsp;the&nbsp;vertices&nbsp;of&nbsp;a&nbsp;hypercube&nbsp;(default&nbsp;is&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;shift&nbsp;(float,&nbsp;optional):&nbsp;Shift&nbsp;features&nbsp;by&nbsp;the&nbsp;specified&nbsp;value&nbsp;(default&nbsp;is&nbsp;0.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;scale&nbsp;(float,&nbsp;optional):&nbsp;Multiply&nbsp;features&nbsp;by&nbsp;the&nbsp;specified&nbsp;value&nbsp;(default&nbsp;is&nbsp;1.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;shuffle&nbsp;(bool,&nbsp;optional):&nbsp;Shuffle&nbsp;the&nbsp;samples&nbsp;and&nbsp;features&nbsp;(default&nbsp;is&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int&nbsp;or&nbsp;None,&nbsp;optional):&nbsp;Random&nbsp;seed&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(np.ndarray):&nbsp;Generated&nbsp;samples&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(np.ndarray):&nbsp;Integer&nbsp;labels&nbsp;for&nbsp;class&nbsp;membership&nbsp;of&nbsp;each&nbsp;sample&nbsp;of&nbsp;shape&nbsp;(n_samples,).</span></dd></dl>
 <dl><dt><a name="-make_regression"><strong>make_regression</strong></a>(n_samples=100, n_features=100, n_informative=10, n_targets=1, bias=0.0, effective_rank=None, tail_strength=0.5, noise=0.0, shuffle=True, coef=False, random_state=None)</dt><dd><span class="code">Generates&nbsp;a&nbsp;random&nbsp;regression&nbsp;problem.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_samples&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;samples&nbsp;(default&nbsp;is&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_features&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;features&nbsp;(default&nbsp;is&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_informative&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;informative&nbsp;features&nbsp;used&nbsp;to&nbsp;build&nbsp;the&nbsp;linear&nbsp;model&nbsp;(default&nbsp;is&nbsp;10).<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_targets&nbsp;(int,&nbsp;optional):&nbsp;Number&nbsp;of&nbsp;regression&nbsp;targets&nbsp;(default&nbsp;is&nbsp;1).<br>
&nbsp;&nbsp;&nbsp;&nbsp;bias&nbsp;(float,&nbsp;optional):&nbsp;Bias&nbsp;term&nbsp;in&nbsp;the&nbsp;underlying&nbsp;linear&nbsp;model&nbsp;(default&nbsp;is&nbsp;0.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;effective_rank&nbsp;(int&nbsp;or&nbsp;None,&nbsp;optional):&nbsp;Approximate&nbsp;dimension&nbsp;of&nbsp;the&nbsp;data&nbsp;matrix&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;tail_strength&nbsp;(float,&nbsp;optional):&nbsp;Relative&nbsp;importance&nbsp;of&nbsp;the&nbsp;noisy&nbsp;tail&nbsp;of&nbsp;the&nbsp;singular&nbsp;values&nbsp;profile&nbsp;(default&nbsp;is&nbsp;0.5).<br>
&nbsp;&nbsp;&nbsp;&nbsp;noise&nbsp;(float,&nbsp;optional):&nbsp;Standard&nbsp;deviation&nbsp;of&nbsp;the&nbsp;Gaussian&nbsp;noise&nbsp;applied&nbsp;to&nbsp;the&nbsp;output&nbsp;(default&nbsp;is&nbsp;0.0).<br>
&nbsp;&nbsp;&nbsp;&nbsp;shuffle&nbsp;(bool,&nbsp;optional):&nbsp;Whether&nbsp;to&nbsp;shuffle&nbsp;the&nbsp;samples&nbsp;and&nbsp;features&nbsp;(default&nbsp;is&nbsp;True).<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef&nbsp;(bool,&nbsp;optional):&nbsp;If&nbsp;True,&nbsp;returns&nbsp;the&nbsp;coefficients&nbsp;of&nbsp;the&nbsp;underlying&nbsp;linear&nbsp;model&nbsp;(default&nbsp;is&nbsp;False).<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_state&nbsp;(int&nbsp;or&nbsp;None,&nbsp;optional):&nbsp;Random&nbsp;seed&nbsp;(default&nbsp;is&nbsp;None).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(np.ndarray):&nbsp;Input&nbsp;samples&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(np.ndarray):&nbsp;Output&nbsp;values&nbsp;of&nbsp;shape&nbsp;(n_samples,)&nbsp;or&nbsp;(n_samples,&nbsp;n_targets).<br>
&nbsp;&nbsp;&nbsp;&nbsp;coef&nbsp;(np.ndarray,&nbsp;optional):&nbsp;Coefficients&nbsp;of&nbsp;the&nbsp;underlying&nbsp;linear&nbsp;model&nbsp;of&nbsp;shape&nbsp;(n_features,)&nbsp;or&nbsp;(n_features,&nbsp;n_targets).&nbsp;Only&nbsp;returned&nbsp;if&nbsp;coef=True.</span></dd></dl>
 <dl><dt><a name="-make_sample_data"><strong>make_sample_data</strong></a>(n_samples, n_features, cov_class_1, cov_class_2, shift=None, seed=0)</dt><dd><span class="code">Generates&nbsp;sample&nbsp;data&nbsp;for&nbsp;testing&nbsp;LDA&nbsp;and&nbsp;QDA&nbsp;models.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_samples:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;samples&nbsp;per&nbsp;class.<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_features:&nbsp;(int)&nbsp;-&nbsp;Number&nbsp;of&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cov_class_1:&nbsp;(np.ndarray)&nbsp;-&nbsp;Covariance&nbsp;matrix&nbsp;for&nbsp;class&nbsp;1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cov_class_2:&nbsp;(np.ndarray)&nbsp;-&nbsp;Covariance&nbsp;matrix&nbsp;for&nbsp;class&nbsp;2.<br>
&nbsp;&nbsp;&nbsp;&nbsp;shift:&nbsp;(list),&nbsp;optional&nbsp;-&nbsp;Shift&nbsp;applied&nbsp;to&nbsp;class&nbsp;2&nbsp;data&nbsp;(default&nbsp;is&nbsp;[1,&nbsp;1]).<br>
&nbsp;&nbsp;&nbsp;&nbsp;seed:&nbsp;(int),&nbsp;optional&nbsp;-&nbsp;Random&nbsp;seed&nbsp;for&nbsp;reproducibility&nbsp;(default&nbsp;is&nbsp;0).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(np.ndarray)&nbsp;-&nbsp;Generated&nbsp;feature&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y:&nbsp;(np.ndarray)&nbsp;-&nbsp;Generated&nbsp;target&nbsp;labels.</span></dd></dl>
 <dl><dt><a name="-normalize"><strong>normalize</strong></a>(X, norm='l2')</dt><dd><span class="code">Normalizes&nbsp;the&nbsp;input&nbsp;data&nbsp;using&nbsp;the&nbsp;specified&nbsp;norm.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;input&nbsp;data&nbsp;to&nbsp;be&nbsp;normalized.<br>
&nbsp;&nbsp;&nbsp;&nbsp;norm:&nbsp;(str),&nbsp;optional&nbsp;-&nbsp;The&nbsp;type&nbsp;of&nbsp;norm&nbsp;to&nbsp;use&nbsp;for&nbsp;normalization&nbsp;(default&nbsp;is&nbsp;'l2').<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Options:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;'l2':&nbsp;L2&nbsp;normalization&nbsp;(Euclidean&nbsp;norm).<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;'l1':&nbsp;L1&nbsp;normalization&nbsp;(Manhattan&nbsp;norm).<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;'max':&nbsp;Max&nbsp;normalization&nbsp;(divides&nbsp;by&nbsp;the&nbsp;maximum&nbsp;absolute&nbsp;value).<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;'minmax':&nbsp;Min-max&nbsp;normalization&nbsp;(scales&nbsp;to&nbsp;[0,&nbsp;1]).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X:&nbsp;(numpy.ndarray)&nbsp;-&nbsp;The&nbsp;normalized&nbsp;data.</span></dd></dl>
 <dl><dt><a name="-one_hot_encode"><strong>one_hot_encode</strong></a>(y, num_classes)</dt><dd><span class="code">One-hot&nbsp;encode&nbsp;a&nbsp;vector&nbsp;of&nbsp;class&nbsp;labels.</span></dd></dl>
 <dl><dt><a name="-train_test_split"><strong>train_test_split</strong></a>(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)</dt><dd><span class="code">Split&nbsp;arrays&nbsp;or&nbsp;matrices&nbsp;into&nbsp;random&nbsp;train&nbsp;and&nbsp;test&nbsp;subsets.<br>
&nbsp;<br>
Parameters<br>
----------<br>
*arrays&nbsp;:&nbsp;sequence&nbsp;of&nbsp;arrays<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allowed&nbsp;inputs&nbsp;are&nbsp;lists,&nbsp;numpy&nbsp;arrays,&nbsp;scipy-sparse&nbsp;matrices&nbsp;or&nbsp;pandas&nbsp;DataFrames.<br>
&nbsp;<br>
test_size&nbsp;:&nbsp;float&nbsp;or&nbsp;int,&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;float,&nbsp;should&nbsp;be&nbsp;between&nbsp;0.0&nbsp;and&nbsp;1.0&nbsp;and&nbsp;represent&nbsp;the&nbsp;proportion<br>
&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;the&nbsp;dataset&nbsp;to&nbsp;include&nbsp;in&nbsp;the&nbsp;test&nbsp;split.&nbsp;If&nbsp;int,&nbsp;represents&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;absolute&nbsp;number&nbsp;of&nbsp;test&nbsp;samples.<br>
&nbsp;<br>
train_size&nbsp;:&nbsp;float&nbsp;or&nbsp;int,&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;float,&nbsp;should&nbsp;be&nbsp;between&nbsp;0.0&nbsp;and&nbsp;1.0&nbsp;and&nbsp;represent&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;proportion&nbsp;of&nbsp;the&nbsp;dataset&nbsp;to&nbsp;include&nbsp;in&nbsp;the&nbsp;train&nbsp;split.&nbsp;If&nbsp;int,<br>
&nbsp;&nbsp;&nbsp;&nbsp;represents&nbsp;the&nbsp;absolute&nbsp;number&nbsp;of&nbsp;train&nbsp;samples.&nbsp;If&nbsp;None,&nbsp;the&nbsp;value&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;automatically&nbsp;computed&nbsp;as&nbsp;the&nbsp;complement&nbsp;of&nbsp;the&nbsp;test&nbsp;size&nbsp;(unless&nbsp;both<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;None,&nbsp;in&nbsp;which&nbsp;case&nbsp;test_size&nbsp;defaults&nbsp;to&nbsp;0.25).<br>
&nbsp;<br>
random_state&nbsp;:&nbsp;int,&nbsp;RandomState&nbsp;instance&nbsp;or&nbsp;None,&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Controls&nbsp;the&nbsp;shuffling&nbsp;applied&nbsp;to&nbsp;the&nbsp;data&nbsp;before&nbsp;applying&nbsp;the&nbsp;split.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Pass&nbsp;an&nbsp;int&nbsp;for&nbsp;reproducible&nbsp;output&nbsp;across&nbsp;multiple&nbsp;function&nbsp;calls.<br>
&nbsp;<br>
shuffle&nbsp;:&nbsp;bool,&nbsp;default=True<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;shuffle&nbsp;the&nbsp;data&nbsp;before&nbsp;splitting.&nbsp;If&nbsp;shuffle=False<br>
&nbsp;&nbsp;&nbsp;&nbsp;then&nbsp;stratify&nbsp;must&nbsp;be&nbsp;None.<br>
&nbsp;<br>
stratify&nbsp;:&nbsp;array-like,&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;not&nbsp;None,&nbsp;data&nbsp;is&nbsp;split&nbsp;in&nbsp;a&nbsp;stratified&nbsp;fashion,&nbsp;using&nbsp;this&nbsp;as<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;class&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
-------<br>
splitting&nbsp;:&nbsp;list,&nbsp;length=2&nbsp;*&nbsp;len(arrays)<br>
&nbsp;&nbsp;&nbsp;&nbsp;List&nbsp;containing&nbsp;train-test&nbsp;split&nbsp;of&nbsp;inputs.</span></dd></dl>
</td></tr></table><p>
<table class="section">
<tr class="decor data-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Data</strong></td></tr>

<tr><td class="decor data-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><strong>__all__</strong> = ['PolynomialTransform', 'DataPrep', 'VotingRegressor', 'VotingClassifier', 'ModelSelectionUtility', 'GridSearchCV', 'RandomSearchCV', 'Metrics', 'PCA', 'SVD', 'RandomOverSampler', 'RandomUnderSampler', 'SMOTE', 'Augmenter', 'make_blobs', 'make_regression', 'make_classification', 'train_test_split', 'one_hot_encode', 'normalize', ...]</td></tr></table>
</body></html>
