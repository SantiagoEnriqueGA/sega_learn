<!DOCTYPE html>
<html lang="en">
<head>
<style>
body { background-color: #f0f0f8; }
table.heading tr { background-color: #7799ee; }
.decor { color: #ffffff; }
.title-decor { background-color: #ffc8d8; color: #000000; }
.pkg-content-decor { background-color: #aa55cc; }
.index-decor { background-color: #ee77aa; }
.functions-decor { background-color: #eeaa77; }
.data-decor { background-color: #55aa55; }
.author-decor { background-color: #7799ee; }
.credits-decor { background-color: #7799ee; }
.error-decor { background-color: #bb0000; }
.grey { color: #909090; }
.white { color: #ffffff; }
.repr { color: #c040c0; }
table.heading tr td.title, table.heading tr td.extra { vertical-align: bottom; }
table.heading tr td.extra { text-align: right; }
.heading-text { font-family: helvetica, arial; }
.bigsection { font-size: larger; }
.title { font-size: x-large; }
.code { font-family: monospace; }
table { width: 100%; border-spacing: 0; border-collapse: collapse; border: 0; }
td { padding: 2; }
td.section-title, td.multicolumn { vertical-align: bottom; }
td.multicolumn { width: 25%; }
td.singlecolumn { width: 100%; }
</style>
<meta charset="utf-8">
<title>Python: package sega_learn</title>
</head><body>

<table class="heading">
<tr class="heading-text decor">
<td class="title">&nbsp;<br><strong class="title">sega_learn</strong></td>
</tr></table>
    <p></p>
<p>
<table class="section">
<tr class="decor pkg-content-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Package Contents</strong></td></tr>
    
<tr><td class="decor pkg-content-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><table><tr><td class="multicolumn"><a href="sega_learn.clustering.html"><strong>clustering</strong>&nbsp;(package)</a><br>
<a href="sega_learn.linear_models.html"><strong>linear_models</strong>&nbsp;(package)</a><br>
</td><td class="multicolumn"><a href="sega_learn.neural_networks.html"><strong>neural_networks</strong>&nbsp;(package)</a><br>
<a href="sega_learn.trees.html"><strong>trees</strong>&nbsp;(package)</a><br>
</td><td class="multicolumn"><a href="sega_learn.utils.html"><strong>utils</strong>&nbsp;(package)</a><br>
</td><td class="multicolumn"></td></tr></table></td></tr></table><p>
<table class="section">
<tr class="decor index-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Classes</strong></td></tr>
    
<tr><td class="decor index-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><dl>
<dt class="heading-text"><a href="builtins.html#object">builtins.object</a>
</dt><dd>
<dl>
<dt class="heading-text"><a href="sega_learn.clustering.clustering.html#DBSCAN">sega_learn.clustering.clustering.DBSCAN</a>
</dt><dt class="heading-text"><a href="sega_learn.clustering.clustering.html#KMeans">sega_learn.clustering.clustering.KMeans</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.discriminantAnalysis.html#LinearDiscriminantAnalysis">sega_learn.linear_models.discriminantAnalysis.LinearDiscriminantAnalysis</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.discriminantAnalysis.html#QuadraticDiscriminantAnalysis">sega_learn.linear_models.discriminantAnalysis.QuadraticDiscriminantAnalysis</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.linearModels.html#Bayesian">sega_learn.linear_models.linearModels.Bayesian</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.linearModels.html#Lasso">sega_learn.linear_models.linearModels.Lasso</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.linearModels.html#OrdinaryLeastSquares">sega_learn.linear_models.linearModels.OrdinaryLeastSquares</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.linearModels.html#PassiveAggressiveRegressor">sega_learn.linear_models.linearModels.PassiveAggressiveRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.linearModels.html#RANSAC">sega_learn.linear_models.linearModels.RANSAC</a>
</dt><dt class="heading-text"><a href="sega_learn.linear_models.linearModels.html#Ridge">sega_learn.linear_models.linearModels.Ridge</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss.html#BCEWithLogitsLoss">sega_learn.neural_networks.loss.BCEWithLogitsLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.loss.html#CrossEntropyLoss">sega_learn.neural_networks.loss.CrossEntropyLoss</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.neuralNetwork.html#Activation">sega_learn.neural_networks.neuralNetwork.Activation</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.neuralNetwork.html#Layer">sega_learn.neural_networks.neuralNetwork.Layer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.neuralNetwork.html#NeuralNetwork">sega_learn.neural_networks.neuralNetwork.NeuralNetwork</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.optimizers.html#AdadeltaOptimizer">sega_learn.neural_networks.optimizers.AdadeltaOptimizer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.optimizers.html#AdamOptimizer">sega_learn.neural_networks.optimizers.AdamOptimizer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.optimizers.html#SGDOptimizer">sega_learn.neural_networks.optimizers.SGDOptimizer</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.schedulers.html#lr_scheduler_exp">sega_learn.neural_networks.schedulers.lr_scheduler_exp</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.schedulers.html#lr_scheduler_plateau">sega_learn.neural_networks.schedulers.lr_scheduler_plateau</a>
</dt><dt class="heading-text"><a href="sega_learn.neural_networks.schedulers.html#lr_scheduler_step">sega_learn.neural_networks.schedulers.lr_scheduler_step</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.gradientBoostedRegressor.html#GradientBoostedRegressor">sega_learn.trees.gradientBoostedRegressor.GradientBoostedRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.randomForestClassifier.html#RandomForestClassifier">sega_learn.trees.randomForestClassifier.RandomForestClassifier</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.randomForestRegressor.html#RandomForestRegressor">sega_learn.trees.randomForestRegressor.RandomForestRegressor</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeClassifier.html#ClassifierTree">sega_learn.trees.treeClassifier.ClassifierTree</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeRegressor.html#RegressorTree">sega_learn.trees.treeRegressor.RegressorTree</a>
</dt><dt class="heading-text"><a href="sega_learn.trees.treeRegressor.html#RegressorTreeUtility">sega_learn.trees.treeRegressor.RegressorTreeUtility</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.dataPrep.html#DataPrep">sega_learn.utils.dataPrep.DataPrep</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.metrics.html#Metrics">sega_learn.utils.metrics.Metrics</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.modelSelection.html#GridSearchCV">sega_learn.utils.modelSelection.GridSearchCV</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.modelSelection.html#ModelSelectionUtility">sega_learn.utils.modelSelection.ModelSelectionUtility</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.modelSelection.html#RandomSearchCV">sega_learn.utils.modelSelection.RandomSearchCV</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.polynomialTransform.html#PolynomialTransform">sega_learn.utils.polynomialTransform.PolynomialTransform</a>
</dt><dt class="heading-text"><a href="sega_learn.utils.voting.html#VotingRegressor">sega_learn.utils.voting.VotingRegressor</a>
</dt></dl>
</dd>
</dl>
 <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Activation">class <strong>Activation</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">This&nbsp;class&nbsp;contains&nbsp;various&nbsp;activation&nbsp;functions&nbsp;and&nbsp;their&nbsp;corresponding&nbsp;derivatives&nbsp;for&nbsp;use&nbsp;in&nbsp;neural&nbsp;networks.<br>
relu:&nbsp;Rectified&nbsp;Linear&nbsp;Unit&nbsp;activation&nbsp;function.&nbsp;Returns&nbsp;the&nbsp;input&nbsp;directly&nbsp;if&nbsp;it's&nbsp;positive,&nbsp;otherwise&nbsp;returns&nbsp;0.<br>
leaky_relu:&nbsp;Leaky&nbsp;ReLU&nbsp;activation&nbsp;function.&nbsp;A&nbsp;variant&nbsp;of&nbsp;ReLU&nbsp;that&nbsp;allows&nbsp;a&nbsp;small&nbsp;gradient&nbsp;when&nbsp;the&nbsp;input&nbsp;is&nbsp;negative.&nbsp;<br>
tanh:&nbsp;Hyperbolic&nbsp;tangent&nbsp;activation&nbsp;function.&nbsp;Maps&nbsp;input&nbsp;to&nbsp;range&nbsp;[-1,&nbsp;1].&nbsp;Commonly&nbsp;used&nbsp;for&nbsp;normalized&nbsp;input.<br>
sigmoid:&nbsp;Sigmoid&nbsp;activation&nbsp;function.&nbsp;Maps&nbsp;input&nbsp;to&nbsp;range&nbsp;[0,&nbsp;1].&nbsp;Commonly&nbsp;used&nbsp;for&nbsp;binary&nbsp;classification.<br>
softmax:&nbsp;Softmax&nbsp;activation&nbsp;function.&nbsp;Maps&nbsp;input&nbsp;into&nbsp;a&nbsp;probability&nbsp;distribution&nbsp;over&nbsp;multiple&nbsp;classes.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Static methods defined here:<br>
<dl><dt><a name="Activation-leaky_relu"><strong>leaky_relu</strong></a>(z, alpha=0.01)</dt><dd><span class="code">Leaky&nbsp;ReLU&nbsp;activation&nbsp;function:&nbsp;f(z)&nbsp;=&nbsp;z&nbsp;if&nbsp;z&nbsp;&gt;&nbsp;0,&nbsp;else&nbsp;alpha&nbsp;*&nbsp;z<br>
Allows&nbsp;a&nbsp;small,&nbsp;non-zero&nbsp;gradient&nbsp;when&nbsp;the&nbsp;input&nbsp;is&nbsp;negative&nbsp;to&nbsp;address&nbsp;the&nbsp;dying&nbsp;ReLU&nbsp;problem.</span></dd></dl>

<dl><dt><a name="Activation-leaky_relu_derivative"><strong>leaky_relu_derivative</strong></a>(z, alpha=0.01)</dt><dd><span class="code">Derivative&nbsp;of&nbsp;the&nbsp;Leaky&nbsp;ReLU&nbsp;function:&nbsp;f'(z)&nbsp;=&nbsp;1&nbsp;if&nbsp;z&nbsp;&gt;&nbsp;0,&nbsp;else&nbsp;alpha<br>
Returns&nbsp;1&nbsp;for&nbsp;positive&nbsp;input,&nbsp;and&nbsp;alpha&nbsp;for&nbsp;negative&nbsp;input.</span></dd></dl>

<dl><dt><a name="Activation-relu"><strong>relu</strong></a>(z)</dt><dd><span class="code">ReLU&nbsp;(Rectified&nbsp;Linear&nbsp;Unit)&nbsp;activation&nbsp;function:&nbsp;f(z)&nbsp;=&nbsp;max(0,&nbsp;z)<br>
Returns&nbsp;the&nbsp;input&nbsp;directly&nbsp;if&nbsp;it's&nbsp;positive,&nbsp;otherwise&nbsp;returns&nbsp;0.</span></dd></dl>

<dl><dt><a name="Activation-relu_derivative"><strong>relu_derivative</strong></a>(z)</dt><dd><span class="code">Derivative&nbsp;of&nbsp;the&nbsp;ReLU&nbsp;function:&nbsp;f'(z)&nbsp;=&nbsp;1&nbsp;if&nbsp;z&nbsp;&gt;&nbsp;0,&nbsp;else&nbsp;0<br>
Returns&nbsp;1&nbsp;for&nbsp;positive&nbsp;input,&nbsp;and&nbsp;0&nbsp;for&nbsp;negative&nbsp;input.</span></dd></dl>

<dl><dt><a name="Activation-sigmoid"><strong>sigmoid</strong></a>(z)</dt><dd><span class="code">Sigmoid&nbsp;activation&nbsp;function:&nbsp;f(z)&nbsp;=&nbsp;1&nbsp;/&nbsp;(1&nbsp;+&nbsp;exp(-z))<br>
Maps&nbsp;input&nbsp;to&nbsp;the&nbsp;range&nbsp;[0,&nbsp;1],&nbsp;commonly&nbsp;used&nbsp;for&nbsp;binary&nbsp;classification.</span></dd></dl>

<dl><dt><a name="Activation-sigmoid_derivative"><strong>sigmoid_derivative</strong></a>(z)</dt><dd><span class="code">Derivative&nbsp;of&nbsp;the&nbsp;sigmoid&nbsp;function:&nbsp;f'(z)&nbsp;=&nbsp;<a href="#Activation-sigmoid">sigmoid</a>(z)&nbsp;*&nbsp;(1&nbsp;-&nbsp;<a href="#Activation-sigmoid">sigmoid</a>(z))<br>
Used&nbsp;for&nbsp;backpropagation&nbsp;through&nbsp;the&nbsp;sigmoid&nbsp;activation.</span></dd></dl>

<dl><dt><a name="Activation-softmax"><strong>softmax</strong></a>(z)</dt><dd><span class="code">Softmax&nbsp;activation&nbsp;function:&nbsp;f(z)_i&nbsp;=&nbsp;exp(z_i)&nbsp;/&nbsp;sum(exp(z_j))&nbsp;for&nbsp;all&nbsp;j<br>
Maps&nbsp;input&nbsp;into&nbsp;a&nbsp;probability&nbsp;distribution&nbsp;over&nbsp;multiple&nbsp;classes.&nbsp;Used&nbsp;for&nbsp;multiclass&nbsp;classification.</span></dd></dl>

<dl><dt><a name="Activation-tanh"><strong>tanh</strong></a>(z)</dt><dd><span class="code">Hyperbolic&nbsp;tangent&nbsp;(tanh)&nbsp;activation&nbsp;function:&nbsp;f(z)&nbsp;=&nbsp;(exp(z)&nbsp;-&nbsp;exp(-z))&nbsp;/&nbsp;(exp(z)&nbsp;+&nbsp;exp(-z))<br>
Maps&nbsp;input&nbsp;to&nbsp;the&nbsp;range&nbsp;[-1,&nbsp;1],&nbsp;typically&nbsp;used&nbsp;for&nbsp;normalized&nbsp;input.</span></dd></dl>

<dl><dt><a name="Activation-tanh_derivative"><strong>tanh_derivative</strong></a>(z)</dt><dd><span class="code">Derivative&nbsp;of&nbsp;the&nbsp;tanh&nbsp;function:&nbsp;f'(z)&nbsp;=&nbsp;1&nbsp;-&nbsp;<a href="#Activation-tanh">tanh</a>(z)^2<br>
Used&nbsp;for&nbsp;backpropagation&nbsp;through&nbsp;the&nbsp;tanh&nbsp;activation.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="AdadeltaOptimizer">class <strong>AdadeltaOptimizer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#AdadeltaOptimizer">AdadeltaOptimizer</a>(learning_rate=1.0,&nbsp;rho=0.95,&nbsp;epsilon=1e-06,&nbsp;reg_lambda=0.0)<br>
&nbsp;<br>
Adadelta&nbsp;optimizer&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
Formula:&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;E[g^2]_t&nbsp;=&nbsp;rho&nbsp;*&nbsp;E[g^2]_{t-1}&nbsp;+&nbsp;(1&nbsp;-&nbsp;rho)&nbsp;*&nbsp;g^2<br>
&nbsp;&nbsp;&nbsp;&nbsp;Delta_x&nbsp;=&nbsp;-&nbsp;(sqrt(E[delta_x^2]_{t-1}&nbsp;+&nbsp;epsilon)&nbsp;/&nbsp;sqrt(E[g^2]_t&nbsp;+&nbsp;epsilon))&nbsp;*&nbsp;g<br>
&nbsp;&nbsp;&nbsp;&nbsp;E[delta_x^2]_t&nbsp;=&nbsp;rho&nbsp;*&nbsp;E[delta_x^2]_{t-1}&nbsp;+&nbsp;(1&nbsp;-&nbsp;rho)&nbsp;*&nbsp;Delta_x^2<br>
Derived&nbsp;from:&nbsp;<a href="https://arxiv.org/abs/1212.5701">https://arxiv.org/abs/1212.5701</a><br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;1.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;rho&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;decay&nbsp;rate.&nbsp;Defaults&nbsp;to&nbsp;0.95.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float,&nbsp;optional):&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero.&nbsp;Defaults&nbsp;to&nbsp;1e-6.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter.&nbsp;Defaults&nbsp;to&nbsp;0.0.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="AdadeltaOptimizer-__init__"><strong>__init__</strong></a>(self, learning_rate=1.0, rho=0.95, epsilon=1e-06, reg_lambda=0.0)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="AdadeltaOptimizer-initialize"><strong>initialize</strong></a>(self, layers)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;running&nbsp;averages&nbsp;for&nbsp;each&nbsp;layer's&nbsp;weights.<br>
Args:&nbsp;layers&nbsp;(list):&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
Returns:&nbsp;None</span></dd></dl>

<dl><dt><a name="AdadeltaOptimizer-update"><strong>update</strong></a>(self, layer, dW, db, index)</dt><dd><span class="code">Updates&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;a&nbsp;layer&nbsp;using&nbsp;the&nbsp;Adadelta&nbsp;optimization&nbsp;algorithm.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer&nbsp;(<a href="#Layer">Layer</a>):&nbsp;The&nbsp;layer&nbsp;to&nbsp;update.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dW&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;db&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;index&nbsp;(int):&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;layer.<br>
Returns:&nbsp;None</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="AdamOptimizer">class <strong>AdamOptimizer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#AdamOptimizer">AdamOptimizer</a>(learning_rate=0.001,&nbsp;beta1=0.9,&nbsp;beta2=0.999,&nbsp;epsilon=1e-08,&nbsp;reg_lambda=0.01)<br>
&nbsp;<br>
Adam&nbsp;optimizer&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
Formula:&nbsp;w&nbsp;=&nbsp;w&nbsp;-&nbsp;alpha&nbsp;*&nbsp;m_hat&nbsp;/&nbsp;(sqrt(v_hat)&nbsp;+&nbsp;epsilon)&nbsp;-&nbsp;lambda&nbsp;*&nbsp;w&nbsp;<br>
Derived&nbsp;from:&nbsp;<a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a><br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;0.001.<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta1&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;first&nbsp;moment&nbsp;estimates.&nbsp;Defaults&nbsp;to&nbsp;0.9.<br>
&nbsp;&nbsp;&nbsp;&nbsp;beta2&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;second&nbsp;moment&nbsp;estimates.&nbsp;Defaults&nbsp;to&nbsp;0.999.<br>
&nbsp;&nbsp;&nbsp;&nbsp;epsilon&nbsp;(float,&nbsp;optional):&nbsp;A&nbsp;small&nbsp;value&nbsp;to&nbsp;prevent&nbsp;division&nbsp;by&nbsp;zero.&nbsp;Defaults&nbsp;to&nbsp;1e-8.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter.&nbsp;Defaults&nbsp;to&nbsp;0.01.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="AdamOptimizer-__init__"><strong>__init__</strong></a>(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, reg_lambda=0.01)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="AdamOptimizer-initialize"><strong>initialize</strong></a>(self, layers)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;first&nbsp;and&nbsp;second&nbsp;moment&nbsp;estimates&nbsp;for&nbsp;each&nbsp;layer's&nbsp;weights.<br>
Args:&nbsp;layers&nbsp;(list):&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
Returns:&nbsp;None</span></dd></dl>

<dl><dt><a name="AdamOptimizer-update"><strong>update</strong></a>(self, layer, dW, db, index)</dt><dd><span class="code">Updates&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;a&nbsp;layer&nbsp;using&nbsp;the&nbsp;Adam&nbsp;optimization&nbsp;algorithm.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer&nbsp;(<a href="#Layer">Layer</a>):&nbsp;The&nbsp;layer&nbsp;to&nbsp;update.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dW&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;db&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;index&nbsp;(int):&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;layer.<br>
Returns:&nbsp;None</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="BCEWithLogitsLoss">class <strong>BCEWithLogitsLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss&nbsp;with&nbsp;logits&nbsp;implementation&nbsp;using&nbsp;numpy.<br>
Formula:&nbsp;-mean(y&nbsp;*&nbsp;log(p)&nbsp;+&nbsp;(1&nbsp;-&nbsp;y)&nbsp;*&nbsp;log(1&nbsp;-&nbsp;p))<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#BCEWithLogitsLoss-__call__">__call__</a>(self,&nbsp;logits,&nbsp;targets):&nbsp;Calculate&nbsp;the&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="BCEWithLogitsLoss-__call__"><strong>__call__</strong></a>(self, logits, targets)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;logits&nbsp;(np.ndarray):&nbsp;The&nbsp;logits&nbsp;(predicted&nbsp;values)&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;targets&nbsp;(np.ndarray):&nbsp;The&nbsp;target&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;binary&nbsp;cross&nbsp;entropy&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Bayesian">class <strong>Bayesian</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#Bayesian">Bayesian</a>(max_iter=300,&nbsp;tol=0.001,&nbsp;alpha_1=1e-06,&nbsp;alpha_2=1e-06,&nbsp;lambda_1=1e-06,&nbsp;lambda_2=1e-06,&nbsp;fit_intercept=None)<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;<a href="#Bayesian">Bayesian</a>&nbsp;Regression&nbsp;using&nbsp;Coordinate&nbsp;Descent.<br>
<a href="#Bayesian">Bayesian</a>&nbsp;regression&nbsp;implements&nbsp;both&nbsp;L1&nbsp;and&nbsp;L2&nbsp;regularization,&nbsp;which&nbsp;helps&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;a&nbsp;penalty&nbsp;term&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;max_iter:&nbsp;int,&nbsp;default=300<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;to&nbsp;perform.<br>
-&nbsp;tol:&nbsp;float,&nbsp;default=0.001<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;convergence&nbsp;threshold.&nbsp;The&nbsp;algorithm&nbsp;will&nbsp;stop&nbsp;if&nbsp;the&nbsp;coefficients&nbsp;change&nbsp;less&nbsp;than&nbsp;the&nbsp;threshold.<br>
-&nbsp;alpha_1:&nbsp;float,&nbsp;default=1e-06<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;shape&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;weights.<br>
-&nbsp;alpha_2:&nbsp;float,&nbsp;default=1e-06<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;scale&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;weights.<br>
-&nbsp;lambda_1:&nbsp;float,&nbsp;default=1e-06<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;shape&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;noise.<br>
-&nbsp;lambda_2:&nbsp;float,&nbsp;default=1e-06<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;scale&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;noise.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
-&nbsp;fit_intercept:&nbsp;bool,&nbsp;default=True<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
Attributes:<br>
-&nbsp;intercept_:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;intercept&nbsp;of&nbsp;the&nbsp;model.<br>
-&nbsp;coef_:&nbsp;ndarray&nbsp;of&nbsp;shape&nbsp;(n_features,)&nbsp;or&nbsp;(n_features&nbsp;+&nbsp;1,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;linear&nbsp;regression&nbsp;problem.&nbsp;If&nbsp;`fit_intercept`&nbsp;is&nbsp;True,&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;the&nbsp;intercept.<br>
-&nbsp;n_iter_:&nbsp;int&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;iterations&nbsp;performed.<br>
-&nbsp;alpha_:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;precision&nbsp;of&nbsp;the&nbsp;weights.<br>
-&nbsp;lambda_:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;precision&nbsp;of&nbsp;the&nbsp;noise.<br>
-&nbsp;sigma_:&nbsp;ndarray&nbsp;of&nbsp;shape&nbsp;(n_features,&nbsp;n_features)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;posterior&nbsp;covariance&nbsp;of&nbsp;the&nbsp;weights.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="Bayesian-__init__"><strong>__init__</strong></a>(self, max_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, fit_intercept=None)</dt><dd><span class="code">This&nbsp;class&nbsp;implements&nbsp;<a href="#Bayesian">Bayesian</a>&nbsp;Regression&nbsp;using&nbsp;Coordinate&nbsp;Descent.<br>
<a href="#Bayesian">Bayesian</a>&nbsp;regression&nbsp;implements&nbsp;both&nbsp;L1&nbsp;and&nbsp;L2&nbsp;regularization,&nbsp;which&nbsp;helps&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;a&nbsp;penalty&nbsp;term&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;max_iter:&nbsp;int,&nbsp;default=300<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;to&nbsp;perform.<br>
-&nbsp;tol:&nbsp;float,&nbsp;default=0.001<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;convergence&nbsp;threshold.&nbsp;The&nbsp;algorithm&nbsp;will&nbsp;stop&nbsp;if&nbsp;the&nbsp;coefficients&nbsp;change&nbsp;less&nbsp;than&nbsp;the&nbsp;threshold.<br>
-&nbsp;alpha_1:&nbsp;float,&nbsp;default=1e-06<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;shape&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;weights.<br>
-&nbsp;alpha_2:&nbsp;float,&nbsp;default=1e-06<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;scale&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;weights.<br>
-&nbsp;lambda_1:&nbsp;float,&nbsp;default=1e-06<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;shape&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;noise.<br>
-&nbsp;lambda_2:&nbsp;float,&nbsp;default=1e-06<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;scale&nbsp;parameter&nbsp;for&nbsp;the&nbsp;prior&nbsp;on&nbsp;the&nbsp;noise.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
-&nbsp;fit_intercept:&nbsp;bool,&nbsp;default=True<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model.</span></dd></dl>

<dl><dt><a name="Bayesian-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;str(self).</span></dd></dl>

<dl><dt><a name="Bayesian-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Training&nbsp;data.<br>
-&nbsp;y&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,)&nbsp;or&nbsp;(n_samples,&nbsp;n_targets):&nbsp;Target&nbsp;values.</span></dd></dl>

<dl><dt><a name="Bayesian-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Computes&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;formula&nbsp;:&nbsp;str:&nbsp;The&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="Bayesian-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model.&nbsp;Computes&nbsp;the&nbsp;dot&nbsp;product&nbsp;of&nbsp;X&nbsp;and&nbsp;the&nbsp;coefficients.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Samples.</span></dd></dl>

<dl><dt><a name="Bayesian-tune"><strong>tune</strong></a>(self, X, y, beta1=0.9, beta2=0.999, iter=1000)</dt><dd><span class="code">Automatically&nbsp;tune&nbsp;the&nbsp;hyperparameters&nbsp;alpha_1,&nbsp;alpha_2,&nbsp;lambda_1,&nbsp;lambda_2.<br>
Loops&nbsp;through&nbsp;the&nbsp;parameter&nbsp;space,&nbsp;and&nbsp;returns&nbsp;the&nbsp;best&nbsp;hyperparameters&nbsp;based&nbsp;on&nbsp;the&nbsp;mean&nbsp;squared&nbsp;error.<br>
Compues&nbsp;gradients&nbsp;using&nbsp;ADAM&nbsp;optimizer.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Training&nbsp;data.<br>
-&nbsp;y&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,)&nbsp;or&nbsp;(n_samples,&nbsp;n_targets):&nbsp;Target&nbsp;values.<br>
-&nbsp;beta1:&nbsp;float,&nbsp;default=0.9<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;first&nbsp;moment&nbsp;estimates.<br>
-&nbsp;beta2:&nbsp;float,&nbsp;default=0.999<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;exponential&nbsp;decay&nbsp;rate&nbsp;for&nbsp;the&nbsp;second&nbsp;moment&nbsp;estimates.<br>
-&nbsp;iter:&nbsp;int,&nbsp;default=1000<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;iterations&nbsp;to&nbsp;perform.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;best_alpha_1:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;best&nbsp;value&nbsp;of&nbsp;alpha_1.<br>
-&nbsp;best_alpha_2:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;best&nbsp;value&nbsp;of&nbsp;alpha_2.<br>
-&nbsp;best_lambda_1:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;best&nbsp;value&nbsp;of&nbsp;lambda_1.<br>
-&nbsp;best_lambda_2:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;best&nbsp;value&nbsp;of&nbsp;lambda_2.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="ClassifierTree">class <strong>ClassifierTree</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#ClassifierTree">ClassifierTree</a>(max_depth=5)<br>
&nbsp;<br>
A&nbsp;class&nbsp;representing&nbsp;a&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Methods:<br>
-&nbsp;<a href="#ClassifierTree-learn">learn</a>(X,&nbsp;y,&nbsp;par_node={},&nbsp;depth=0):&nbsp;Builds&nbsp;the&nbsp;decision&nbsp;tree&nbsp;based&nbsp;on&nbsp;the&nbsp;given&nbsp;training&nbsp;data.<br>
-&nbsp;<a href="#ClassifierTree-classify">classify</a>(record):&nbsp;Classifies&nbsp;a&nbsp;record&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="ClassifierTree-__init__"><strong>__init__</strong></a>(self, max_depth=5)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="ClassifierTree-classify"><strong>classify</strong></a>(self, record)</dt><dd><span class="code">Classifies&nbsp;a&nbsp;given&nbsp;record&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;record:&nbsp;A&nbsp;dictionary&nbsp;representing&nbsp;the&nbsp;record&nbsp;to&nbsp;be&nbsp;classified.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;The&nbsp;label&nbsp;assigned&nbsp;to&nbsp;the&nbsp;record&nbsp;based&nbsp;on&nbsp;the&nbsp;decision&nbsp;tree.</span></dd></dl>

<dl><dt><a name="ClassifierTree-learn"><strong>learn</strong></a>(self, X, y, par_node={}, depth=0)</dt><dd><span class="code">Builds&nbsp;the&nbsp;decision&nbsp;tree&nbsp;based&nbsp;on&nbsp;the&nbsp;given&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;features.<br>
-&nbsp;y&nbsp;(array-like):&nbsp;The&nbsp;target&nbsp;labels.<br>
-&nbsp;par_node&nbsp;(dict):&nbsp;The&nbsp;parent&nbsp;node&nbsp;of&nbsp;the&nbsp;current&nbsp;subtree&nbsp;(default:&nbsp;{}).<br>
-&nbsp;depth&nbsp;(int):&nbsp;The&nbsp;current&nbsp;depth&nbsp;of&nbsp;the&nbsp;subtree&nbsp;(default:&nbsp;0).<br>
&nbsp;<br>
Returns:<br>
-&nbsp;dict:&nbsp;The&nbsp;learned&nbsp;decision&nbsp;tree.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="CrossEntropyLoss">class <strong>CrossEntropyLoss</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Custom&nbsp;cross&nbsp;entropy&nbsp;loss&nbsp;implementation&nbsp;using&nbsp;numpy&nbsp;for&nbsp;multi-class&nbsp;classification.<br>
Formula:&nbsp;-sum(y&nbsp;*&nbsp;log(p)&nbsp;+&nbsp;(1&nbsp;-&nbsp;y)&nbsp;*&nbsp;log(1&nbsp;-&nbsp;p))&nbsp;/&nbsp;m<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#CrossEntropyLoss-__call__">__call__</a>(self,&nbsp;logits,&nbsp;targets):&nbsp;Calculate&nbsp;the&nbsp;cross&nbsp;entropy&nbsp;loss.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="CrossEntropyLoss-__call__"><strong>__call__</strong></a>(self, logits, targets)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;cross&nbsp;entropy&nbsp;loss.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;logits&nbsp;(np.ndarray):&nbsp;The&nbsp;logits&nbsp;(predicted&nbsp;values)&nbsp;of&nbsp;shape&nbsp;(num_samples,&nbsp;num_classes).<br>
&nbsp;&nbsp;&nbsp;&nbsp;targets&nbsp;(np.ndarray):&nbsp;The&nbsp;target&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(num_samples,&nbsp;num_classes).<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;float:&nbsp;The&nbsp;cross&nbsp;entropy&nbsp;loss.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="DBSCAN">class <strong>DBSCAN</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#DBSCAN">DBSCAN</a>(X,&nbsp;eps=0.5,&nbsp;min_samples=5)<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;the&nbsp;Density-Based&nbsp;Spatial&nbsp;Clustering&nbsp;of&nbsp;Applications&nbsp;with&nbsp;Noise&nbsp;(<a href="#DBSCAN">DBSCAN</a>)&nbsp;algorithm.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
-&nbsp;eps:&nbsp;The&nbsp;maximum&nbsp;distance&nbsp;between&nbsp;two&nbsp;samples&nbsp;for&nbsp;one&nbsp;to&nbsp;be&nbsp;considered&nbsp;as&nbsp;in&nbsp;the&nbsp;neighborhood&nbsp;of&nbsp;the&nbsp;other.<br>
-&nbsp;min_samples:&nbsp;The&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;a&nbsp;neighborhood&nbsp;for&nbsp;a&nbsp;point&nbsp;to&nbsp;be&nbsp;considered&nbsp;as&nbsp;a&nbsp;core&nbsp;point.<br>
&nbsp;<br>
Methods:<br>
-&nbsp;__init__:&nbsp;Initializes&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;<a href="builtins.html#object">object</a>&nbsp;with&nbsp;the&nbsp;input&nbsp;parameters.<br>
-&nbsp;fit:&nbsp;Fits&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;and&nbsp;assigns&nbsp;cluster&nbsp;labels.<br>
-&nbsp;predict:&nbsp;Predicts&nbsp;the&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;new&nbsp;data&nbsp;points.<br>
-&nbsp;fit_predict:&nbsp;Fits&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;model&nbsp;and&nbsp;returns&nbsp;cluster&nbsp;labels.<br>
-&nbsp;silhouette_score:&nbsp;Calculates&nbsp;the&nbsp;Silhouette&nbsp;Score&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
-&nbsp;_handle_categorical:&nbsp;Handles&nbsp;categorical&nbsp;columns&nbsp;by&nbsp;one-hot&nbsp;encoding.<br>
-&nbsp;_convert_to_ndarray:&nbsp;Converts&nbsp;input&nbsp;data&nbsp;to&nbsp;a&nbsp;NumPy&nbsp;ndarray&nbsp;and&nbsp;handles&nbsp;categorical&nbsp;columns.<br>
-&nbsp;_custom_distance_matrix:&nbsp;Calculates&nbsp;the&nbsp;pairwise&nbsp;distance&nbsp;matrix&nbsp;using&nbsp;a&nbsp;custom&nbsp;distance&nbsp;calculation&nbsp;method.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="DBSCAN-__init__"><strong>__init__</strong></a>(self, X, eps=0.5, min_samples=5)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
-&nbsp;eps:&nbsp;The&nbsp;maximum&nbsp;distance&nbsp;between&nbsp;two&nbsp;samples&nbsp;for&nbsp;one&nbsp;to&nbsp;be&nbsp;considered&nbsp;as&nbsp;in&nbsp;the&nbsp;neighborhood&nbsp;of&nbsp;the&nbsp;other.<br>
-&nbsp;min_samples:&nbsp;The&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;a&nbsp;neighborhood&nbsp;for&nbsp;a&nbsp;point&nbsp;to&nbsp;be&nbsp;considered&nbsp;as&nbsp;a&nbsp;core&nbsp;point.</span></dd></dl>

<dl><dt><a name="DBSCAN-auto_eps"><strong>auto_eps</strong></a>(self, min=0.1, max=1.1, precision=0.01, return_scores=False, verbose=False)</dt><dd><span class="code">Find&nbsp;the&nbsp;optimal&nbsp;eps&nbsp;value&nbsp;for&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;based&nbsp;on&nbsp;silhouette&nbsp;score.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;min:&nbsp;The&nbsp;minimum&nbsp;eps&nbsp;value&nbsp;to&nbsp;start&nbsp;the&nbsp;search.<br>
-&nbsp;max:&nbsp;The&nbsp;maximum&nbsp;eps&nbsp;value&nbsp;to&nbsp;end&nbsp;the&nbsp;search.<br>
-&nbsp;precision:&nbsp;The&nbsp;precision&nbsp;of&nbsp;the&nbsp;search.<br>
-&nbsp;return_scores:&nbsp;Whether&nbsp;to&nbsp;return&nbsp;a&nbsp;dictionary&nbsp;of&nbsp;(eps,&nbsp;score)&nbsp;pairs.<br>
-&nbsp;verbose:&nbsp;Whether&nbsp;to&nbsp;print&nbsp;the&nbsp;silhouette&nbsp;score&nbsp;for&nbsp;each&nbsp;eps&nbsp;value.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;eps:&nbsp;The&nbsp;optimal&nbsp;eps&nbsp;value.<br>
-&nbsp;scores_dict&nbsp;(optional):&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;(eps,&nbsp;score)&nbsp;pairs&nbsp;if&nbsp;return_scores&nbsp;is&nbsp;True.</span></dd></dl>

<dl><dt><a name="DBSCAN-fit"><strong>fit</strong></a>(self, metric='euclidean')</dt><dd><span class="code">Fit&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data.<br>
&nbsp;<br>
Algorithm&nbsp;Steps:<br>
1.&nbsp;Calculate&nbsp;the&nbsp;distance&nbsp;matrix&nbsp;between&nbsp;all&nbsp;points&nbsp;in&nbsp;the&nbsp;dataset.<br>
2.&nbsp;Identify&nbsp;core&nbsp;points&nbsp;based&nbsp;on&nbsp;the&nbsp;minimum&nbsp;number&nbsp;of&nbsp;neighbors&nbsp;within&nbsp;eps&nbsp;distance.<br>
3.&nbsp;Assign&nbsp;cluster&nbsp;labels&nbsp;using&nbsp;depth-first&nbsp;search&nbsp;(DFS)&nbsp;starting&nbsp;from&nbsp;core&nbsp;points.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;metric:&nbsp;The&nbsp;distance&nbsp;metric&nbsp;to&nbsp;use&nbsp;('euclidean',&nbsp;'manhattan',&nbsp;or&nbsp;'cosine').<br>
&nbsp;<br>
Returns:<br>
-&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;each&nbsp;data&nbsp;point.</span></dd></dl>

<dl><dt><a name="DBSCAN-fit_predict"><strong>fit_predict</strong></a>(self)</dt><dd><span class="code">Fit&nbsp;the&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;and&nbsp;return&nbsp;the&nbsp;cluster&nbsp;labels.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;the&nbsp;data.</span></dd></dl>

<dl><dt><a name="DBSCAN-predict"><strong>predict</strong></a>(self, new_X)</dt><dd><span class="code">Predict&nbsp;the&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;new&nbsp;data&nbsp;points.<br>
Note:&nbsp;<a href="#DBSCAN">DBSCAN</a>&nbsp;does&nbsp;not&nbsp;naturally&nbsp;support&nbsp;predicting&nbsp;new&nbsp;data&nbsp;points.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;new_X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;to&nbsp;predict&nbsp;(numpy&nbsp;array).<br>
&nbsp;<br>
Returns:<br>
-&nbsp;labels:&nbsp;The&nbsp;predicted&nbsp;cluster&nbsp;labels&nbsp;(-1&nbsp;for&nbsp;noise).</span></dd></dl>

<dl><dt><a name="DBSCAN-silhouette_score"><strong>silhouette_score</strong></a>(self)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;silhouette&nbsp;score&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;silhouette_score:&nbsp;The&nbsp;computed&nbsp;silhouette&nbsp;score.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="DataPrep">class <strong>DataPrep</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">A&nbsp;class&nbsp;for&nbsp;preparing&nbsp;data&nbsp;for&nbsp;machine&nbsp;learning&nbsp;models.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="DataPrep-df_to_ndarray"><strong>df_to_ndarray</strong></a>(df, y_col=0)</dt><dd><span class="code">Converts&nbsp;a&nbsp;DataFrame&nbsp;to&nbsp;a&nbsp;NumPy&nbsp;array.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;df&nbsp;(pandas.DataFrame):&nbsp;The&nbsp;DataFrame&nbsp;to&nbsp;be&nbsp;converted.<br>
-&nbsp;y_col&nbsp;(int):&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;label&nbsp;column.&nbsp;Default&nbsp;is&nbsp;0.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;X&nbsp;(numpy.ndarray):&nbsp;The&nbsp;feature&nbsp;columns&nbsp;as&nbsp;a&nbsp;NumPy&nbsp;array.<br>
-&nbsp;y&nbsp;(numpy.ndarray):&nbsp;The&nbsp;label&nbsp;column&nbsp;as&nbsp;a&nbsp;NumPy&nbsp;array.</span></dd></dl>

<dl><dt><a name="DataPrep-k_split"><strong>k_split</strong></a>(X, y, k=5)</dt><dd><span class="code">Splits&nbsp;the&nbsp;data&nbsp;into&nbsp;k&nbsp;folds&nbsp;for&nbsp;cross-validation.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;(numpy.ndarray):&nbsp;The&nbsp;feature&nbsp;columns.<br>
-&nbsp;y&nbsp;(numpy.ndarray):&nbsp;The&nbsp;label&nbsp;column.<br>
-&nbsp;k&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;folds.&nbsp;Default&nbsp;is&nbsp;5.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;X_folds&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;k&nbsp;folds&nbsp;of&nbsp;feature&nbsp;columns.<br>
-&nbsp;y_folds&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;k&nbsp;folds&nbsp;of&nbsp;label&nbsp;columns.</span></dd></dl>

<dl><dt><a name="DataPrep-one_hot_encode"><strong>one_hot_encode</strong></a>(df, cols)</dt><dd><span class="code">One-hot&nbsp;encodes&nbsp;non-numerical&nbsp;columns&nbsp;in&nbsp;a&nbsp;DataFrame.<br>
Drops&nbsp;the&nbsp;original&nbsp;columns&nbsp;after&nbsp;encoding.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;df&nbsp;(pandas.DataFrame):&nbsp;The&nbsp;DataFrame&nbsp;to&nbsp;be&nbsp;encoded.<br>
-&nbsp;cols&nbsp;(list):&nbsp;The&nbsp;list&nbsp;of&nbsp;column&nbsp;indices&nbsp;to&nbsp;be&nbsp;encoded.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;df&nbsp;(pandas.DataFrame):&nbsp;The&nbsp;DataFrame&nbsp;with&nbsp;one-hot&nbsp;encoded&nbsp;columns.</span></dd></dl>

<dl><dt><a name="DataPrep-prepare_data"><strong>prepare_data</strong></a>(csv_file, label_col_index, cols_to_encode=[], write_to_csv=True)</dt><dd><span class="code">Prepares&nbsp;the&nbsp;data&nbsp;by&nbsp;loading&nbsp;a&nbsp;CSV&nbsp;file,&nbsp;one-hot&nbsp;encoding&nbsp;non-numerical&nbsp;columns,<br>
and&nbsp;optionally&nbsp;writing&nbsp;the&nbsp;prepared&nbsp;data&nbsp;to&nbsp;a&nbsp;new&nbsp;CSV&nbsp;file.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;csv_file&nbsp;(str):&nbsp;The&nbsp;path&nbsp;of&nbsp;the&nbsp;CSV&nbsp;file&nbsp;to&nbsp;load.<br>
-&nbsp;label_col_index&nbsp;(int):&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;label&nbsp;column.<br>
-&nbsp;cols_to_encode&nbsp;(list):&nbsp;The&nbsp;list&nbsp;of&nbsp;column&nbsp;indices&nbsp;to&nbsp;one-hot&nbsp;encode.&nbsp;Default&nbsp;is&nbsp;an&nbsp;empty&nbsp;list.<br>
-&nbsp;write_to_csv&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;write&nbsp;the&nbsp;prepared&nbsp;data&nbsp;to&nbsp;a&nbsp;new&nbsp;CSV&nbsp;file.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;df&nbsp;(pandas.DataFrame):&nbsp;The&nbsp;prepared&nbsp;DataFrame.<br>
-&nbsp;prepared_csv_file&nbsp;(str):&nbsp;The&nbsp;path&nbsp;of&nbsp;the&nbsp;prepared&nbsp;CSV&nbsp;file.&nbsp;If&nbsp;write_to_csv&nbsp;is&nbsp;False,&nbsp;returns&nbsp;"N/A".</span></dd></dl>

<dl><dt><a name="DataPrep-write_data"><strong>write_data</strong></a>(df, csv_file, print_path=False)</dt><dd><span class="code">Writes&nbsp;the&nbsp;DataFrame&nbsp;to&nbsp;a&nbsp;CSV&nbsp;file.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;df&nbsp;(pandas.DataFrame):&nbsp;The&nbsp;DataFrame&nbsp;to&nbsp;be&nbsp;written.<br>
-&nbsp;csv_file&nbsp;(str):&nbsp;The&nbsp;path&nbsp;of&nbsp;the&nbsp;CSV&nbsp;file&nbsp;to&nbsp;write&nbsp;to.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="GradientBoostedRegressor">class <strong>GradientBoostedRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#GradientBoostedRegressor">GradientBoostedRegressor</a>(X=None,&nbsp;y=None,&nbsp;num_trees:&nbsp;int&nbsp;=&nbsp;10,&nbsp;max_depth:&nbsp;int&nbsp;=&nbsp;10,&nbsp;random_seed:&nbsp;int&nbsp;=&nbsp;0)<br>
&nbsp;<br>
A&nbsp;class&nbsp;to&nbsp;represent&nbsp;a&nbsp;Gradient&nbsp;Boosted&nbsp;Decision&nbsp;Tree&nbsp;Regressor.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int):&nbsp;The&nbsp;random&nbsp;seed&nbsp;for&nbsp;the&nbsp;random&nbsp;number&nbsp;generator.<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_trees&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;ensemble.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;decision&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;display&nbsp;(bool):&nbsp;A&nbsp;flag&nbsp;to&nbsp;display&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;input&nbsp;data&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;XX&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;input&nbsp;data&nbsp;features&nbsp;and&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;numerical_cols&nbsp;(set):&nbsp;A&nbsp;set&nbsp;of&nbsp;indices&nbsp;of&nbsp;numeric&nbsp;attributes&nbsp;(columns).<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-__init__">__init__</a>(file_loc,&nbsp;num_trees=5,&nbsp;random_seed=0,&nbsp;max_depth=10):&nbsp;Initializes&nbsp;the&nbsp;GBDT&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-reset">reset</a>():&nbsp;Resets&nbsp;the&nbsp;GBDT&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-fit">fit</a>():&nbsp;Fits&nbsp;the&nbsp;GBDT&nbsp;model&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-predict">predict</a>():&nbsp;Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#GradientBoostedRegressor-get_stats">get_stats</a>(y_predicted):&nbsp;Calculates&nbsp;various&nbsp;evaluation&nbsp;metrics&nbsp;for&nbsp;the&nbsp;predicted&nbsp;target&nbsp;values.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="GradientBoostedRegressor-__init__"><strong>__init__</strong></a>(self, X=None, y=None, num_trees: int = 10, max_depth: int = 10, random_seed: int = 0)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-fit"><strong>fit</strong></a>(self, X=None, y=None, stats=False)</dt><dd><span class="code">Fits&nbsp;the&nbsp;gradient&nbsp;boosted&nbsp;decision&nbsp;tree&nbsp;regressor&nbsp;to&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;<br>
This&nbsp;method&nbsp;trains&nbsp;the&nbsp;ensemble&nbsp;of&nbsp;decision&nbsp;trees&nbsp;by&nbsp;iteratively&nbsp;fitting&nbsp;each&nbsp;tree&nbsp;to&nbsp;the&nbsp;residuals<br>
of&nbsp;the&nbsp;previous&nbsp;iteration.&nbsp;The&nbsp;residuals&nbsp;are&nbsp;updated&nbsp;after&nbsp;each&nbsp;iteration&nbsp;by&nbsp;subtracting&nbsp;the&nbsp;predictions<br>
made&nbsp;by&nbsp;the&nbsp;current&nbsp;tree&nbsp;from&nbsp;the&nbsp;target&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(numpy.ndarray):&nbsp;An&nbsp;array&nbsp;of&nbsp;input&nbsp;data&nbsp;features.&nbsp;Default&nbsp;is&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(numpy.ndarray):&nbsp;An&nbsp;array&nbsp;of&nbsp;target&nbsp;values.&nbsp;Default&nbsp;is&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;stats&nbsp;(bool):&nbsp;A&nbsp;flag&nbsp;to&nbsp;decide&nbsp;whether&nbsp;to&nbsp;return&nbsp;stats&nbsp;or&nbsp;not.&nbsp;Default&nbsp;is&nbsp;False.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;None</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-get_stats"><strong>get_stats</strong></a>(self, y_predicted)</dt><dd><span class="code">Calculates&nbsp;various&nbsp;evaluation&nbsp;metrics&nbsp;for&nbsp;the&nbsp;predicted&nbsp;target&nbsp;values.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;y_predicted&nbsp;(numpy.ndarray):&nbsp;An&nbsp;array&nbsp;of&nbsp;predicted&nbsp;target&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;the&nbsp;evaluation&nbsp;metrics.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;MSE&nbsp;(float):&nbsp;Mean&nbsp;Squared&nbsp;Error<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;R^2&nbsp;(float):&nbsp;R-squared&nbsp;Score<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;MAPE&nbsp;(float):&nbsp;Mean&nbsp;Absolute&nbsp;Percentage&nbsp;Error<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;MAE&nbsp;(float):&nbsp;Mean&nbsp;Absolute&nbsp;Error<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;RMSE&nbsp;(float):&nbsp;Root&nbsp;Mean&nbsp;Squared&nbsp;Error</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-predict"><strong>predict</strong></a>(self, X=None)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;data&nbsp;using&nbsp;the&nbsp;gradient&nbsp;boosted&nbsp;decision&nbsp;tree&nbsp;regressor.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;(numpy.ndarray):&nbsp;An&nbsp;array&nbsp;of&nbsp;input&nbsp;data&nbsp;features.&nbsp;Default&nbsp;is&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;predictions&nbsp;(numpy.ndarray):&nbsp;An&nbsp;array&nbsp;of&nbsp;predicted&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;data.</span></dd></dl>

<dl><dt><a name="GradientBoostedRegressor-reset"><strong>reset</strong></a>(self)</dt></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="GridSearchCV">class <strong>GridSearchCV</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#GridSearchCV">GridSearchCV</a>(model,&nbsp;param_grid,&nbsp;cv=5,&nbsp;metric='mse',&nbsp;direction='minimize')<br>
&nbsp;<br>
Implements&nbsp;a&nbsp;grid&nbsp;search&nbsp;cross-validation&nbsp;for&nbsp;hyperparameter&nbsp;tuning.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="GridSearchCV-__init__"><strong>__init__</strong></a>(self, model, param_grid, cv=5, metric='mse', direction='minimize')</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#GridSearchCV">GridSearchCV</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;model:&nbsp;The&nbsp;model&nbsp;Object&nbsp;to&nbsp;be&nbsp;tuned.<br>
-&nbsp;param_grid&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;dictionaries&nbsp;containing&nbsp;hyperparameters&nbsp;to&nbsp;be&nbsp;tuned.<br>
-&nbsp;cv&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;folds&nbsp;for&nbsp;cross-validation.&nbsp;Default&nbsp;is&nbsp;5.<br>
-&nbsp;metric&nbsp;(str):&nbsp;The&nbsp;metric&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;evaluation.&nbsp;Default&nbsp;is&nbsp;'mse'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Regression&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'mse',&nbsp;'r2',&nbsp;'mae',&nbsp;'rmse',&nbsp;'mape',&nbsp;'mpe'<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Classification&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'accuracy',&nbsp;'precision',&nbsp;'recall',&nbsp;'f1',&nbsp;'log_loss'<br>
-&nbsp;direction&nbsp;(str):&nbsp;The&nbsp;direction&nbsp;to&nbsp;optimize&nbsp;the&nbsp;metric.&nbsp;Default&nbsp;is&nbsp;'minimize'.</span></dd></dl>

<dl><dt><a name="GridSearchCV-fit"><strong>fit</strong></a>(self, X, y, verbose=False)</dt><dd><span class="code">Fits&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;for&nbsp;all&nbsp;hyperparameter&nbsp;combinations.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;(numpy.ndarray):&nbsp;The&nbsp;feature&nbsp;columns.<br>
-&nbsp;y&nbsp;(numpy.ndarray):&nbsp;The&nbsp;label&nbsp;column.<br>
-&nbsp;verbose&nbsp;(bool):&nbsp;A&nbsp;flag&nbsp;to&nbsp;display&nbsp;the&nbsp;training&nbsp;progress.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;model:&nbsp;The&nbsp;best&nbsp;model&nbsp;with&nbsp;the&nbsp;optimal&nbsp;hyperparameters.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="KMeans">class <strong>KMeans</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#KMeans">KMeans</a>(X,&nbsp;n_clusters=3,&nbsp;max_iter=300,&nbsp;tol=0.0001)<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;the&nbsp;K-Means&nbsp;clustering&nbsp;algorithm&nbsp;along&nbsp;with&nbsp;methods&nbsp;for&nbsp;evaluating&nbsp;the&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;<br>
and&nbsp;visualizing&nbsp;the&nbsp;clustering&nbsp;results.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
-&nbsp;n_clusters:&nbsp;The&nbsp;number&nbsp;of&nbsp;clusters.<br>
-&nbsp;max_iter:&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations.<br>
-&nbsp;tol:&nbsp;The&nbsp;tolerance&nbsp;to&nbsp;declare&nbsp;convergence.<br>
&nbsp;<br>
Methods:<br>
-&nbsp;__init__:&nbsp;Initializes&nbsp;the&nbsp;<a href="#KMeans">KMeans</a>&nbsp;<a href="builtins.html#object">object</a>&nbsp;with&nbsp;parameters&nbsp;such&nbsp;as&nbsp;the&nbsp;data&nbsp;matrix,&nbsp;number&nbsp;of&nbsp;clusters,&nbsp;maximum&nbsp;iterations,&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;convergence&nbsp;tolerance.<br>
-&nbsp;_handle_categorical:&nbsp;Handles&nbsp;categorical&nbsp;columns&nbsp;in&nbsp;the&nbsp;input&nbsp;data&nbsp;by&nbsp;one-hot&nbsp;encoding.<br>
-&nbsp;_convert_to_ndarray:&nbsp;Converts&nbsp;input&nbsp;data&nbsp;to&nbsp;a&nbsp;NumPy&nbsp;ndarray&nbsp;and&nbsp;handles&nbsp;categorical&nbsp;columns.<br>
-&nbsp;initialize_centroids:&nbsp;Randomly&nbsp;initializes&nbsp;the&nbsp;centroids&nbsp;for&nbsp;<a href="#KMeans">KMeans</a>&nbsp;clustering.<br>
-&nbsp;assign_clusters:&nbsp;Assigns&nbsp;clusters&nbsp;based&nbsp;on&nbsp;the&nbsp;nearest&nbsp;centroid.<br>
-&nbsp;update_centroids:&nbsp;Updates&nbsp;centroids&nbsp;based&nbsp;on&nbsp;the&nbsp;current&nbsp;cluster&nbsp;assignments.<br>
-&nbsp;fit:&nbsp;Fits&nbsp;the&nbsp;<a href="#KMeans">KMeans</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;by&nbsp;iteratively&nbsp;updating&nbsp;centroids&nbsp;and&nbsp;cluster&nbsp;assignments&nbsp;until&nbsp;convergence.<br>
-&nbsp;predict:&nbsp;Predicts&nbsp;the&nbsp;closest&nbsp;cluster&nbsp;each&nbsp;sample&nbsp;in&nbsp;new_X&nbsp;belongs&nbsp;to.<br>
-&nbsp;elbow_method:&nbsp;Implements&nbsp;the&nbsp;elbow&nbsp;method&nbsp;to&nbsp;determine&nbsp;the&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters.<br>
-&nbsp;calinski_harabasz_index:&nbsp;Calculates&nbsp;the&nbsp;Calinski-Harabasz&nbsp;Index&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
-&nbsp;davies_bouldin_index:&nbsp;Calculates&nbsp;the&nbsp;Davies-Bouldin&nbsp;Index&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
-&nbsp;silhouette_score:&nbsp;Calculates&nbsp;the&nbsp;Silhouette&nbsp;Score&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
-&nbsp;find_optimal_clusters:&nbsp;Implements&nbsp;methods&nbsp;to&nbsp;find&nbsp;the&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;using&nbsp;the&nbsp;elbow&nbsp;method,&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Calinski-Harabasz&nbsp;Index,&nbsp;Davies-Bouldin&nbsp;Index,&nbsp;and&nbsp;Silhouette&nbsp;Score.&nbsp;It&nbsp;also&nbsp;plots&nbsp;the&nbsp;evaluation&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;metrics&nbsp;to&nbsp;aid&nbsp;in&nbsp;determining&nbsp;the&nbsp;optimal&nbsp;k&nbsp;value.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="KMeans-__init__"><strong>__init__</strong></a>(self, X, n_clusters=3, max_iter=300, tol=0.0001)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#KMeans">KMeans</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array,&nbsp;pandas&nbsp;DataFrame,&nbsp;or&nbsp;list).<br>
-&nbsp;n_clusters:&nbsp;The&nbsp;number&nbsp;of&nbsp;clusters.<br>
-&nbsp;max_iter:&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;iterations.<br>
-&nbsp;tol:&nbsp;The&nbsp;tolerance&nbsp;to&nbsp;declare&nbsp;convergence.</span></dd></dl>

<dl><dt><a name="KMeans-assign_clusters"><strong>assign_clusters</strong></a>(self, centroids)</dt><dd><span class="code">Assign&nbsp;clusters&nbsp;based&nbsp;on&nbsp;the&nbsp;nearest&nbsp;centroid.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;centroids:&nbsp;The&nbsp;current&nbsp;centroids.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;assignments&nbsp;for&nbsp;each&nbsp;data&nbsp;point.</span></dd></dl>

<dl><dt><a name="KMeans-calinski_harabasz_index"><strong>calinski_harabasz_index</strong></a>(self, X, labels, centroids)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;Calinski-Harabasz&nbsp;Index&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
-&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;each&nbsp;data&nbsp;point.<br>
-&nbsp;centroids:&nbsp;The&nbsp;centroids&nbsp;of&nbsp;the&nbsp;clusters.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;ch_index:&nbsp;The&nbsp;computed&nbsp;Calinski-Harabasz&nbsp;Index.</span></dd></dl>

<dl><dt><a name="KMeans-davies_bouldin_index"><strong>davies_bouldin_index</strong></a>(self, X, labels, centroids)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;Davies-Bouldin&nbsp;Index&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
-&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;each&nbsp;data&nbsp;point.<br>
-&nbsp;centroids:&nbsp;The&nbsp;centroids&nbsp;of&nbsp;the&nbsp;clusters.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;db_index:&nbsp;The&nbsp;computed&nbsp;Davies-Bouldin&nbsp;Index.</span></dd></dl>

<dl><dt><a name="KMeans-elbow_method"><strong>elbow_method</strong></a>(self, max_k=10)</dt><dd><span class="code">Implement&nbsp;the&nbsp;elbow&nbsp;method&nbsp;to&nbsp;determine&nbsp;the&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;max_k:&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;clusters&nbsp;to&nbsp;test.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;distortions:&nbsp;A&nbsp;list&nbsp;of&nbsp;distortions&nbsp;for&nbsp;each&nbsp;k.</span></dd></dl>

<dl><dt><a name="KMeans-find_optimal_clusters"><strong>find_optimal_clusters</strong></a>(self, max_k=10, true_k=None, save_dir=None)</dt><dd><span class="code">Find&nbsp;the&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;using&nbsp;various&nbsp;evaluation&nbsp;metrics&nbsp;and&nbsp;plot&nbsp;the&nbsp;results.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
-&nbsp;max_k:&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;clusters&nbsp;to&nbsp;consider.<br>
-&nbsp;true_k:&nbsp;The&nbsp;true&nbsp;number&nbsp;of&nbsp;clusters&nbsp;in&nbsp;the&nbsp;data.<br>
-&nbsp;save_dir:&nbsp;The&nbsp;directory&nbsp;to&nbsp;save&nbsp;the&nbsp;plot&nbsp;(optional).<br>
&nbsp;<br>
Returns:<br>
-&nbsp;ch_optimal_k:&nbsp;The&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;based&nbsp;on&nbsp;the&nbsp;Calinski-Harabasz&nbsp;Index.<br>
-&nbsp;db_optimal_k:&nbsp;The&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;based&nbsp;on&nbsp;the&nbsp;Davies-Bouldin&nbsp;Index.<br>
-&nbsp;silhouette_optimal_k:&nbsp;The&nbsp;optimal&nbsp;number&nbsp;of&nbsp;clusters&nbsp;based&nbsp;on&nbsp;the&nbsp;Silhouette&nbsp;Score.</span></dd></dl>

<dl><dt><a name="KMeans-fit"><strong>fit</strong></a>(self)</dt><dd><span class="code">Fit&nbsp;the&nbsp;<a href="#KMeans">KMeans</a>&nbsp;model&nbsp;to&nbsp;the&nbsp;data.</span></dd></dl>

<dl><dt><a name="KMeans-initialize_centroids"><strong>initialize_centroids</strong></a>(self)</dt><dd><span class="code">Randomly&nbsp;initialize&nbsp;the&nbsp;centroids.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;centroids:&nbsp;The&nbsp;initialized&nbsp;centroids.</span></dd></dl>

<dl><dt><a name="KMeans-predict"><strong>predict</strong></a>(self, new_X)</dt><dd><span class="code">Predict&nbsp;the&nbsp;closest&nbsp;cluster&nbsp;each&nbsp;sample&nbsp;in&nbsp;new_X&nbsp;belongs&nbsp;to.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;new_X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;to&nbsp;predict&nbsp;(numpy&nbsp;array).<br>
&nbsp;<br>
Returns:<br>
-&nbsp;labels:&nbsp;The&nbsp;predicted&nbsp;cluster&nbsp;labels.</span></dd></dl>

<dl><dt><a name="KMeans-silhouette_score"><strong>silhouette_score</strong></a>(self, X, labels)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;silhouette&nbsp;score&nbsp;for&nbsp;evaluating&nbsp;clustering&nbsp;performance.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X:&nbsp;The&nbsp;data&nbsp;matrix&nbsp;(numpy&nbsp;array).<br>
-&nbsp;labels:&nbsp;The&nbsp;cluster&nbsp;labels&nbsp;for&nbsp;each&nbsp;data&nbsp;point.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;silhouette_score:&nbsp;The&nbsp;computed&nbsp;silhouette&nbsp;score.</span></dd></dl>

<dl><dt><a name="KMeans-update_centroids"><strong>update_centroids</strong></a>(self)</dt><dd><span class="code">Update&nbsp;the&nbsp;centroids&nbsp;based&nbsp;on&nbsp;the&nbsp;current&nbsp;cluster&nbsp;assignments.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;centroids:&nbsp;The&nbsp;updated&nbsp;centroids.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Lasso">class <strong>Lasso</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#Lasso">Lasso</a>(alpha=1.0,&nbsp;fit_intercept=True,&nbsp;max_iter=10000,&nbsp;tol=0.0001)<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;<a href="#Lasso">Lasso</a>&nbsp;Regression&nbsp;using&nbsp;Coordinate&nbsp;Descent.<br>
<a href="#Lasso">Lasso</a>&nbsp;regression&nbsp;implements&nbsp;L1&nbsp;regularization,&nbsp;which&nbsp;helps&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;a&nbsp;penalty&nbsp;term&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;alpha&nbsp;:&nbsp;float,&nbsp;default=1.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;Regularization&nbsp;strength;&nbsp;must&nbsp;be&nbsp;a&nbsp;positive&nbsp;float.&nbsp;Regularization&nbsp;improves&nbsp;the&nbsp;conditioning&nbsp;of&nbsp;the&nbsp;problem&nbsp;and&nbsp;reduces&nbsp;the&nbsp;variance&nbsp;of&nbsp;the&nbsp;estimates.<br>
-&nbsp;fit_intercept&nbsp;:&nbsp;bool,&nbsp;default=True<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model.<br>
-&nbsp;max_iter&nbsp;:&nbsp;int,&nbsp;default=10000<br>
&nbsp;&nbsp;&nbsp;&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;the&nbsp;coordinate&nbsp;descent&nbsp;solver.<br>
-&nbsp;tol&nbsp;:&nbsp;float,&nbsp;default=1e-4<br>
&nbsp;&nbsp;&nbsp;&nbsp;Tolerance&nbsp;for&nbsp;the&nbsp;optimization.&nbsp;The&nbsp;optimization&nbsp;stops&nbsp;when&nbsp;the&nbsp;change&nbsp;in&nbsp;the&nbsp;coefficients&nbsp;is&nbsp;less&nbsp;than&nbsp;this&nbsp;tolerance.<br>
&nbsp;<br>
Attributes:<br>
-&nbsp;coef_&nbsp;:&nbsp;ndarray&nbsp;of&nbsp;shape&nbsp;(n_features,)&nbsp;or&nbsp;(n_features&nbsp;+&nbsp;1,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;linear&nbsp;regression&nbsp;problem.&nbsp;If&nbsp;`fit_intercept`&nbsp;is&nbsp;True,&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;the&nbsp;intercept.<br>
-&nbsp;intercept_&nbsp;:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;Independent&nbsp;term&nbsp;in&nbsp;the&nbsp;linear&nbsp;model.&nbsp;Set&nbsp;to&nbsp;0.0&nbsp;if&nbsp;`fit_intercept`&nbsp;is&nbsp;False.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="Lasso-__init__"><strong>__init__</strong></a>(self, alpha=1.0, fit_intercept=True, max_iter=10000, tol=0.0001)</dt><dd><span class="code">This&nbsp;class&nbsp;implements&nbsp;<a href="#Lasso">Lasso</a>&nbsp;Regression&nbsp;using&nbsp;Coordinate&nbsp;Descent.<br>
<a href="#Lasso">Lasso</a>&nbsp;regression&nbsp;implements&nbsp;L1&nbsp;regularization,&nbsp;which&nbsp;helps&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;a&nbsp;penalty&nbsp;term&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;alpha&nbsp;:&nbsp;float,&nbsp;default=1.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;Regularization&nbsp;strength;&nbsp;must&nbsp;be&nbsp;a&nbsp;positive&nbsp;float.&nbsp;Regularization&nbsp;improves&nbsp;the&nbsp;conditioning&nbsp;of&nbsp;the&nbsp;problem&nbsp;and&nbsp;reduces&nbsp;the&nbsp;variance&nbsp;of&nbsp;the&nbsp;estimates.<br>
-&nbsp;fit_intercept&nbsp;:&nbsp;bool,&nbsp;default=True<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model.<br>
-&nbsp;max_iter&nbsp;:&nbsp;int,&nbsp;default=10000<br>
&nbsp;&nbsp;&nbsp;&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;the&nbsp;coordinate&nbsp;descent&nbsp;solver.<br>
-&nbsp;tol&nbsp;:&nbsp;float,&nbsp;default=1e-4<br>
&nbsp;&nbsp;&nbsp;&nbsp;Tolerance&nbsp;for&nbsp;the&nbsp;optimization.&nbsp;The&nbsp;optimization&nbsp;stops&nbsp;when&nbsp;the&nbsp;change&nbsp;in&nbsp;the&nbsp;coefficients&nbsp;is&nbsp;less&nbsp;than&nbsp;this&nbsp;tolerance.</span></dd></dl>

<dl><dt><a name="Lasso-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;str(self).</span></dd></dl>

<dl><dt><a name="Lasso-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;using&nbsp;coordinate&nbsp;descent.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Training&nbsp;data.<br>
-&nbsp;y&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,)&nbsp;or&nbsp;(n_samples,&nbsp;n_targets):&nbsp;Target&nbsp;values.</span></dd></dl>

<dl><dt><a name="Lasso-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Computes&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;formula&nbsp;:&nbsp;str:&nbsp;The&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="Lasso-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Samples.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Layer">class <strong>Layer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#Layer">Layer</a>(input_size,&nbsp;output_size,&nbsp;activation='relu')<br>
&nbsp;<br>
Initializes&nbsp;a&nbsp;<a href="#Layer">Layer</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_size&nbsp;(int):&nbsp;The&nbsp;size&nbsp;of&nbsp;the&nbsp;input&nbsp;to&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_size&nbsp;(int):&nbsp;The&nbsp;size&nbsp;of&nbsp;the&nbsp;output&nbsp;from&nbsp;the&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;activation&nbsp;(str):&nbsp;The&nbsp;activation&nbsp;function&nbsp;to&nbsp;be&nbsp;used&nbsp;in&nbsp;the&nbsp;layer.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="Layer-__init__"><strong>__init__</strong></a>(self, input_size, output_size, activation='relu')</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="Layer-activate"><strong>activate</strong></a>(self, Z)</dt><dd><span class="code">Apply&nbsp;the&nbsp;activation&nbsp;function&nbsp;based&nbsp;on&nbsp;the&nbsp;layer's&nbsp;configuration.</span></dd></dl>

<dl><dt><a name="Layer-activation_derivative"><strong>activation_derivative</strong></a>(self, Z)</dt><dd><span class="code">Apply&nbsp;the&nbsp;derivative&nbsp;of&nbsp;the&nbsp;activation&nbsp;function&nbsp;for&nbsp;backpropagation.</span></dd></dl>

<dl><dt><a name="Layer-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><span class="code">Reset&nbsp;the&nbsp;gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;to&nbsp;zero.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="LinearDiscriminantAnalysis">class <strong>LinearDiscriminantAnalysis</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#LinearDiscriminantAnalysis">LinearDiscriminantAnalysis</a>(solver='svd',&nbsp;priors=None)<br>
&nbsp;<br>
Implements&nbsp;Linear&nbsp;Discriminant&nbsp;Analysis.<br>
A&nbsp;classifier&nbsp;with&nbsp;a&nbsp;linear&nbsp;decision&nbsp;boundary,&nbsp;generated&nbsp;by&nbsp;fitting&nbsp;class&nbsp;conditional&nbsp;densities&nbsp;to&nbsp;the&nbsp;data&nbsp;and&nbsp;using&nbsp;Bayes'&nbsp;rule.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;solver&nbsp;:&nbsp;{'svd',&nbsp;'lsqr',&nbsp;'eigen'},&nbsp;default='svd'<br>
&nbsp;&nbsp;&nbsp;&nbsp;Solver&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;LDA.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'svd'&nbsp;is&nbsp;the&nbsp;default&nbsp;and&nbsp;recommended&nbsp;solver.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'lsqr'&nbsp;is&nbsp;a&nbsp;faster&nbsp;alternative&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;when&nbsp;the&nbsp;number&nbsp;of&nbsp;features&nbsp;is&nbsp;large.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'eigen'&nbsp;is&nbsp;an&nbsp;alternative&nbsp;solver&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;when&nbsp;the&nbsp;number&nbsp;of&nbsp;features&nbsp;is&nbsp;small.<br>
-&nbsp;priors&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_classes,),&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Prior&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;classes.&nbsp;If&nbsp;None,&nbsp;the&nbsp;priors&nbsp;are&nbsp;uniform.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="LinearDiscriminantAnalysis-__init__"><strong>__init__</strong></a>(self, solver='svd', priors=None)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;Linear&nbsp;Discriminant&nbsp;Analysis&nbsp;model&nbsp;with&nbsp;the&nbsp;specified&nbsp;solver&nbsp;and&nbsp;prior&nbsp;probabilities.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;solver&nbsp;:&nbsp;{'svd',&nbsp;'lsqr',&nbsp;'eigen'},&nbsp;default='svd'<br>
&nbsp;&nbsp;&nbsp;&nbsp;Solver&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;LDA.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'svd'&nbsp;is&nbsp;the&nbsp;default&nbsp;and&nbsp;recommended&nbsp;solver.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'lsqr'&nbsp;is&nbsp;a&nbsp;faster&nbsp;alternative&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;when&nbsp;the&nbsp;number&nbsp;of&nbsp;features&nbsp;is&nbsp;large.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'eigen'&nbsp;is&nbsp;an&nbsp;alternative&nbsp;solver&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;when&nbsp;the&nbsp;number&nbsp;of&nbsp;features&nbsp;is&nbsp;small.<br>
-&nbsp;priors&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_classes,),&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Prior&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;classes.&nbsp;If&nbsp;None,&nbsp;the&nbsp;priors&nbsp;are&nbsp;uniform.</span></dd></dl>

<dl><dt><a name="LinearDiscriminantAnalysis-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Apply&nbsp;decision&nbsp;function&nbsp;to&nbsp;an&nbsp;array&nbsp;of&nbsp;samples.&nbsp;<br>
The&nbsp;decision&nbsp;function&nbsp;is&nbsp;the&nbsp;log-likelihood&nbsp;of&nbsp;each&nbsp;class.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Test&nbsp;data,&nbsp;where&nbsp;n_samples&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;and&nbsp;n_features&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;array,&nbsp;shape&nbsp;(n_samples,&nbsp;n_classes):&nbsp;Log-likelihood&nbsp;of&nbsp;each&nbsp;class&nbsp;for&nbsp;the&nbsp;input&nbsp;samples.</span></dd></dl>

<dl><dt><a name="LinearDiscriminantAnalysis-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;according&nbsp;to&nbsp;the&nbsp;given&nbsp;training&nbsp;data.<br>
This&nbsp;method&nbsp;computes&nbsp;the&nbsp;mean&nbsp;and&nbsp;covariance&nbsp;of&nbsp;each&nbsp;class,&nbsp;and&nbsp;the&nbsp;prior&nbsp;probabilities&nbsp;of&nbsp;each&nbsp;class.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Training&nbsp;data,&nbsp;where&nbsp;n_samples&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;and&nbsp;n_features&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;features.<br>
-&nbsp;y&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,):&nbsp;Target&nbsp;values,&nbsp;i.e.,&nbsp;class&nbsp;labels.</span></dd></dl>

<dl><dt><a name="LinearDiscriminantAnalysis-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Perform&nbsp;classification&nbsp;on&nbsp;an&nbsp;array&nbsp;of&nbsp;test&nbsp;vectors&nbsp;X.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Test&nbsp;data,&nbsp;where&nbsp;n_samples&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;and&nbsp;n_features&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;array,&nbsp;shape&nbsp;(n_samples,):&nbsp;Predicted&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;input&nbsp;samples.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Metrics">class <strong>Metrics</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor"><span class="code">&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn">Class methods defined here:<br>
<dl><dt><a name="Metrics-accuracy"><strong>accuracy</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;accuracy&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;accuracy&nbsp;(float):&nbsp;The&nbsp;accuracy&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-classification_report"><strong>classification_report</strong></a>(y_true, y_pred)</dt><dd><span class="code">Generates&nbsp;a&nbsp;classification&nbsp;report&nbsp;for&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;report&nbsp;(dict):&nbsp;The&nbsp;classification&nbsp;report.</span></dd></dl>

<dl><dt><a name="Metrics-confusion_matrix"><strong>confusion_matrix</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;confusion&nbsp;matrix&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;cm&nbsp;(numpy.ndarray):&nbsp;The&nbsp;confusion&nbsp;matrix.</span></dd></dl>

<dl><dt><a name="Metrics-f1_score"><strong>f1_score</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;F1&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;f1_score&nbsp;(float):&nbsp;The&nbsp;F1&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-log_loss"><strong>log_loss</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;log&nbsp;loss&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;probabilities.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;log_loss&nbsp;(float):&nbsp;The&nbsp;log&nbsp;loss.</span></dd></dl>

<dl><dt><a name="Metrics-mean_absolute_error"><strong>mean_absolute_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;absolute&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;mae&nbsp;(float):&nbsp;The&nbsp;mean&nbsp;absolute&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-mean_absolute_percentage_error"><strong>mean_absolute_percentage_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;absolute&nbsp;percentage&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;mape&nbsp;(float):&nbsp;The&nbsp;mean&nbsp;absolute&nbsp;percentage&nbsp;error&nbsp;as&nbsp;a&nbsp;decimal.&nbsp;Returns&nbsp;np.nan&nbsp;if&nbsp;y_true&nbsp;is&nbsp;all&nbsp;zeros.</span></dd></dl>

<dl><dt><a name="Metrics-mean_percentage_error"><strong>mean_percentage_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;percentage&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;mpe&nbsp;(float):&nbsp;The&nbsp;mean&nbsp;percentage&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-mean_squared_error"><strong>mean_squared_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;mean&nbsp;squared&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;mse&nbsp;(float):&nbsp;The&nbsp;mean&nbsp;squared&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-precision"><strong>precision</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;precision&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;precision&nbsp;(float):&nbsp;The&nbsp;precision&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-r_squared"><strong>r_squared</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;R-squared&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;r_squared&nbsp;(float):&nbsp;The&nbsp;R-squared&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-recall"><strong>recall</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;recall&nbsp;score&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;recall&nbsp;(float):&nbsp;The&nbsp;recall&nbsp;score.</span></dd></dl>

<dl><dt><a name="Metrics-root_mean_squared_error"><strong>root_mean_squared_error</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;root&nbsp;mean&nbsp;squared&nbsp;error&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;rmse&nbsp;(float):&nbsp;The&nbsp;root&nbsp;mean&nbsp;squared&nbsp;error.</span></dd></dl>

<dl><dt><a name="Metrics-show_classification_report"><strong>show_classification_report</strong></a>(y_true, y_pred)</dt><dd><span class="code">Generates&nbsp;and&nbsp;displays&nbsp;a&nbsp;classification&nbsp;report&nbsp;for&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;report&nbsp;(dict):&nbsp;The&nbsp;classification&nbsp;report.</span></dd></dl>

<dl><dt><a name="Metrics-show_confusion_matrix"><strong>show_confusion_matrix</strong></a>(y_true, y_pred)</dt><dd><span class="code">Calculates&nbsp;and&nbsp;displays&nbsp;the&nbsp;confusion&nbsp;matrix&nbsp;between&nbsp;the&nbsp;true&nbsp;and&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;y_true&nbsp;(numpy.ndarray):&nbsp;The&nbsp;true&nbsp;values.<br>
-&nbsp;y_pred&nbsp;(numpy.ndarray):&nbsp;The&nbsp;predicted&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;cm&nbsp;(numpy.ndarray):&nbsp;The&nbsp;confusion&nbsp;matrix.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="ModelSelectionUtility">class <strong>ModelSelectionUtility</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor"><span class="code">&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn">Static methods defined here:<br>
<dl><dt><a name="ModelSelectionUtility-cross_validate"><strong>cross_validate</strong></a>(model, X, y, params, cv=5, metric='mse', direction='minimize', verbose=False)</dt><dd><span class="code">Implements&nbsp;a&nbsp;custom&nbsp;cross-validation&nbsp;for&nbsp;hyperparameter&nbsp;tuning.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;model:&nbsp;The&nbsp;model&nbsp;Object&nbsp;to&nbsp;be&nbsp;tuned.<br>
-&nbsp;X&nbsp;(numpy.ndarray):&nbsp;The&nbsp;feature&nbsp;columns.<br>
-&nbsp;y&nbsp;(numpy.ndarray):&nbsp;The&nbsp;label&nbsp;column.<br>
-&nbsp;params&nbsp;(dict):&nbsp;The&nbsp;hyperparameters&nbsp;to&nbsp;be&nbsp;tuned.<br>
-&nbsp;cv&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;folds&nbsp;for&nbsp;cross-validation.&nbsp;Default&nbsp;is&nbsp;5.<br>
-&nbsp;metric&nbsp;(str):&nbsp;The&nbsp;metric&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;evaluation.&nbsp;Default&nbsp;is&nbsp;'mse'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Regression&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'mse',&nbsp;'r2',&nbsp;'mae',&nbsp;'rmse',&nbsp;'mape',&nbsp;'mpe'<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Classification&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'accuracy',&nbsp;'precision',&nbsp;'recall',&nbsp;'f1',&nbsp;'log_loss'<br>
-&nbsp;direction&nbsp;(str):&nbsp;The&nbsp;direction&nbsp;to&nbsp;optimize&nbsp;the&nbsp;metric.&nbsp;Default&nbsp;is&nbsp;'minimize'.<br>
-&nbsp;verbose&nbsp;(bool):&nbsp;A&nbsp;flag&nbsp;to&nbsp;display&nbsp;the&nbsp;training&nbsp;progress.&nbsp;Default&nbsp;is&nbsp;False.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;tuple:&nbsp;A&nbsp;tuple&nbsp;containing&nbsp;the&nbsp;scores&nbsp;(list)&nbsp;and&nbsp;the&nbsp;trained&nbsp;model.</span></dd></dl>

<dl><dt><a name="ModelSelectionUtility-get_param_combinations"><strong>get_param_combinations</strong></a>(param_grid)</dt><dd><span class="code">Generates&nbsp;all&nbsp;possible&nbsp;combinations&nbsp;of&nbsp;hyperparameters.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;param_combinations&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;dictionaries&nbsp;containing&nbsp;hyperparameter&nbsp;combinations.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="NeuralNetwork">class <strong>NeuralNetwork</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#NeuralNetwork">NeuralNetwork</a>(layer_sizes,&nbsp;dropout_rate=0.2,&nbsp;reg_lambda=0.01,&nbsp;activations=None)<br>
&nbsp;<br>
Neural&nbsp;network&nbsp;class&nbsp;for&nbsp;training&nbsp;and&nbsp;evaluating&nbsp;a&nbsp;custom&nbsp;neural&nbsp;network&nbsp;model.<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;layer_sizes&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;integers&nbsp;representing&nbsp;the&nbsp;sizes&nbsp;of&nbsp;each&nbsp;layer&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;dropout_rate&nbsp;(float):&nbsp;The&nbsp;dropout&nbsp;rate&nbsp;to&nbsp;be&nbsp;applied&nbsp;during&nbsp;training.&nbsp;Default&nbsp;is&nbsp;0.2.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;reg_lambda&nbsp;(float):&nbsp;The&nbsp;regularization&nbsp;lambda&nbsp;value.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;activations&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;activation&nbsp;functions&nbsp;for&nbsp;each&nbsp;layer.&nbsp;Default&nbsp;is&nbsp;['relu',&nbsp;'relu',&nbsp;...&nbsp;'softmax'].<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="NeuralNetwork-__init__"><strong>__init__</strong></a>(self, layer_sizes, dropout_rate=0.2, reg_lambda=0.01, activations=None)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="NeuralNetwork-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;repr(self).</span></dd></dl>

<dl><dt><a name="NeuralNetwork-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;str(self).</span></dd></dl>

<dl><dt><a name="NeuralNetwork-apply_dropout"><strong>apply_dropout</strong></a>(self, A)</dt><dd><span class="code">Applies&nbsp;dropout&nbsp;regularization&nbsp;to&nbsp;the&nbsp;input&nbsp;array.<br>
Parameters:&nbsp;A:&nbsp;numpy.ndarray:&nbsp;Input&nbsp;array&nbsp;to&nbsp;apply&nbsp;dropout&nbsp;regularization&nbsp;to.<br>
Returns:&nbsp;numpy.ndarray:&nbsp;Array&nbsp;with&nbsp;dropout&nbsp;regularization&nbsp;applied.</span></dd></dl>

<dl><dt><a name="NeuralNetwork-backward"><strong>backward</strong></a>(self, y)</dt><dd><span class="code">Performs&nbsp;backward&nbsp;propagation&nbsp;to&nbsp;calculate&nbsp;the&nbsp;gradients&nbsp;of&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
Parameters:&nbsp;y&nbsp;(numpy.ndarray):&nbsp;Target&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(m,&nbsp;1),&nbsp;where&nbsp;m&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples.<br>
Returns:&nbsp;None</span></dd></dl>

<dl><dt><a name="NeuralNetwork-calculate_loss"><strong>calculate_loss</strong></a>(self, X, y, class_weights=None)</dt><dd><span class="code">Calculates&nbsp;the&nbsp;loss&nbsp;of&nbsp;the&nbsp;neural&nbsp;network&nbsp;model.<br>
Formula:&nbsp;loss&nbsp;=&nbsp;loss_fn(outputs,&nbsp;y)&nbsp;+&nbsp;reg_lambda&nbsp;*&nbsp;sum([sum(layer.weights**2)&nbsp;for&nbsp;layer&nbsp;in&nbsp;self.<strong>layers</strong>])<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;X&nbsp;(numpy.ndarray):&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(num_samples,&nbsp;num_features).<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;y&nbsp;(numpy.ndarray):&nbsp;Target&nbsp;labels&nbsp;of&nbsp;shape&nbsp;(num_samples,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;class_weights&nbsp;(numpy.ndarray,&nbsp;optional):&nbsp;Weights&nbsp;for&nbsp;each&nbsp;class.&nbsp;Default&nbsp;is&nbsp;None.<br>
Returns:&nbsp;loss&nbsp;(float):&nbsp;The&nbsp;calculated&nbsp;loss&nbsp;value.</span></dd></dl>

<dl><dt><a name="NeuralNetwork-create_optimizer"><strong>create_optimizer</strong></a>(self, optimizer_type, learning_rate)</dt><dd><span class="code">Creates&nbsp;an&nbsp;optimizer&nbsp;instance&nbsp;based&nbsp;on&nbsp;the&nbsp;specified&nbsp;type&nbsp;and&nbsp;learning&nbsp;rate.<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer_type&nbsp;(str):&nbsp;The&nbsp;type&nbsp;of&nbsp;optimizer&nbsp;(e.g.,&nbsp;'SGD',&nbsp;'Adam').<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer:&nbsp;An&nbsp;instance&nbsp;of&nbsp;the&nbsp;specified&nbsp;optimizer.</span></dd></dl>

<dl><dt><a name="NeuralNetwork-evaluate"><strong>evaluate</strong></a>(self, X, y)</dt><dd><span class="code">Evaluates&nbsp;the&nbsp;performance&nbsp;of&nbsp;the&nbsp;neural&nbsp;network&nbsp;model&nbsp;on&nbsp;the&nbsp;given&nbsp;input&nbsp;data.<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;X&nbsp;(numpy.ndarray):&nbsp;The&nbsp;input&nbsp;data&nbsp;for&nbsp;evaluation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;y&nbsp;(numpy.ndarray):&nbsp;The&nbsp;target&nbsp;labels&nbsp;for&nbsp;evaluation.<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;accuracy&nbsp;(float):&nbsp;The&nbsp;accuracy&nbsp;of&nbsp;the&nbsp;model's&nbsp;predictions.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;predicted&nbsp;(numpy.ndarray):&nbsp;The&nbsp;labels&nbsp;predicted&nbsp;by&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="NeuralNetwork-forward"><strong>forward</strong></a>(self, X)</dt><dd><span class="code">Performs&nbsp;forward&nbsp;propagation&nbsp;through&nbsp;the&nbsp;neural&nbsp;network.<br>
Args:&nbsp;X&nbsp;(ndarray):&nbsp;Input&nbsp;data&nbsp;of&nbsp;shape&nbsp;(batch_size,&nbsp;input_size).<br>
Returns:&nbsp;ndarray:&nbsp;Output&nbsp;predictions&nbsp;of&nbsp;shape&nbsp;(batch_size,&nbsp;output_size).</span></dd></dl>

<dl><dt><a name="NeuralNetwork-train"><strong>train</strong></a>(self, X_train, y_train, X_test=None, y_test=None, optimizer=&lt;sega_learn.neural_networks.optimizers.AdamOptimizer object at 0x0000018D0C860950&gt;, epochs=100, batch_size=32, early_stopping_threshold=10, lr_scheduler=None, p=True)</dt><dd><span class="code">Trains&nbsp;the&nbsp;neural&nbsp;network&nbsp;model.<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;X_train&nbsp;(numpy.ndarray):&nbsp;Training&nbsp;data&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;y_train&nbsp;(numpy.ndarray):&nbsp;Training&nbsp;data&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;X_test&nbsp;(numpy.ndarray):&nbsp;Test&nbsp;data&nbsp;features,&nbsp;optional&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;y_test&nbsp;(numpy.ndarray):&nbsp;Test&nbsp;data&nbsp;labels,&nbsp;optional&nbsp;(default:&nbsp;None).<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;optimizer&nbsp;(Optimizer):&nbsp;The&nbsp;optimizer&nbsp;used&nbsp;for&nbsp;updating&nbsp;the&nbsp;model&nbsp;parameters&nbsp;(default:&nbsp;Adam,&nbsp;lr=0.0001).<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;epochs&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;training&nbsp;epochs&nbsp;(default:&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;batch_size&nbsp;(int):&nbsp;Batch&nbsp;size&nbsp;for&nbsp;mini-batch&nbsp;gradient&nbsp;descent&nbsp;(default:&nbsp;32).<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;early_stopping_threshold&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;epochs&nbsp;to&nbsp;wait&nbsp;for&nbsp;improvement&nbsp;in&nbsp;training&nbsp;loss&nbsp;before&nbsp;early&nbsp;stopping&nbsp;(default:&nbsp;5).<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;p&nbsp;(bool):&nbsp;Whether&nbsp;to&nbsp;print&nbsp;training&nbsp;progress&nbsp;(default:&nbsp;True).<br>
Returns:&nbsp;None</span></dd></dl>

<dl><dt><a name="NeuralNetwork-tune_hyperparameters"><strong>tune_hyperparameters</strong></a>(self, param_grid, num_layers_range, layer_size_range, output_size, X_train, y_train, X_val, y_val, optimizer_type, lr_range, epochs=100, batch_size=32)</dt><dd><span class="code">Performs&nbsp;hyperparameter&nbsp;tuning&nbsp;using&nbsp;grid&nbsp;search.<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;param_grid&nbsp;(dict):&nbsp;A&nbsp;dictionary&nbsp;where&nbsp;keys&nbsp;are&nbsp;parameter&nbsp;names&nbsp;and&nbsp;values&nbsp;are&nbsp;lists&nbsp;of&nbsp;values&nbsp;to&nbsp;try.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;num_layers_range&nbsp;(tuple):&nbsp;A&nbsp;tuple&nbsp;(min_layers,&nbsp;max_layers,&nbsp;step)&nbsp;for&nbsp;the&nbsp;number&nbsp;of&nbsp;layers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;layer_size_range&nbsp;(tuple):&nbsp;A&nbsp;tuple&nbsp;(min_size,&nbsp;max_size,&nbsp;step)&nbsp;for&nbsp;the&nbsp;layer&nbsp;sizes.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;output_size&nbsp;(int):&nbsp;The&nbsp;size&nbsp;of&nbsp;the&nbsp;output&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;X_train&nbsp;(numpy.ndarray):&nbsp;Training&nbsp;data&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;y_train&nbsp;(numpy.ndarray):&nbsp;Training&nbsp;data&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;X_val&nbsp;(numpy.ndarray):&nbsp;Validation&nbsp;data&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;y_val&nbsp;(numpy.ndarray):&nbsp;Validation&nbsp;data&nbsp;labels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;optimizer_type&nbsp;(str):&nbsp;The&nbsp;type&nbsp;of&nbsp;optimizer&nbsp;(e.g.,&nbsp;'SGD',&nbsp;'Adam').<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;lr_range&nbsp;(tuple):&nbsp;A&nbsp;tuple&nbsp;(min_lr,&nbsp;max_lr,&nbsp;num_steps)&nbsp;for&nbsp;learning&nbsp;rates.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;epochs&nbsp;(int):&nbsp;Number&nbsp;of&nbsp;training&nbsp;epochs&nbsp;(default:&nbsp;100).<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;batch_size&nbsp;(int):&nbsp;Batch&nbsp;size&nbsp;for&nbsp;mini-batch&nbsp;gradient&nbsp;descent&nbsp;(default:&nbsp;32).<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_params&nbsp;(dict):&nbsp;The&nbsp;best&nbsp;hyperparameters&nbsp;found&nbsp;during&nbsp;tuning.<br>
&nbsp;&nbsp;&nbsp;&nbsp;best_accuracy&nbsp;(float):&nbsp;The&nbsp;best&nbsp;validation&nbsp;accuracy&nbsp;achieved.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="OrdinaryLeastSquares">class <strong>OrdinaryLeastSquares</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#OrdinaryLeastSquares">OrdinaryLeastSquares</a>(fit_intercept=True)&nbsp;-&amp;gt;&nbsp;None<br>
&nbsp;<br>
Ordinary&nbsp;Least&nbsp;Squares&nbsp;(OLS)&nbsp;linear&nbsp;regression&nbsp;model.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;fit_intercept&nbsp;:&nbsp;bool,&nbsp;default=True<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model.&nbsp;If&nbsp;set&nbsp;to&nbsp;False,&nbsp;no&nbsp;intercept&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;calculations.<br>
&nbsp;<br>
Attributes:<br>
-&nbsp;coef_&nbsp;:&nbsp;ndarray&nbsp;of&nbsp;shape&nbsp;(n_features,)&nbsp;or&nbsp;(n_features&nbsp;+&nbsp;1,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;linear&nbsp;regression&nbsp;problem.&nbsp;If&nbsp;`fit_intercept`&nbsp;is&nbsp;True,&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;the&nbsp;intercept.<br>
-&nbsp;intercept_&nbsp;:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;Independent&nbsp;term&nbsp;in&nbsp;the&nbsp;linear&nbsp;model.&nbsp;Set&nbsp;to&nbsp;0.0&nbsp;if&nbsp;`fit_intercept`&nbsp;is&nbsp;False.<br>
&nbsp;<br>
Methods:&nbsp;<br>
-&nbsp;<a href="#OrdinaryLeastSquares-fit">fit</a>(X,&nbsp;y):&nbsp;Fit&nbsp;the&nbsp;linear&nbsp;model&nbsp;to&nbsp;the&nbsp;data.<br>
-&nbsp;<a href="#OrdinaryLeastSquares-predict">predict</a>(X):&nbsp;Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model.<br>
-&nbsp;<a href="#OrdinaryLeastSquares-get_formula">get_formula</a>():&nbsp;Returns&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model&nbsp;as&nbsp;a&nbsp;string.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="OrdinaryLeastSquares-__init__"><strong>__init__</strong></a>(self, fit_intercept=True) -&gt; None</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#OrdinaryLeastSquares">OrdinaryLeastSquares</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;fit_intercept&nbsp;:&nbsp;bool,&nbsp;default=True<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model.</span></dd></dl>

<dl><dt><a name="OrdinaryLeastSquares-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;str(self).</span></dd></dl>

<dl><dt><a name="OrdinaryLeastSquares-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fit&nbsp;linear&nbsp;model.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Training&nbsp;data.<br>
-&nbsp;y&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,)&nbsp;or&nbsp;(n_samples,&nbsp;n_targets):&nbsp;Target&nbsp;values.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;self&nbsp;:&nbsp;<a href="builtins.html#object">object</a></span></dd></dl>

<dl><dt><a name="OrdinaryLeastSquares-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Returns&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model&nbsp;as&nbsp;a&nbsp;string.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;formula&nbsp;:&nbsp;str:&nbsp;The&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="OrdinaryLeastSquares-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Samples.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;y_pred&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,):&nbsp;Predicted&nbsp;values.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="PassiveAggressiveRegressor">class <strong>PassiveAggressiveRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#PassiveAggressiveRegressor">PassiveAggressiveRegressor</a>(C=1.0,&nbsp;max_iter=1000,&nbsp;tol=0.001)<br>
&nbsp;<br>
Implements&nbsp;Passive&nbsp;Aggressive&nbsp;Regression&nbsp;using&nbsp;the&nbsp;Passive&nbsp;Aggressive&nbsp;algorithm.<br>
The&nbsp;algorithm&nbsp;is&nbsp;a&nbsp;type&nbsp;of&nbsp;online&nbsp;learning&nbsp;algorithm&nbsp;that&nbsp;updates&nbsp;the&nbsp;model&nbsp;parameters&nbsp;based&nbsp;on&nbsp;the&nbsp;current&nbsp;sample.<br>
If&nbsp;the&nbsp;prediction&nbsp;is&nbsp;within&nbsp;a&nbsp;certain&nbsp;tolerance,&nbsp;the&nbsp;model&nbsp;parameters&nbsp;are&nbsp;updated.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;C:&nbsp;float,&nbsp;default=1.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;Regularization&nbsp;parameter/step&nbsp;size.<br>
-&nbsp;max_iter:&nbsp;int,&nbsp;default=1000<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;passes&nbsp;over&nbsp;the&nbsp;training&nbsp;data.<br>
-&nbsp;tol:&nbsp;float,&nbsp;default=1e-3<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;stopping&nbsp;criterion.<br>
&nbsp;<br>
Attributes:<br>
-&nbsp;coef_:&nbsp;ndarray&nbsp;of&nbsp;shape&nbsp;(n_features,)&nbsp;or&nbsp;(n_features&nbsp;+&nbsp;1,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;linear&nbsp;regression&nbsp;problem.&nbsp;If&nbsp;`fit_intercept`&nbsp;is&nbsp;True,&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;the&nbsp;intercept.<br>
-&nbsp;intercept_:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;Independent&nbsp;term&nbsp;in&nbsp;the&nbsp;linear&nbsp;model.&nbsp;Set&nbsp;to&nbsp;0.0&nbsp;if&nbsp;`fit_intercept`&nbsp;is&nbsp;False.<br>
-&nbsp;n_iter_:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;iterations&nbsp;performed.<br>
-&nbsp;steps_:&nbsp;list&nbsp;of&nbsp;tuples&nbsp;of&nbsp;shape&nbsp;(n_features,)&nbsp;or&nbsp;(n_features&nbsp;+&nbsp;1,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;weights&nbsp;and&nbsp;intercept&nbsp;at&nbsp;each&nbsp;iteration&nbsp;if&nbsp;save_steps&nbsp;is&nbsp;True.<br>
-&nbsp;save_steps:&nbsp;bool,&nbsp;default=False<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Whether&nbsp;to&nbsp;save&nbsp;the&nbsp;weights&nbsp;and&nbsp;intercept&nbsp;at&nbsp;each&nbsp;iteration.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="PassiveAggressiveRegressor-__init__"><strong>__init__</strong></a>(self, C=1.0, max_iter=1000, tol=0.001)</dt><dd><span class="code">Implements&nbsp;Passive&nbsp;Aggressive&nbsp;Regression&nbsp;using&nbsp;the&nbsp;Passive&nbsp;Aggressive&nbsp;algorithm.<br>
The&nbsp;algorithm&nbsp;is&nbsp;a&nbsp;type&nbsp;of&nbsp;online&nbsp;learning&nbsp;algorithm&nbsp;that&nbsp;updates&nbsp;the&nbsp;model&nbsp;parameters&nbsp;based&nbsp;on&nbsp;the&nbsp;current&nbsp;sample.<br>
If&nbsp;the&nbsp;prediction&nbsp;is&nbsp;within&nbsp;a&nbsp;certain&nbsp;tolerance,&nbsp;the&nbsp;model&nbsp;parameters&nbsp;are&nbsp;updated.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;C:&nbsp;float,&nbsp;default=1.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;Regularization&nbsp;parameter/step&nbsp;size.<br>
-&nbsp;max_iter:&nbsp;int,&nbsp;default=1000<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;passes&nbsp;over&nbsp;the&nbsp;training&nbsp;data.<br>
-&nbsp;tol:&nbsp;float,&nbsp;default=1e-3<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;stopping&nbsp;criterion.</span></dd></dl>

<dl><dt><a name="PassiveAggressiveRegressor-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;str(self).</span></dd></dl>

<dl><dt><a name="PassiveAggressiveRegressor-fit"><strong>fit</strong></a>(self, X, y, save_steps=False, verbose=False)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data.<br>
Save&nbsp;the&nbsp;weights&nbsp;and&nbsp;the&nbsp;intercept&nbsp;at&nbsp;each&nbsp;iteration&nbsp;if&nbsp;save_steps&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Training&nbsp;data.<br>
-&nbsp;y&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,)&nbsp;or&nbsp;(n_samples,&nbsp;n_targets):&nbsp;Target&nbsp;values.<br>
-&nbsp;save_steps:&nbsp;bool,&nbsp;default=False<br>
-&nbsp;verbose:&nbsp;bool,&nbsp;default=False</span></dd></dl>

<dl><dt><a name="PassiveAggressiveRegressor-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Computes&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;formula&nbsp;:&nbsp;str:&nbsp;The&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="PassiveAggressiveRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model.&nbsp;Dot&nbsp;product&nbsp;of&nbsp;X&nbsp;and&nbsp;the&nbsp;coefficients.</span></dd></dl>

<dl><dt><a name="PassiveAggressiveRegressor-predict_all_steps"><strong>predict_all_steps</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model&nbsp;at&nbsp;each&nbsp;iteration.&nbsp;(save_steps=True)</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="PolynomialTransform">class <strong>PolynomialTransform</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#PolynomialTransform">PolynomialTransform</a>(degree=2)<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;Polynomial&nbsp;Feature&nbsp;Transformation.<br>
Polynomial&nbsp;feature&nbsp;transformation&nbsp;is&nbsp;a&nbsp;technique&nbsp;used&nbsp;to&nbsp;create&nbsp;new&nbsp;features&nbsp;from&nbsp;the&nbsp;existing&nbsp;features&nbsp;by&nbsp;raising&nbsp;them&nbsp;to&nbsp;a&nbsp;power&nbsp;or&nbsp;by&nbsp;creating&nbsp;interaction&nbsp;terms.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;degree:&nbsp;int,&nbsp;default=2<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;degree&nbsp;of&nbsp;the&nbsp;polynomial&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
Attributes:<br>
-&nbsp;n_samples:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;samples.<br>
-&nbsp;n_features:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;features.<br>
-&nbsp;n_output_features:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;output&nbsp;features.<br>
-&nbsp;combinations:&nbsp;list&nbsp;of&nbsp;tuples&nbsp;of&nbsp;shape&nbsp;(n_features,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;combinations&nbsp;of&nbsp;features(X)&nbsp;of&nbsp;degree&nbsp;n.<br>
-&nbsp;bias:&nbsp;bool,&nbsp;default=True<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;include&nbsp;a&nbsp;bias&nbsp;term&nbsp;in&nbsp;the&nbsp;output&nbsp;features.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="PolynomialTransform-__init__"><strong>__init__</strong></a>(self, degree=2)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="PolynomialTransform-fit"><strong>fit</strong></a>(self, X)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data.&nbsp;<br>
Uses&nbsp;itertools.combinations_with_replacement&nbsp;to&nbsp;generate&nbsp;all&nbsp;possible&nbsp;combinations&nbsp;of&nbsp;features(X)&nbsp;of&nbsp;degree&nbsp;n.</span></dd></dl>

<dl><dt><a name="PolynomialTransform-fit_transform"><strong>fit_transform</strong></a>(self, X)</dt><dd><span class="code">Fit&nbsp;to&nbsp;data,&nbsp;then&nbsp;transform&nbsp;it.</span></dd></dl>

<dl><dt><a name="PolynomialTransform-transform"><strong>transform</strong></a>(self, X)</dt><dd><span class="code">Transform&nbsp;the&nbsp;data&nbsp;into&nbsp;polynomial&nbsp;features&nbsp;by&nbsp;computing&nbsp;the&nbsp;product&nbsp;of&nbsp;the&nbsp;features&nbsp;for&nbsp;each&nbsp;combination&nbsp;of&nbsp;features.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="QuadraticDiscriminantAnalysis">class <strong>QuadraticDiscriminantAnalysis</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#QuadraticDiscriminantAnalysis">QuadraticDiscriminantAnalysis</a>(priors=None,&nbsp;reg_param=0.0)<br>
&nbsp;<br>
Implements&nbsp;Quadratic&nbsp;Discriminant&nbsp;Analysis.<br>
The&nbsp;quadratic&nbsp;term&nbsp;allows&nbsp;for&nbsp;more&nbsp;flexibility&nbsp;in&nbsp;modeling&nbsp;the&nbsp;class&nbsp;conditional<br>
A&nbsp;classifier&nbsp;with&nbsp;a&nbsp;quadratic&nbsp;decision&nbsp;boundary,&nbsp;generated&nbsp;by&nbsp;fitting&nbsp;class&nbsp;conditional&nbsp;densities&nbsp;to&nbsp;the&nbsp;data&nbsp;and&nbsp;using&nbsp;Bayes'&nbsp;rule.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;priors&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_classes,),&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Prior&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;classes.&nbsp;If&nbsp;None,&nbsp;the&nbsp;priors&nbsp;are&nbsp;uniform.<br>
-&nbsp;reg_param&nbsp;:&nbsp;float,&nbsp;default=0.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;Regularization&nbsp;parameter.&nbsp;If&nbsp;greater&nbsp;than&nbsp;0,&nbsp;the&nbsp;covariance&nbsp;matrices&nbsp;are&nbsp;regularized&nbsp;by&nbsp;adding&nbsp;a&nbsp;scaled&nbsp;identity&nbsp;matrix&nbsp;to&nbsp;them.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="QuadraticDiscriminantAnalysis-__init__"><strong>__init__</strong></a>(self, priors=None, reg_param=0.0)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;Quadratic&nbsp;Discriminant&nbsp;Analysis&nbsp;model&nbsp;with&nbsp;the&nbsp;specified&nbsp;prior&nbsp;probabilities&nbsp;and&nbsp;regularization&nbsp;parameter.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;priors&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_classes,),&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Prior&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;classes.&nbsp;If&nbsp;None,&nbsp;the&nbsp;priors&nbsp;are&nbsp;uniform.<br>
-&nbsp;reg_param&nbsp;:&nbsp;float,&nbsp;default=0.0</span></dd></dl>

<dl><dt><a name="QuadraticDiscriminantAnalysis-decision_function"><strong>decision_function</strong></a>(self, X)</dt><dd><span class="code">Apply&nbsp;decision&nbsp;function&nbsp;to&nbsp;an&nbsp;array&nbsp;of&nbsp;samples.<br>
The&nbsp;decision&nbsp;function&nbsp;is&nbsp;the&nbsp;log-likelihood&nbsp;of&nbsp;each&nbsp;class.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Test&nbsp;data,&nbsp;where&nbsp;n_samples&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;and&nbsp;n_features&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;array,&nbsp;shape&nbsp;(n_samples,&nbsp;n_classes):&nbsp;Log-likelihood&nbsp;of&nbsp;each&nbsp;class&nbsp;for&nbsp;the&nbsp;input&nbsp;samples.</span></dd></dl>

<dl><dt><a name="QuadraticDiscriminantAnalysis-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;according&nbsp;to&nbsp;the&nbsp;given&nbsp;training&nbsp;data.&nbsp;Uses&nbsp;the&nbsp;means&nbsp;and&nbsp;covariance&nbsp;matrices&nbsp;of&nbsp;each&nbsp;class.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Training&nbsp;data,&nbsp;where&nbsp;n_samples&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;and&nbsp;n_features&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;features.<br>
-&nbsp;y&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,):&nbsp;Target&nbsp;values,&nbsp;i.e.,&nbsp;class&nbsp;labels.</span></dd></dl>

<dl><dt><a name="QuadraticDiscriminantAnalysis-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Perform&nbsp;classification&nbsp;on&nbsp;an&nbsp;array&nbsp;of&nbsp;test&nbsp;vectors&nbsp;X.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Test&nbsp;data,&nbsp;where&nbsp;n_samples&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;and&nbsp;n_features&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;features.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;array,&nbsp;shape&nbsp;(n_samples,):&nbsp;Predicted&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;input&nbsp;samples.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RANSAC">class <strong>RANSAC</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RANSAC">RANSAC</a>(n=10,&nbsp;k=100,&nbsp;t=0.05,&nbsp;d=10,&nbsp;model=None,&nbsp;auto_scale_t=False,&nbsp;scale_t_factor=2,&nbsp;auto_scale_n=False,&nbsp;scale_n_factor=2)<br>
&nbsp;<br>
Implements&nbsp;<a href="#RANSAC">RANSAC</a>&nbsp;(RANdom&nbsp;SAmple&nbsp;Consensus)&nbsp;algorithm&nbsp;for&nbsp;robust&nbsp;linear&nbsp;regression.<br>
This&nbsp;uses&nbsp;the&nbsp;<a href="#RANSAC">RANSAC</a>&nbsp;algorithm&nbsp;to&nbsp;fit&nbsp;a&nbsp;linear&nbsp;model&nbsp;to&nbsp;the&nbsp;data,&nbsp;while&nbsp;ignoring&nbsp;outliers.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;n:&nbsp;int,&nbsp;default=10<br>
&nbsp;&nbsp;&nbsp;&nbsp;Number&nbsp;of&nbsp;data&nbsp;points&nbsp;to&nbsp;estimate&nbsp;parameters.<br>
-&nbsp;k:&nbsp;int,&nbsp;default=100<br>
&nbsp;&nbsp;&nbsp;&nbsp;Maximum&nbsp;iterations&nbsp;allowed.<br>
-&nbsp;t:&nbsp;float,&nbsp;default=0.05<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Threshold&nbsp;value&nbsp;to&nbsp;determine&nbsp;if&nbsp;points&nbsp;are&nbsp;fit&nbsp;well,&nbsp;in&nbsp;terms&nbsp;of&nbsp;residuals.<br>
-&nbsp;d:&nbsp;int,&nbsp;default=10<br>
&nbsp;&nbsp;&nbsp;&nbsp;Number&nbsp;of&nbsp;close&nbsp;data&nbsp;points&nbsp;required&nbsp;to&nbsp;assert&nbsp;model&nbsp;fits&nbsp;well.&nbsp;<br>
-&nbsp;model:&nbsp;<a href="builtins.html#object">object</a>,&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;model&nbsp;to&nbsp;use&nbsp;for&nbsp;fitting.&nbsp;If&nbsp;None,&nbsp;uses&nbsp;Ordinary&nbsp;Least&nbsp;Squares.<br>
-&nbsp;auto_scale_t:&nbsp;bool,&nbsp;default=False<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Whether&nbsp;to&nbsp;automatically&nbsp;scale&nbsp;the&nbsp;threshold&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit.<br>
-&nbsp;scale_t_factor:&nbsp;float,&nbsp;default=2<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Factor&nbsp;by&nbsp;which&nbsp;to&nbsp;scale&nbsp;the&nbsp;threshold&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit.<br>
-&nbsp;auto_scale_n:&nbsp;bool,&nbsp;default=False<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Whether&nbsp;to&nbsp;automatically&nbsp;scale&nbsp;the&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit.<br>
-&nbsp;scale_n_factor:&nbsp;float,&nbsp;default=2<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Factor&nbsp;by&nbsp;which&nbsp;to&nbsp;scale&nbsp;the&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit.<br>
&nbsp;<br>
Attributes:<br>
-&nbsp;best_fit:&nbsp;<a href="builtins.html#object">object</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;best&nbsp;model&nbsp;fit.<br>
-&nbsp;best_error:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;best&nbsp;error&nbsp;achieved&nbsp;by&nbsp;the&nbsp;model.<br>
-&nbsp;best_n:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;best&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;used&nbsp;to&nbsp;fit&nbsp;the&nbsp;model.<br>
-&nbsp;best_t:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;best&nbsp;threshold&nbsp;value&nbsp;used&nbsp;to&nbsp;determine&nbsp;if&nbsp;points&nbsp;are&nbsp;fit&nbsp;well,&nbsp;in&nbsp;terms&nbsp;of&nbsp;residuals.<br>
-&nbsp;best_model:&nbsp;<a href="builtins.html#object">object</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;best&nbsp;model&nbsp;fit.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RANSAC-__init__"><strong>__init__</strong></a>(self, n=10, k=100, t=0.05, d=10, model=None, auto_scale_t=False, scale_t_factor=2, auto_scale_n=False, scale_n_factor=2)</dt><dd><span class="code">Implements&nbsp;<a href="#RANSAC">RANSAC</a>&nbsp;(RANdom&nbsp;SAmple&nbsp;Consensus)&nbsp;algorithm&nbsp;for&nbsp;robust&nbsp;linear&nbsp;regression.<br>
This&nbsp;uses&nbsp;the&nbsp;<a href="#RANSAC">RANSAC</a>&nbsp;algorithm&nbsp;to&nbsp;fit&nbsp;a&nbsp;linear&nbsp;model&nbsp;to&nbsp;the&nbsp;data,&nbsp;while&nbsp;ignoring&nbsp;outliers.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;n:&nbsp;int,&nbsp;default=10<br>
&nbsp;&nbsp;&nbsp;&nbsp;Number&nbsp;of&nbsp;data&nbsp;points&nbsp;to&nbsp;estimate&nbsp;parameters.<br>
-&nbsp;k:&nbsp;int,&nbsp;default=100<br>
&nbsp;&nbsp;&nbsp;&nbsp;Maximum&nbsp;iterations&nbsp;allowed.<br>
-&nbsp;t:&nbsp;float,&nbsp;default=0.05<br>
&nbsp;&nbsp;&nbsp;&nbsp;Threshold&nbsp;value&nbsp;to&nbsp;determine&nbsp;if&nbsp;points&nbsp;are&nbsp;fit&nbsp;well,&nbsp;in&nbsp;terms&nbsp;of&nbsp;residuals.<br>
-&nbsp;d:&nbsp;int,&nbsp;default=10<br>
&nbsp;&nbsp;&nbsp;&nbsp;Number&nbsp;of&nbsp;close&nbsp;data&nbsp;points&nbsp;required&nbsp;to&nbsp;assert&nbsp;model&nbsp;fits&nbsp;well.&nbsp;<br>
-&nbsp;model:&nbsp;<a href="builtins.html#object">object</a>,&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;model&nbsp;to&nbsp;use&nbsp;for&nbsp;fitting.&nbsp;If&nbsp;None,&nbsp;uses&nbsp;Ordinary&nbsp;Least&nbsp;Squares.<br>
-&nbsp;auto_scale_t:&nbsp;bool,&nbsp;default=False<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Whether&nbsp;to&nbsp;automatically&nbsp;scale&nbsp;the&nbsp;threshold&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit.<br>
-&nbsp;scale_t_factor:&nbsp;float,&nbsp;default=2<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Factor&nbsp;by&nbsp;which&nbsp;to&nbsp;scale&nbsp;the&nbsp;threshold&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit.<br>
-&nbsp;auto_scale_n:&nbsp;bool,&nbsp;default=False<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Whether&nbsp;to&nbsp;automatically&nbsp;scale&nbsp;the&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit.<br>
-&nbsp;scale_n_factor:&nbsp;float,&nbsp;default=2<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Factor&nbsp;by&nbsp;which&nbsp;to&nbsp;scale&nbsp;the&nbsp;number&nbsp;of&nbsp;data&nbsp;points&nbsp;until&nbsp;a&nbsp;model&nbsp;is&nbsp;fit.</span></dd></dl>

<dl><dt><a name="RANSAC-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;str(self).</span></dd></dl>

<dl><dt><a name="RANSAC-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data,&nbsp;using&nbsp;<a href="#RANSAC">RANSAC</a>.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Training&nbsp;data.<br>
-&nbsp;y&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,)&nbsp;or&nbsp;(n_samples,&nbsp;n_targets):&nbsp;Target&nbsp;values.</span></dd></dl>

<dl><dt><a name="RANSAC-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Computes&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model&nbsp;if&nbsp;fit,&nbsp;else&nbsp;returns&nbsp;"No&nbsp;model&nbsp;fit&nbsp;available"</span></dd></dl>

<dl><dt><a name="RANSAC-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;using&nbsp;the&nbsp;best&nbsp;fit&nbsp;model.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Samples.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RandomForestClassifier">class <strong>RandomForestClassifier</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RandomForestClassifier">RandomForestClassifier</a>(X=None,&nbsp;y=None,&nbsp;max_depth=5,&nbsp;forest_size=5,&nbsp;display=False,&nbsp;random_seed=0)<br>
&nbsp;<br>
Random&nbsp;Forest&nbsp;classifier.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_trees&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;random&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;decision_trees&nbsp;(list):&nbsp;List&nbsp;of&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;random&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bootstraps_datasets&nbsp;(list):&nbsp;List&nbsp;of&nbsp;bootstrapped&nbsp;datasets&nbsp;for&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bootstraps_labels&nbsp;(list):&nbsp;List&nbsp;of&nbsp;true&nbsp;class&nbsp;labels&nbsp;corresponding&nbsp;to&nbsp;records&nbsp;in&nbsp;the&nbsp;bootstrapped&nbsp;datasets.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-__init__">__init__</a>(self,&nbsp;num_trees,&nbsp;max_depth):&nbsp;Initializes&nbsp;the&nbsp;RandomForest&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_reset(self):&nbsp;Resets&nbsp;the&nbsp;RandomForest&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_bootstrapping(self,&nbsp;XX,&nbsp;n):&nbsp;Performs&nbsp;bootstrapping&nbsp;on&nbsp;the&nbsp;dataset.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-bootstrapping">bootstrapping</a>(self,&nbsp;XX):&nbsp;Initializes&nbsp;the&nbsp;bootstrapped&nbsp;datasets&nbsp;for&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-fitting">fitting</a>(self):&nbsp;Fits&nbsp;the&nbsp;decision&nbsp;trees&nbsp;to&nbsp;the&nbsp;bootstrapped&nbsp;datasets.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestClassifier-voting">voting</a>(self,&nbsp;X):&nbsp;Performs&nbsp;voting&nbsp;to&nbsp;classify&nbsp;the&nbsp;input&nbsp;records.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RandomForestClassifier-__init__"><strong>__init__</strong></a>(self, X=None, y=None, max_depth=5, forest_size=5, display=False, random_seed=0)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;RandomForest&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_trees&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;random&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;decision&nbsp;tree.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-bootstrapping"><strong>bootstrapping</strong></a>(self, XX)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;bootstrapped&nbsp;datasets&nbsp;for&nbsp;each&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;XX&nbsp;(list):&nbsp;The&nbsp;dataset.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-display_info_gains"><strong>display_info_gains</strong></a>(self)</dt><dd><span class="code">Displays&nbsp;the&nbsp;information&nbsp;gains&nbsp;of&nbsp;each&nbsp;decision&nbsp;tree.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-fit"><strong>fit</strong></a>(self, X=None, y=None, verbose=False)</dt><dd><span class="code">Runs&nbsp;the&nbsp;random&nbsp;forest&nbsp;algorithm.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tuple:&nbsp;A&nbsp;tuple&nbsp;containing&nbsp;the&nbsp;random&nbsp;forest&nbsp;<a href="builtins.html#object">object</a>&nbsp;and&nbsp;the&nbsp;accuracy&nbsp;of&nbsp;the&nbsp;random&nbsp;forest&nbsp;algorithm.<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;FileNotFoundError:&nbsp;If&nbsp;the&nbsp;file&nbsp;specified&nbsp;by&nbsp;file_loc&nbsp;does&nbsp;not&nbsp;exist.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-fitting"><strong>fitting</strong></a>(self)</dt><dd><span class="code">Fits&nbsp;the&nbsp;decision&nbsp;trees&nbsp;to&nbsp;the&nbsp;bootstrapped&nbsp;datasets.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-plot_info_gains"><strong>plot_info_gains</strong></a>(self)</dt><dd><span class="code">Plots&nbsp;the&nbsp;information&nbsp;gain&nbsp;of&nbsp;each&nbsp;decision&nbsp;tree&nbsp;separately.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-plot_info_gains_together"><strong>plot_info_gains_together</strong></a>(self)</dt><dd><span class="code">Plots&nbsp;the&nbsp;information&nbsp;gains&nbsp;of&nbsp;all&nbsp;decision&nbsp;trees&nbsp;together.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;input&nbsp;records.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(list):&nbsp;The&nbsp;input&nbsp;records.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;The&nbsp;predicted&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;input&nbsp;records.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-reset"><strong>reset</strong></a>(self)</dt><dd><span class="code">Resets&nbsp;the&nbsp;random&nbsp;forest&nbsp;<a href="builtins.html#object">object</a>.</span></dd></dl>

<dl><dt><a name="RandomForestClassifier-voting"><strong>voting</strong></a>(self, X)</dt><dd><span class="code">Performs&nbsp;voting&nbsp;to&nbsp;classify&nbsp;the&nbsp;input&nbsp;records.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(list):&nbsp;The&nbsp;input&nbsp;records.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;The&nbsp;predicted&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;input&nbsp;records.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>X</strong> = []</dl>

<dl><dt><strong>XX</strong> = []</dl>

<dl><dt><strong>bootstraps_datasets</strong> = []</dl>

<dl><dt><strong>bootstraps_labels</strong> = []</dl>

<dl><dt><strong>decision_trees</strong> = []</dl>

<dl><dt><strong>display</strong> = False</dl>

<dl><dt><strong>forest_size</strong> = 10</dl>

<dl><dt><strong>max_depth</strong> = 10</dl>

<dl><dt><strong>num_trees</strong> = 0</dl>

<dl><dt><strong>numerical_cols</strong> = 0</dl>

<dl><dt><strong>random_seed</strong> = 0</dl>

<dl><dt><strong>y</strong> = []</dl>

</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RandomForestRegressor">class <strong>RandomForestRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RandomForestRegressor">RandomForestRegressor</a>(X=None,&nbsp;y=None,&nbsp;forest_size=10,&nbsp;random_seed=0,&nbsp;max_depth=10)<br>
&nbsp;<br>
A&nbsp;class&nbsp;representing&nbsp;a&nbsp;Random&nbsp;Forest&nbsp;model.<br>
&nbsp;<br>
Attributes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_trees&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;random&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;decision_trees&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;random&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bootstraps_datasets&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;bootstrapped&nbsp;datasets&nbsp;for&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;bootstraps_labels&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;corresponding&nbsp;labels&nbsp;for&nbsp;each&nbsp;bootstrapped&nbsp;dataset.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-__init__">__init__</a>(num_trees,&nbsp;max_depth):&nbsp;Initializes&nbsp;the&nbsp;RandomForest&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_bootstrapping(XX,&nbsp;n):&nbsp;Performs&nbsp;bootstrapping&nbsp;on&nbsp;the&nbsp;dataset.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-bootstrapping">bootstrapping</a>(XX):&nbsp;Initializes&nbsp;the&nbsp;bootstrapped&nbsp;datasets&nbsp;for&nbsp;each&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-fitting">fitting</a>():&nbsp;Fits&nbsp;the&nbsp;decision&nbsp;trees&nbsp;to&nbsp;the&nbsp;bootstrapped&nbsp;datasets.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#RandomForestRegressor-voting">voting</a>(X):&nbsp;Performs&nbsp;voting&nbsp;to&nbsp;predict&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;records.<br>
&nbsp;&nbsp;&nbsp;&nbsp;user():&nbsp;Returns&nbsp;the&nbsp;user's&nbsp;GTUsername.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RandomForestRegressor-__init__"><strong>__init__</strong></a>(self, X=None, y=None, forest_size=10, random_seed=0, max_depth=10)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;RandomForest&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(ndarray):&nbsp;The&nbsp;input&nbsp;data&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;(ndarray):&nbsp;The&nbsp;target&nbsp;values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;forest_size&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;random&nbsp;forest.<br>
&nbsp;&nbsp;&nbsp;&nbsp;random_seed&nbsp;(int):&nbsp;The&nbsp;random&nbsp;seed&nbsp;for&nbsp;reproducibility.<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;each&nbsp;decision&nbsp;tree.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-bootstrapping"><strong>bootstrapping</strong></a>(self, XX)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;bootstrapped&nbsp;datasets&nbsp;for&nbsp;each&nbsp;tree.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;XX&nbsp;(list):&nbsp;The&nbsp;dataset.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-fit"><strong>fit</strong></a>(self, X=None, y=None, verbose=False)</dt><dd><span class="code">Runs&nbsp;the&nbsp;random&nbsp;forest&nbsp;algorithm.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-fitting"><strong>fitting</strong></a>(self)</dt><dd><span class="code">Fits&nbsp;the&nbsp;decision&nbsp;trees&nbsp;to&nbsp;the&nbsp;bootstrapped&nbsp;datasets.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-get_stats"><strong>get_stats</strong></a>(self, verbose=True)</dt><dd><span class="code">Returns&nbsp;the&nbsp;evaluation&nbsp;metrics.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-predict"><strong>predict</strong></a>(self, X=None)</dt><dd><span class="code">Predicts&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;data.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-reset"><strong>reset</strong></a>(self)</dt><dd><span class="code">Resets&nbsp;the&nbsp;random&nbsp;forest&nbsp;<a href="builtins.html#object">object</a>.</span></dd></dl>

<dl><dt><a name="RandomForestRegressor-voting"><strong>voting</strong></a>(self, X)</dt><dd><span class="code">Performs&nbsp;voting&nbsp;to&nbsp;predict&nbsp;the&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;records.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;(list):&nbsp;The&nbsp;input&nbsp;records.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;The&nbsp;predicted&nbsp;target&nbsp;values&nbsp;for&nbsp;the&nbsp;input&nbsp;records.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>X</strong> = []</dl>

<dl><dt><strong>XX</strong> = []</dl>

<dl><dt><strong>bootstraps_datasets</strong> = []</dl>

<dl><dt><strong>bootstraps_labels</strong> = []</dl>

<dl><dt><strong>decision_trees</strong> = []</dl>

<dl><dt><strong>display</strong> = False</dl>

<dl><dt><strong>forest_size</strong> = 10</dl>

<dl><dt><strong>max_depth</strong> = 10</dl>

<dl><dt><strong>num_trees</strong> = 0</dl>

<dl><dt><strong>numerical_cols</strong> = 0</dl>

<dl><dt><strong>random_seed</strong> = 0</dl>

<dl><dt><strong>y</strong> = []</dl>

</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RandomSearchCV">class <strong>RandomSearchCV</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RandomSearchCV">RandomSearchCV</a>(model,&nbsp;param_grid,&nbsp;iter=10,&nbsp;cv=5,&nbsp;metric='mse',&nbsp;direction='minimize')<br>
&nbsp;<br>
Implements&nbsp;a&nbsp;random&nbsp;search&nbsp;cross-validation&nbsp;for&nbsp;hyperparameter&nbsp;tuning.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RandomSearchCV-__init__"><strong>__init__</strong></a>(self, model, param_grid, iter=10, cv=5, metric='mse', direction='minimize')</dt><dd><span class="code">Initializes&nbsp;the&nbsp;<a href="#RandomSearchCV">RandomSearchCV</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;model:&nbsp;The&nbsp;model&nbsp;Object&nbsp;to&nbsp;be&nbsp;tuned.<br>
-&nbsp;param_grid&nbsp;(list):&nbsp;A&nbsp;list&nbsp;of&nbsp;dictionaries&nbsp;containing&nbsp;hyperparameters&nbsp;to&nbsp;be&nbsp;tuned.<br>
-&nbsp;iter&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;random&nbsp;search.&nbsp;Default&nbsp;is&nbsp;10.<br>
-&nbsp;cv&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;folds&nbsp;for&nbsp;cross-validation.&nbsp;Default&nbsp;is&nbsp;5.<br>
-&nbsp;metric&nbsp;(str):&nbsp;The&nbsp;metric&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;evaluation.&nbsp;Default&nbsp;is&nbsp;'mse'.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Regression&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'mse',&nbsp;'r2',&nbsp;'mae',&nbsp;'rmse',&nbsp;'mape',&nbsp;'mpe'<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Classification&nbsp;<a href="#Metrics">Metrics</a>:&nbsp;'accuracy',&nbsp;'precision',&nbsp;'recall',&nbsp;'f1',&nbsp;'log_loss'<br>
-&nbsp;direction&nbsp;(str):&nbsp;The&nbsp;direction&nbsp;to&nbsp;optimize&nbsp;the&nbsp;metric.&nbsp;Default&nbsp;is&nbsp;'minimize'.</span></dd></dl>

<dl><dt><a name="RandomSearchCV-fit"><strong>fit</strong></a>(self, X, y, verbose=False)</dt><dd><span class="code">Fits&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;for&nbsp;iter&nbsp;random&nbsp;hyperparameter&nbsp;combinations.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;(numpy.ndarray):&nbsp;The&nbsp;feature&nbsp;columns.<br>
-&nbsp;y&nbsp;(numpy.ndarray):&nbsp;The&nbsp;label&nbsp;column.<br>
-&nbsp;verbose&nbsp;(bool):&nbsp;A&nbsp;flag&nbsp;to&nbsp;display&nbsp;the&nbsp;training&nbsp;progress.&nbsp;Default&nbsp;is&nbsp;True.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;model:&nbsp;The&nbsp;best&nbsp;model&nbsp;with&nbsp;the&nbsp;optimal&nbsp;hyperparameters.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RegressorTree">class <strong>RegressorTree</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#RegressorTree">RegressorTree</a>(max_depth=5)<br>
&nbsp;<br>
A&nbsp;class&nbsp;representing&nbsp;a&nbsp;decision&nbsp;tree&nbsp;for&nbsp;regression.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;max_depth&nbsp;(int):&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Methods:<br>
-&nbsp;<a href="#RegressorTree-learn">learn</a>(X,&nbsp;y,&nbsp;par_node={},&nbsp;depth=0):&nbsp;Builds&nbsp;the&nbsp;decision&nbsp;tree&nbsp;based&nbsp;on&nbsp;the&nbsp;given&nbsp;training&nbsp;data.<br>
-&nbsp;classify(record):&nbsp;Predicts&nbsp;the&nbsp;target&nbsp;value&nbsp;for&nbsp;a&nbsp;record&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RegressorTree-__init__"><strong>__init__</strong></a>(self, max_depth=5)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="RegressorTree-learn"><strong>learn</strong></a>(self, X, y, par_node={}, depth=0)</dt><dd><span class="code">Builds&nbsp;the&nbsp;decision&nbsp;tree&nbsp;based&nbsp;on&nbsp;the&nbsp;given&nbsp;training&nbsp;data.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;features.<br>
-&nbsp;y&nbsp;(array-like):&nbsp;The&nbsp;target&nbsp;labels.<br>
-&nbsp;par_node&nbsp;(dict):&nbsp;The&nbsp;parent&nbsp;node&nbsp;of&nbsp;the&nbsp;current&nbsp;subtree&nbsp;(default:&nbsp;{}).<br>
-&nbsp;depth&nbsp;(int):&nbsp;The&nbsp;current&nbsp;depth&nbsp;of&nbsp;the&nbsp;subtree&nbsp;(default:&nbsp;0).<br>
&nbsp;<br>
Returns:<br>
-&nbsp;dict:&nbsp;The&nbsp;learned&nbsp;decision&nbsp;tree.</span></dd></dl>

<dl><dt><a name="RegressorTree-predict"><strong>predict</strong></a>(self, record)</dt><dd><span class="code">Predicts&nbsp;a&nbsp;given&nbsp;record&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;record:&nbsp;A&nbsp;dictionary&nbsp;representing&nbsp;the&nbsp;record&nbsp;to&nbsp;be&nbsp;classified.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;Returns&nbsp;the&nbsp;mean&nbsp;of&nbsp;the&nbsp;target&nbsp;values.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="RegressorTreeUtility">class <strong>RegressorTreeUtility</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code">Utility&nbsp;class&nbsp;for&nbsp;computing&nbsp;variance,&nbsp;partitioning&nbsp;classes,&nbsp;and&nbsp;calculating&nbsp;information&nbsp;gain.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="RegressorTreeUtility-best_split"><strong>best_split</strong></a>(self, X, y)</dt><dd><span class="code">Finds&nbsp;the&nbsp;best&nbsp;attribute&nbsp;and&nbsp;value&nbsp;to&nbsp;split&nbsp;the&nbsp;data&nbsp;based&nbsp;on&nbsp;information&nbsp;gain.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;features.<br>
-&nbsp;y&nbsp;(array-like):&nbsp;The&nbsp;target&nbsp;variable.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;dict:&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;the&nbsp;best&nbsp;split&nbsp;attribute,&nbsp;split&nbsp;value,&nbsp;left&nbsp;and&nbsp;right&nbsp;subsets&nbsp;of&nbsp;X&nbsp;and&nbsp;y,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;the&nbsp;information&nbsp;gain&nbsp;achieved&nbsp;by&nbsp;the&nbsp;split.</span></dd></dl>

<dl><dt><a name="RegressorTreeUtility-calculate_variance"><strong>calculate_variance</strong></a>(self, y)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;variance&nbsp;of&nbsp;a&nbsp;dataset.<br>
Variance&nbsp;is&nbsp;used&nbsp;as&nbsp;the&nbsp;measure&nbsp;of&nbsp;impurity&nbsp;in&nbsp;the&nbsp;case&nbsp;of&nbsp;regression.</span></dd></dl>

<dl><dt><a name="RegressorTreeUtility-information_gain"><strong>information_gain</strong></a>(self, previous_y, current_y)</dt><dd><span class="code">Calculate&nbsp;the&nbsp;information&nbsp;gain&nbsp;from&nbsp;a&nbsp;split&nbsp;by&nbsp;subtracting&nbsp;the&nbsp;variance&nbsp;of<br>
child&nbsp;nodes&nbsp;from&nbsp;the&nbsp;variance&nbsp;of&nbsp;the&nbsp;parent&nbsp;node.</span></dd></dl>

<dl><dt><a name="RegressorTreeUtility-partition_classes"><strong>partition_classes</strong></a>(self, X, y, split_attribute, split_val)</dt><dd><span class="code">Partitions&nbsp;the&nbsp;dataset&nbsp;into&nbsp;two&nbsp;subsets&nbsp;based&nbsp;on&nbsp;a&nbsp;given&nbsp;split&nbsp;attribute&nbsp;and&nbsp;value.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;(array-like):&nbsp;The&nbsp;input&nbsp;features.<br>
-&nbsp;y&nbsp;(array-like):&nbsp;The&nbsp;target&nbsp;labels.<br>
-&nbsp;split_attribute&nbsp;(int):&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;attribute&nbsp;to&nbsp;split&nbsp;on.<br>
-&nbsp;split_val&nbsp;(float):&nbsp;The&nbsp;value&nbsp;to&nbsp;split&nbsp;the&nbsp;attribute&nbsp;on.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;X_left&nbsp;(array-like):&nbsp;The&nbsp;subset&nbsp;of&nbsp;input&nbsp;features&nbsp;where&nbsp;the&nbsp;split&nbsp;attribute&nbsp;is&nbsp;less&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;the&nbsp;split&nbsp;value.<br>
-&nbsp;X_right&nbsp;(array-like):&nbsp;The&nbsp;subset&nbsp;of&nbsp;input&nbsp;features&nbsp;where&nbsp;the&nbsp;split&nbsp;attribute&nbsp;is&nbsp;greater&nbsp;than&nbsp;the&nbsp;split&nbsp;value.<br>
-&nbsp;y_left&nbsp;(array-like):&nbsp;The&nbsp;subset&nbsp;of&nbsp;target&nbsp;labels&nbsp;corresponding&nbsp;to&nbsp;X_left.<br>
-&nbsp;y_right&nbsp;(array-like):&nbsp;The&nbsp;subset&nbsp;of&nbsp;target&nbsp;labels&nbsp;corresponding&nbsp;to&nbsp;X_right.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="Ridge">class <strong>Ridge</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#Ridge">Ridge</a>(alpha=1.0,&nbsp;fit_intercept=True,&nbsp;max_iter=10000,&nbsp;tol=0.0001)<br>
&nbsp;<br>
This&nbsp;class&nbsp;implements&nbsp;<a href="#Ridge">Ridge</a>&nbsp;Regression&nbsp;using&nbsp;Coordinate&nbsp;Descent.<br>
<a href="#Ridge">Ridge</a>&nbsp;regression&nbsp;implements&nbsp;L2&nbsp;regularization,&nbsp;which&nbsp;helps&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;a&nbsp;penalty&nbsp;term&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;alpha&nbsp;:&nbsp;float,&nbsp;default=1.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;Regularization&nbsp;strength;&nbsp;must&nbsp;be&nbsp;a&nbsp;positive&nbsp;float.&nbsp;Regularization&nbsp;improves&nbsp;the&nbsp;conditioning&nbsp;of&nbsp;the&nbsp;problem&nbsp;and&nbsp;reduces&nbsp;the&nbsp;variance&nbsp;of&nbsp;the&nbsp;estimates.<br>
-&nbsp;fit_intercept&nbsp;:&nbsp;bool,&nbsp;default=True<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model.<br>
-&nbsp;max_iter&nbsp;:&nbsp;int,&nbsp;default=10000<br>
&nbsp;&nbsp;&nbsp;&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;the&nbsp;coordinate&nbsp;descent&nbsp;solver.<br>
-&nbsp;tol&nbsp;:&nbsp;float,&nbsp;default=1e-4<br>
&nbsp;&nbsp;&nbsp;&nbsp;Tolerance&nbsp;for&nbsp;the&nbsp;optimization.&nbsp;The&nbsp;optimization&nbsp;stops&nbsp;when&nbsp;the&nbsp;change&nbsp;in&nbsp;the&nbsp;coefficients&nbsp;is&nbsp;less&nbsp;than&nbsp;this&nbsp;tolerance.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
Attributes:<br>
-&nbsp;coef_&nbsp;:&nbsp;ndarray&nbsp;of&nbsp;shape&nbsp;(n_features,)&nbsp;or&nbsp;(n_features&nbsp;+&nbsp;1,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Estimated&nbsp;coefficients&nbsp;for&nbsp;the&nbsp;linear&nbsp;regression&nbsp;problem.&nbsp;If&nbsp;`fit_intercept`&nbsp;is&nbsp;True,&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;the&nbsp;intercept.<br>
-&nbsp;intercept_&nbsp;:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;Independent&nbsp;term&nbsp;in&nbsp;the&nbsp;linear&nbsp;model.&nbsp;Set&nbsp;to&nbsp;0.0&nbsp;if&nbsp;`fit_intercept`&nbsp;is&nbsp;False.<br>
&nbsp;<br>
Methods:<br>
-&nbsp;<a href="#Ridge-fit">fit</a>(X,&nbsp;y):&nbsp;Fit&nbsp;the&nbsp;linear&nbsp;model&nbsp;to&nbsp;the&nbsp;data.<br>
-&nbsp;<a href="#Ridge-predict">predict</a>(X):&nbsp;Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model.<br>
-&nbsp;<a href="#Ridge-get_formula">get_formula</a>():&nbsp;Returns&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model&nbsp;as&nbsp;a&nbsp;string.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="Ridge-__init__"><strong>__init__</strong></a>(self, alpha=1.0, fit_intercept=True, max_iter=10000, tol=0.0001)</dt><dd><span class="code">This&nbsp;class&nbsp;implements&nbsp;<a href="#Ridge">Ridge</a>&nbsp;Regression&nbsp;using&nbsp;Coordinate&nbsp;Descent.<br>
<a href="#Ridge">Ridge</a>&nbsp;regression&nbsp;implements&nbsp;L2&nbsp;regularization,&nbsp;which&nbsp;helps&nbsp;to&nbsp;prevent&nbsp;overfitting&nbsp;by&nbsp;adding&nbsp;a&nbsp;penalty&nbsp;term&nbsp;to&nbsp;the&nbsp;loss&nbsp;function.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;alpha&nbsp;:&nbsp;float,&nbsp;default=1.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;Regularization&nbsp;strength;&nbsp;must&nbsp;be&nbsp;a&nbsp;positive&nbsp;float.&nbsp;Regularization&nbsp;improves&nbsp;the&nbsp;conditioning&nbsp;of&nbsp;the&nbsp;problem&nbsp;and&nbsp;reduces&nbsp;the&nbsp;variance&nbsp;of&nbsp;the&nbsp;estimates.<br>
-&nbsp;fit_intercept&nbsp;:&nbsp;bool,&nbsp;default=True<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;calculate&nbsp;the&nbsp;intercept&nbsp;for&nbsp;this&nbsp;model.<br>
-&nbsp;max_iter&nbsp;:&nbsp;int,&nbsp;default=10000<br>
&nbsp;&nbsp;&nbsp;&nbsp;Maximum&nbsp;number&nbsp;of&nbsp;iterations&nbsp;for&nbsp;the&nbsp;coordinate&nbsp;descent&nbsp;solver.<br>
-&nbsp;tol&nbsp;:&nbsp;float,&nbsp;default=1e-4<br>
&nbsp;&nbsp;&nbsp;&nbsp;Tolerance&nbsp;for&nbsp;the&nbsp;optimization.&nbsp;The&nbsp;optimization&nbsp;stops&nbsp;when&nbsp;the&nbsp;change&nbsp;in&nbsp;the&nbsp;coefficients&nbsp;is&nbsp;less&nbsp;than&nbsp;this&nbsp;tolerance.</span></dd></dl>

<dl><dt><a name="Ridge-__str__"><strong>__str__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;str(self).</span></dd></dl>

<dl><dt><a name="Ridge-fit"><strong>fit</strong></a>(self, X, y)</dt><dd><span class="code">Fit&nbsp;the&nbsp;model&nbsp;to&nbsp;the&nbsp;data&nbsp;using&nbsp;coordinate&nbsp;descent.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Training&nbsp;data.<br>
-&nbsp;y&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,)&nbsp;or&nbsp;(n_samples,&nbsp;n_targets):&nbsp;Target&nbsp;values.</span></dd></dl>

<dl><dt><a name="Ridge-get_formula"><strong>get_formula</strong></a>(self)</dt><dd><span class="code">Computes&nbsp;the&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;formula&nbsp;:&nbsp;str:&nbsp;The&nbsp;formula&nbsp;of&nbsp;the&nbsp;model.</span></dd></dl>

<dl><dt><a name="Ridge-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;using&nbsp;the&nbsp;linear&nbsp;model.&nbsp;&nbsp;<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X&nbsp;:&nbsp;array-like&nbsp;of&nbsp;shape&nbsp;(n_samples,&nbsp;n_features):&nbsp;Samples.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="SGDOptimizer">class <strong>SGDOptimizer</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#SGDOptimizer">SGDOptimizer</a>(learning_rate=0.001,&nbsp;momentum=0.0,&nbsp;reg_lambda=0.0)<br>
&nbsp;<br>
Stochastic&nbsp;Gradient&nbsp;Descent&nbsp;(SGD)&nbsp;optimizer&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
Formula:&nbsp;w&nbsp;=&nbsp;w&nbsp;-&nbsp;learning_rate&nbsp;*&nbsp;dW,&nbsp;b&nbsp;=&nbsp;b&nbsp;-&nbsp;learning_rate&nbsp;*&nbsp;db<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;for&nbsp;the&nbsp;optimizer.&nbsp;Defaults&nbsp;to&nbsp;0.001.<br>
&nbsp;&nbsp;&nbsp;&nbsp;momentum&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;momentum&nbsp;factor.&nbsp;Defaults&nbsp;to&nbsp;0.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;regularization&nbsp;parameter.&nbsp;Defaults&nbsp;to&nbsp;0.0.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="SGDOptimizer-__init__"><strong>__init__</strong></a>(self, learning_rate=0.001, momentum=0.0, reg_lambda=0.0)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="SGDOptimizer-initialize"><strong>initialize</strong></a>(self, layers)</dt><dd><span class="code">Initializes&nbsp;the&nbsp;velocity&nbsp;for&nbsp;each&nbsp;layer's&nbsp;weights.<br>
Args:&nbsp;layers&nbsp;(list):&nbsp;List&nbsp;of&nbsp;layers&nbsp;in&nbsp;the&nbsp;neural&nbsp;network.<br>
Returns:&nbsp;None</span></dd></dl>

<dl><dt><a name="SGDOptimizer-update"><strong>update</strong></a>(self, layer, dW, db, index)</dt><dd><span class="code">Updates&nbsp;the&nbsp;weights&nbsp;and&nbsp;biases&nbsp;of&nbsp;a&nbsp;layer&nbsp;using&nbsp;the&nbsp;SGD&nbsp;optimization&nbsp;algorithm.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;layer&nbsp;(<a href="#Layer">Layer</a>):&nbsp;The&nbsp;layer&nbsp;to&nbsp;update.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dW&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;db&nbsp;(ndarray):&nbsp;The&nbsp;gradient&nbsp;of&nbsp;the&nbsp;biases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;index&nbsp;(int):&nbsp;The&nbsp;index&nbsp;of&nbsp;the&nbsp;layer.<br>
Returns:&nbsp;None</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="VotingRegressor">class <strong>VotingRegressor</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#VotingRegressor">VotingRegressor</a>(models,&nbsp;model_weights=None)<br>
&nbsp;<br>
Implements&nbsp;a&nbsp;voting&nbsp;regressor.<br>
Takes&nbsp;a&nbsp;list&nbsp;of&nbsp;fitted&nbsp;models&nbsp;and&nbsp;their&nbsp;weights&nbsp;and&nbsp;returns&nbsp;a&nbsp;weighted&nbsp;average&nbsp;of&nbsp;the&nbsp;predictions.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="VotingRegressor-__init__"><strong>__init__</strong></a>(self, models, model_weights=None)</dt><dd><span class="code">Initialize&nbsp;the&nbsp;<a href="#VotingRegressor">VotingRegressor</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;models:&nbsp;list&nbsp;of&nbsp;models&nbsp;to&nbsp;be&nbsp;stacked<br>
-&nbsp;model_weights:&nbsp;list&nbsp;of&nbsp;weights&nbsp;for&nbsp;each&nbsp;model.&nbsp;Default&nbsp;is&nbsp;None.</span></dd></dl>

<dl><dt><a name="VotingRegressor-get_params"><strong>get_params</strong></a>(self)</dt><dd><span class="code">Get&nbsp;the&nbsp;parameters&nbsp;of&nbsp;the&nbsp;<a href="#VotingRegressor">VotingRegressor</a>&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;<br>
Returns:<br>
-&nbsp;params:&nbsp;dictionary&nbsp;of&nbsp;parameters</span></dd></dl>

<dl><dt><a name="VotingRegressor-predict"><strong>predict</strong></a>(self, X)</dt><dd><span class="code">Predict&nbsp;the&nbsp;target&nbsp;variable&nbsp;using&nbsp;the&nbsp;fitted&nbsp;models.<br>
&nbsp;<br>
Parameters:<br>
-&nbsp;X:&nbsp;input&nbsp;features<br>
&nbsp;<br>
Returns:<br>
-&nbsp;y_pred:&nbsp;predicted&nbsp;target&nbsp;variable</span></dd></dl>

<dl><dt><a name="VotingRegressor-show_models"><strong>show_models</strong></a>(self, formula=False)</dt><dd><span class="code">Print&nbsp;the&nbsp;models&nbsp;and&nbsp;their&nbsp;weights.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="lr_scheduler_exp">class <strong>lr_scheduler_exp</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#lr_scheduler_exp">lr_scheduler_exp</a>(optimizer,&nbsp;lr_decay=0.1,&nbsp;lr_decay_epoch=10)<br>
&nbsp;<br>
Learning&nbsp;rate&nbsp;scheduler&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
Reduces&nbsp;the&nbsp;learning&nbsp;rate&nbsp;exponentially&nbsp;by&nbsp;lr_decay&nbsp;every&nbsp;lr_decay_epoch&nbsp;epochs.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="lr_scheduler_exp-__init__"><strong>__init__</strong></a>(self, optimizer, lr_decay=0.1, lr_decay_epoch=10)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="lr_scheduler_exp-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;repr(self).</span></dd></dl>

<dl><dt><a name="lr_scheduler_exp-reduce"><strong>reduce</strong></a>(self)</dt></dl>

<dl><dt><a name="lr_scheduler_exp-step"><strong>step</strong></a>(self, epoch)</dt><dd><span class="code">Adjusts&nbsp;the&nbsp;learning&nbsp;rate&nbsp;based&nbsp;on&nbsp;the&nbsp;current&nbsp;epoch.&nbsp;Decays&nbsp;the&nbsp;learning&nbsp;rate&nbsp;by&nbsp;lr_decay&nbsp;every&nbsp;lr_decay_epoch&nbsp;epochs.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;epoch&nbsp;(int):&nbsp;The&nbsp;current&nbsp;epoch&nbsp;number.<br>
Returns:&nbsp;None</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="lr_scheduler_plateau">class <strong>lr_scheduler_plateau</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#lr_scheduler_plateau">lr_scheduler_plateau</a>(lr_scheduler,&nbsp;patience=5,&nbsp;threshold=0.01)<br>
&nbsp;<br>
A&nbsp;custom&nbsp;learning&nbsp;rate&nbsp;scheduler&nbsp;that&nbsp;adjusts&nbsp;the&nbsp;learning&nbsp;rate&nbsp;based&nbsp;on&nbsp;the&nbsp;plateau&nbsp;of&nbsp;the&nbsp;loss&nbsp;function.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_scheduler&nbsp;(<a href="builtins.html#object">object</a>):&nbsp;The&nbsp;learning&nbsp;rate&nbsp;scheduler&nbsp;<a href="builtins.html#object">object</a>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;patience&nbsp;(int):&nbsp;The&nbsp;number&nbsp;of&nbsp;epochs&nbsp;to&nbsp;wait&nbsp;for&nbsp;improvement&nbsp;before&nbsp;reducing&nbsp;the&nbsp;learning&nbsp;rate.&nbsp;Default&nbsp;is&nbsp;5.<br>
&nbsp;&nbsp;&nbsp;&nbsp;threshold&nbsp;(float):&nbsp;The&nbsp;minimum&nbsp;improvement&nbsp;threshold&nbsp;required&nbsp;to&nbsp;update&nbsp;the&nbsp;best&nbsp;loss.&nbsp;Default&nbsp;is&nbsp;0.01.<br>
Methods:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#lr_scheduler_plateau-step">step</a>(loss):&nbsp;Updates&nbsp;the&nbsp;learning&nbsp;rate&nbsp;based&nbsp;on&nbsp;the&nbsp;loss&nbsp;value.<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="lr_scheduler_plateau-__init__"><strong>__init__</strong></a>(self, lr_scheduler, patience=5, threshold=0.01)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="lr_scheduler_plateau-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;repr(self).</span></dd></dl>

<dl><dt><a name="lr_scheduler_plateau-step"><strong>step</strong></a>(self, epoch, loss)</dt><dd><span class="code">Updates&nbsp;the&nbsp;learning&nbsp;rate&nbsp;based&nbsp;on&nbsp;the&nbsp;loss&nbsp;value.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;loss&nbsp;(float):&nbsp;The&nbsp;current&nbsp;loss&nbsp;value.</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table> <p>
<table class="section">
<tr class="decor title-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><a name="lr_scheduler_step">class <strong>lr_scheduler_step</strong></a>(<a href="builtins.html#object">builtins.object</a>)</td></tr>
    
<tr><td class="decor title-decor" rowspan=2><span class="code">&nbsp;&nbsp;&nbsp;</span></td>
<td class="decor title-decor" colspan=2><span class="code"><a href="#lr_scheduler_step">lr_scheduler_step</a>(optimizer,&nbsp;lr_decay=0.1,&nbsp;lr_decay_epoch=10)<br>
&nbsp;<br>
Learning&nbsp;rate&nbsp;scheduler&nbsp;class&nbsp;for&nbsp;training&nbsp;neural&nbsp;networks.<br>
Reduces&nbsp;the&nbsp;learning&nbsp;rate&nbsp;by&nbsp;a&nbsp;factor&nbsp;of&nbsp;lr_decay&nbsp;every&nbsp;lr_decay_epoch&nbsp;epochs.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;optimizer&nbsp;(Optimizer):&nbsp;The&nbsp;optimizer&nbsp;to&nbsp;adjust&nbsp;the&nbsp;learning&nbsp;rate&nbsp;for.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_decay&nbsp;(float,&nbsp;optional):&nbsp;The&nbsp;factor&nbsp;to&nbsp;reduce&nbsp;the&nbsp;learning&nbsp;rate&nbsp;by.&nbsp;Defaults&nbsp;to&nbsp;0.1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lr_decay_epoch&nbsp;(int,&nbsp;optional):&nbsp;The&nbsp;number&nbsp;of&nbsp;epochs&nbsp;to&nbsp;wait&nbsp;before&nbsp;decaying&nbsp;the&nbsp;learning&nbsp;rate.&nbsp;Defaults&nbsp;to&nbsp;10<br>&nbsp;</span></td></tr>
<tr><td>&nbsp;</td>
<td class="singlecolumn">Methods defined here:<br>
<dl><dt><a name="lr_scheduler_step-__init__"><strong>__init__</strong></a>(self, optimizer, lr_decay=0.1, lr_decay_epoch=10)</dt><dd><span class="code">Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</span></dd></dl>

<dl><dt><a name="lr_scheduler_step-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><span class="code">Return&nbsp;repr(self).</span></dd></dl>

<dl><dt><a name="lr_scheduler_step-reduce"><strong>reduce</strong></a>(self)</dt></dl>

<dl><dt><a name="lr_scheduler_step-step"><strong>step</strong></a>(self, epoch)</dt><dd><span class="code">Adjusts&nbsp;the&nbsp;learning&nbsp;rate&nbsp;based&nbsp;on&nbsp;the&nbsp;current&nbsp;epoch.&nbsp;Decays&nbsp;the&nbsp;learning&nbsp;rate&nbsp;by&nbsp;lr_decay&nbsp;every&nbsp;lr_decay_epoch&nbsp;epochs.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;epoch&nbsp;(int):&nbsp;The&nbsp;current&nbsp;epoch&nbsp;number.<br>
Returns:&nbsp;None</span></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><span class="code">dictionary&nbsp;for&nbsp;instance&nbsp;variables</span></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><span class="code">list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object</span></dd>
</dl>
</td></tr></table></td></tr></table><p>
<table class="section">
<tr class="decor data-decor heading-text">
<td class="section-title" colspan=3>&nbsp;<br><strong class="bigsection">Data</strong></td></tr>
    
<tr><td class="decor data-decor"><span class="code">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></td><td>&nbsp;</td>
<td class="singlecolumn"><strong>__all__</strong> = ['PolynomialTransform', 'DataPrep', 'VotingRegressor', 'ModelSelectionUtility', 'GridSearchCV', 'RandomSearchCV', 'Metrics', 'KMeans', 'DBSCAN', 'OrdinaryLeastSquares', 'Ridge', 'Lasso', 'Bayesian', 'RANSAC', 'PassiveAggressiveRegressor', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'make_dataClassifierTreeUtility', 'ClassifierTree', 'RegressorTreeUtility', ...]</td></tr></table>
</body></html>
